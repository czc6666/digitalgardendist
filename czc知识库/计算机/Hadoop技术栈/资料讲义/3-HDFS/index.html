<!doctype html>
<html lang="zh-CN">
<head>
<title>3-HDFS</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.74516f71.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
<style></style>
</head>
<body class="theme-light markdown-preview-view markdown-rendered markdown-preview-section css-settings-manager mod-windows is-frameless is-maximized is-hidden-frameless is-focused obsidian-app theme-light show-inline-title show-ribbon show-view-header css-settings-manager theme-default line-style-solid folder-default blockquote-normal callout-normal checkbox-default tag-default link-default heading-default responsive-tile-height oz-show-all-num">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">czc&#39;s digital garden</h1>
</a>
</div>
<div class="search-button align-icon" onclick="toggleSearch()">
<span class="search-icon">
<i icon-name="search"></i>
</span>
<span class="search-text">
<span>Search</span>
<span style="font-size:.6rem;padding:2px 2px 0 6px;text-align:center;transform:translateY(4px)" class="search-keys">
CTRL + K
</span>
</span>
</div>
</nav>
<div class="search-container" id="globalsearch" onclick="toggleSearch()">
<div class="search-box">
<input type="search" id="term" placeholder="Start typing...">
<div id="search-results"></div>
<footer class="search-box-footer">
<div class="navigation-hint">
<span>Enter to select</span>
</div>
<div class="navigation-hint align-icon">
<i icon-name="arrow-up" aria-hidden="true"></i>
<i icon-name="arrow-down" aria-hidden="true"></i>
<span>to navigate</span>
</div>
<div class="navigation-hint">
<span>ESC to close</span>
</div>
</footer>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js"></script>
<script>document.addEventListener("DOMContentLoaded",init,!1),document.addEventListener("DOMContentLoaded",setCorrectShortcut,!1),window.toggleSearch=function(){document.getElementById("globalsearch").classList.contains("active")?document.getElementById("globalsearch").classList.remove("active"):(document.getElementById("globalsearch").classList.add("active"),document.getElementById("term").focus())},window.toggleTagSearch=function(e){console.log(e.textContent);const t=e.textContent;t&&(window.document.getElementById("term").value=t.trim(),window.toggleSearch(),window.search())};const loadingSvg='\n    <svg width="100" height="100" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg" stroke="#fff">\n      <g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2">\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="1.5s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="1.5s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="1.5s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="3s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="3s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="3s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="8">\n              <animate attributeName="r"\n                   begin="0s" dur="1.5s"\n                   values="6;1;2;3;4;5;6"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n      </g>\n  </svg>';function debounce(e,t,n){var a;return function(){var r=this,i=arguments,c=n&&!a;clearTimeout(a),a=setTimeout((function(){a=null,n||e.apply(r,i)}),t),c&&e.apply(r,i)}}function setCorrectShortcut(){navigator.platform.toUpperCase().indexOf("MAC")>=0&&document.querySelectorAll(".search-keys").forEach((e=>e.innerHTML="⌘ + K"))}function createIndex(e){const t=e=>e.toLowerCase().split(/([^a-z]|[^\x00-\x7F])/),n=new FlexSearch.Document({cache:!0,charset:"latin:extra",optimize:!0,index:[{field:"content",tokenize:"reverse",encode:t},{field:"title",tokenize:"forward",encode:t},{field:"tags",tokenize:"forward",encode:t}]});return e.forEach(((e,t)=>{n.add({id:t,title:e.title,content:e.content,tags:e.tags})})),n}async function init(){let e=!0;if(localStorage.getItem("searchIndex")){let{date:t,docs:n}=JSON.parse(localStorage.getItem("searchIndex"));if("2025-06-04T13:33:33.931Z"===t){e=!1;let t=createIndex(n);window.docs=n,window.index=t}}if(e){let e=await(await fetch("/searchIndex.json?v=2025-06-04T13:33:33.931Z")).json(),t=createIndex(e);localStorage.setItem("searchIndex",JSON.stringify({date:"2025-06-04T13:33:33.931Z",docs:e})),window.docs=e,window.index=t}document.addEventListener("keydown",(e=>{if((e.ctrlKey||e.metaKey)&&"k"===e.key&&(e.preventDefault(),toggleSearch()),"Escape"===e.key&&document.getElementById("globalsearch").classList.remove("active"),document.getElementById("globalsearch").classList.contains("active")){if("ArrowDown"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.nextElementSibling?t.nextElementSibling.classList.add("active"):document.querySelector(".searchresult").classList.add("active")):document.querySelector(".searchresult").classList.add("active");let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("ArrowUp"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.previousElementSibling?t.previousElementSibling.classList.add("active"):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling||e.classList.add("active")}))):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling&&e.classList.add("active")}));let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("Enter"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t&&(window.location.href=t.querySelector("a").href)}}}));const t=debounce(search,200,!1);field=document.querySelector("#term"),field.addEventListener("keydown",(e=>{"ArrowDown"!==e.key&&"ArrowUp"!==e.key&&t()})),resultsDiv=document.querySelector("#search-results");const n=new URL(location.href).searchParams;n.get("q")&&(field.setAttribute("value",n.get("q")),toggleSearch(),search())}async function search(){let e=field.value.trim();if(!e)return;if(e==lastSearch)return;console.log(`search for ${e}`),window.lastSearch=e,resultsDiv.innerHTML=loadingSvg;let t=offlineSearch(e),n="";if(!t.length){let t=document.createElement("p");return t.innerText=`No results for "${e}"`,resultsDiv.innerHTML="",void resultsDiv.appendChild(t)}n+='<div style="max-width:100%;">',t.forEach((e=>{e.tags&&e.tags.length>0?n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        <div class="header-meta">\n                            <div class="header-tags">\n                                ${e.tags.map((e=>'<a class="tag" href="JavaScript:Void(0);">#'+e+"</a>")).join("")}\n                            </div>\n                        </div>\n                        ${e.content}\n                    </div>\n                </div>`:n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        ${e.content}\n                    </div>\n                </div>`})),n+="</div>",resultsDiv.innerHTML=n}function truncate(e,t){return(e=e.replaceAll(/<[^>]*>/g,"")).length<t?e:e.substring(0,t-3)+"..."}function offlineSearch(e){let t=window.docs,n="#"===e[0]&&e.length>1?index.search(e.substring(1),[{field:"tags"}]):index.search(e,[{field:"title",limit:5},{field:"content",weight:10}]);const a=e=>{const t=n.filter((t=>t.field===e));return 0===t.length?[]:[...t[0].result]};return[...new Set([...a("title"),...a("content"),...a("tags")])].map((e=>{let n=t[e];return n.content=truncate(n.content,400),n.tags=n.tags.filter((e=>"gardenEntry"!=e&&"note"!=e)),n}))}window.lastSearch=""</script>
<main class="content cm-s-obsidian">
<header>
<h1 data-note-icon="">3-HDFS</h1>
<div class="header-meta">
<div class="header-tags">
</div>
<div class="timestamps"><div><i icon-name="calendar-plus"></i> <span class="human-date" data-date="2025-02-28T17:45:54.749+08:00"></span></div><div><i icon-name="calendar-clock"></i> <span class="human-date" data-date="2025-03-19T15:59:25.000+08:00"></span></div></div></div>
</header>
<h3 id="hadoop-day03-hadoop-hdfs" tabindex="-1">hadoop离线day03--Hadoop HDFS</h3>
<hr>
<h4 id="今日课程学习目标" tabindex="-1">今日课程学习目标</h4>
<pre><code>理解分布式文件存储的概念与实现
掌握HDFS分块存储、副本机制等特性
学会shell操作HDFS
掌握HDFS读写流程
理解NameNode元数据管理机制
理解SecondaryNameNode checkpoint机制
</code></pre>
<h4 id="今日课程内容大纲" tabindex="-1">今日课程内容大纲</h4>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#HDFS入门">#HDFS入门</a>
	HDFS介绍
	如何模拟实现分布式文件存储系统？ 具备哪些特性。
		分布式、分块存储、副本机制、元数据管理
	HDFS设计目标和重要特性
<a class="tag" onclick="toggleTagSearch(this)" data-content="#HDFS操作">#HDFS操作</a>
	shell command
<a class="tag" onclick="toggleTagSearch(this)" data-content="#HDFS原理（重中之重）">#HDFS原理（重中之重）</a>
	工作机制--读写流程  角色之间如何配合的 每个角色承担了什么职责
	NN DN角色职责概述总结
<a class="tag" onclick="toggleTagSearch(this)" data-content="#HDFS辅助功能">#HDFS辅助功能</a>
	distcp 跨集群复制数据 
	Archive 归档文件  处理小文件
<a class="tag" onclick="toggleTagSearch(this)" data-content="#HDFS元数据管理机制">#HDFS元数据管理机制</a>
	namenode如何管理元数据
	secondarynamenode职责
		checkpoint机制
<a class="tag" onclick="toggleTagSearch(this)" data-content="#HDFS安全模式">#HDFS安全模式</a>

<a class="tag" onclick="toggleTagSearch(this)" data-content="#理清两个东西">#理清两个东西</a>  数据data 元数据metadata
</code></pre>
<hr>
<h4 id="01" tabindex="-1">知识点01：传统文件系统及其面临的挑战</h4>
<blockquote>
<p>大数据场景下，传统文件系统如何才能支撑海量数据存储？</p>
</blockquote>
<h4 id="02" tabindex="-1">知识点02：分布式文件存储系统核心特性与作用</h4>
<blockquote>
<p>场景互动：如何模拟实现分布式文件系统。</p>
<p>或者说一个<mark>成熟的分布式</mark>文件系统应该要具备哪些属性、功能呢？</p>
</blockquote>
<ul>
<li>分布式存储</li>
<li>元数据记录</li>
<li>分块存储</li>
<li>副本机制</li>
</ul>
<hr>
<h4 id="03-hadoop-hdfs" tabindex="-1">知识点03：Hadoop HDFS--简介</h4>
<p>3.1、HDFS基本概念</p>
<ul>
<li>
<p>首先是一个<mark>文件系统</mark>，就是用来存储文件、存储数据。是大数据最底层一个服务。</p>
</li>
<li>
<p>其次是一个<mark>分布式的文件系统</mark>。分布式意味着多台机器存储。</p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921162345561.png" alt="image-20210921162345561.png"><source media="(max-width:480px)" srcset="/img/optimized/kYPWuiL0wd-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/kYPWuiL0wd-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/kYPWuiL0wd-613.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/kYPWuiL0wd-613.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921162345561.png" alt="image-20210921162345561.png" width=""></picture></p>
</li>
</ul>
<hr>
<h4 id="04-hadoop-hdfs-strong-strong" tabindex="-1">知识点04：Hadoop HDFS--起源发展和<strong>设计目标</strong></h4>
<ul>
<li>具备<strong>故障检测</strong>和<strong>快速恢复</strong>的能力（容错）</li>
<li>面对海量数据的存储，<strong>注重吞吐能力</strong>，而不是交互式。（延迟高）</li>
<li>支持<strong>大文件存储</strong>（越大越开心）</li>
<li><mark>一次写入</mark>多次读取模型(write-one-read-many) （不支持修改操作）</li>
<li>移动计算代价比移动数据代价低</li>
<li>异构存储、<strong>可移植性</strong></li>
</ul>
<p><strong>HDFS适用场景</strong></p>
<ul>
<li>适用：
<ul>
<li>大文件</li>
<li>数据流式访问</li>
<li>一次写入多次读取</li>
<li>低成本部署，廉价pc</li>
<li>高容错</li>
</ul>
</li>
<li>不适用：
<ul>
<li>小文件</li>
<li>数据交互式访问</li>
<li>频繁任意修改</li>
<li>低延迟处理</li>
</ul>
</li>
</ul>
<hr>
<h4 id="05-hadoop-hdfs" tabindex="-1">知识点05：Hadoop HDFS--核心重要特性解读</h4>
<ul>
<li>
<p><mark>master|slaves 主从架构</mark></p>
<ul>
<li>主角色：namenode 管理维护着元数据：目录树结构 文件 大小 副本 备份 位置信息</li>
<li>从角色：datanode 存储着最终的数据块</li>
</ul>
</li>
<li>
<p><mark>分块存储</mark></p>
<pre><code>物理上把文件分开了。
block size =128M  134217728   hadoop2.x (hadoop1.x 64M)

e.g:
	1.txt 300M
		blk-1  0--128
		blk-2  128-256
		blk-3  256-300
	
	2.txt 100M
		blk-4  0--100
</code></pre>
</li>
<li>
<p><mark>副本机制</mark><br>
默认是3副本。<br>
1+2=3 本身一份 额外两份 最终3副本。</p>
</li>
<li>
<p><mark>namespace 名字空间 命名空间</mark></p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#namespace即“命名空间”，也称“名称空间”">#namespace即“命名空间”，也称“名称空间”</a> 

层次感结构  兼顾传统对应文件系统的认知  目录树结构
用户可以针对目录树进行文件夹、文件的增删改查。
统一的抽象目录树。
</code></pre>
</li>
<li>
<p><mark>metadata 元数据</mark></p>
<pre><code>元数据：记录数据的数据 描述性数据、解释性数据

对于HDFS来说，目录结构及文件分块位置信息叫做元数据。
元数据是有namenode维护的。
</code></pre>
</li>
<li>
<p><mark>write one read many</mark></p>
<pre><code>hdfs的模式是一次写入多次读取  
hdfs没有随机修改编辑的操作  只能对已有的数据进行追加。
设计目标是这么决定的。

侧重于数据吞吐量 不注重实时交互性  意味着hdfs操作延迟很高。
</code></pre>
</li>
</ul>
<hr>
<h4 id="06-hadoop-hdfs-shell" tabindex="-1">知识点06：Hadoop HDFS--shell 操作--命令行功能及使用说明</h4>
<pre><code class="language-shell">hadoop  fs &lt;args&gt;  文件系统的路径

<a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop">#hadoop</a>  fs可以操作的文件系统不仅仅有HDFS,还包括本地文件系统、GFS、TFS。
<a class="tag" onclick="toggleTagSearch(this)" data-content="#如何区分操作访问的是什么文件系统呢？">#如何区分操作访问的是什么文件系统呢？</a>  根据文件系统协议

hadoop fs -ls hdfs://node1:8020/

hadoop fs -ls file:///
hadoop fs -ls gfs://

<a class="tag" onclick="toggleTagSearch(this)" data-content="#如果不写协议">#如果不写协议</a> 直接/目录 操作访问的是谁？
[root@node1 ~]# hadoop fs -ls /
Found 4 items
drwxr-xr-x   - root supergroup          0 2021-05-23 16:49 /itcast
drwx------   - root supergroup          0 2021-05-23 16:12 /tmp
drwxr-xr-x   - root supergroup          0 2021-05-23 16:12 /user
drwxr-xr-x   - root supergroup          0 2021-05-23 16:16 /wc

<a class="tag" onclick="toggleTagSearch(this)" data-content="#默认是谁，取决于参数fs">#默认是谁，取决于参数fs</a>.defaultFS
&lt;property&gt;
        &lt;name&gt;fs.defaultFS&lt;/name&gt;
        &lt;value&gt;hdfs://node1:8020&lt;/value&gt;
&lt;/property&gt;

<a class="tag" onclick="toggleTagSearch(this)" data-content="#如果fs">#如果fs</a>.defaultFS没有配置  默认的是file:///

<a class="tag" onclick="toggleTagSearch(this)" data-content="#新旧命令">#新旧命令</a>  推荐使用hadoop fs
hadoop fs &lt;args&gt; = hdfs dfs &lt;args&gt;
</code></pre>
<hr>
<h4 id="07-hadoop-hdfs-shell" tabindex="-1">知识点07：Hadoop HDFS--shell 操作--常见命令操作</h4>
<pre><code class="language-shell"># 查看指定目录下信息
hadoop fs -ls [-h] [-R] &lt;args&gt;
	-h 人性化显示
	-R 递归显示

<a class="tag" onclick="toggleTagSearch(this)" data-content="#创建文件夹">#创建文件夹</a>
hadoop fs -mkdir [-p] &lt;paths&gt;
	-p 创建父目录
	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#上传文件">#上传文件</a>
hadoop fs -put src  dst
将单个 src 或多个 srcs 从本地文件系统复制到目标文件系统
	<a class="tag" onclick="toggleTagSearch(this)" data-content="#src代表的是本地目录">#src代表的是本地目录</a> 所谓的本地指的是客户端所在的机器 
	<a class="tag" onclick="toggleTagSearch(this)" data-content="#dst代表的是HDFS">#dst代表的是HDFS</a>
	-p：保留访问和修改时间，所有权和权限。
	-f：覆盖目的地（如果已经存在）
	
hadoop fs -put file:///root/itcast.txt hdfs://node1:8020/itcast	

hadoop fs -put itcast.txt /itcast

<a class="tag" onclick="toggleTagSearch(this)" data-content="#下载文件">#下载文件</a>
hadoop fs -get  src  localdst
	<a class="tag" onclick="toggleTagSearch(this)" data-content="#将文件复制到本地文件系统。">#将文件复制到本地文件系统。</a>
hadoop fs -get hdfs://node1:8020/itcast/itcast.txt file:///root/
hadoop fs -get /itcast/itcast.txt ./

<a class="tag" onclick="toggleTagSearch(this)" data-content="#追加内容到文件尾部">#追加内容到文件尾部</a> appendToFile
[root@node3 ~]# echo 1 &gt;&gt; 1.txt
[root@node3 ~]# echo 2 &gt;&gt; 2.txt 
[root@node3 ~]# echo 3 &gt;&gt; 3.txt 
[root@node3 ~]# hadoop fs -put 1.txt /
[root@node3 ~]# hadoop fs -cat /1.txt
1
[root@node3 ~]# hadoop fs -appendToFile 2.txt 3.txt /1.txt
[root@node3 ~]# hadoop fs -cat /1.txt
1
2
3
[root@node3 ~]# 

<a class="tag" onclick="toggleTagSearch(this)" data-content="#追加的用途：把本地的小文件上传中合并成为大文件">#追加的用途：把本地的小文件上传中合并成为大文件</a> 解决小文件场景的。

<a class="tag" onclick="toggleTagSearch(this)" data-content="#文件内容的查看">#文件内容的查看</a>
cat 适合小文件
tail 将文件的最后一千字节内容显示到stdout  -f参数支持实时追踪查看

<a class="tag" onclick="toggleTagSearch(this)" data-content="#权限">#权限</a> 拥有者 所属组修改

	hdfs在设计的时候 借鉴模仿着linux权限管理模式
	也有所谓的读写执行 user group others  777
chgrp  修改所属组
chmod  修改权限
cgown  修改拥有者

hadoop fs -chmod 755 /1.txt

<a class="tag" onclick="toggleTagSearch(this)" data-content="#文件移动">#文件移动</a> 复制 删除
mv cp 
rm -r递归删除 


<a class="tag" onclick="toggleTagSearch(this)" data-content="#合并下载">#合并下载</a> getmerge
合并下载多个文件  其功能和appendToFile相反的动作
[root@node3 ~]# hadoop fs -mkdir /small
[root@node3 ~]# hadoop fs -put *.txt /small
[root@node3 ~]# hadoop fs -getmerge /small/* ./merge.txt
[root@node3 ~]# cat merge.txt 

<a class="tag" onclick="toggleTagSearch(this)" data-content="#统计HDFS可用空间">#统计HDFS可用空间</a>  指定目录大小
[root@node3 ~]# hadoop fs -df -h /
Filesystem            Size   Used  Available  Use%
hdfs://node1:8020  111.1 G  5.0 M     98.3 G    0%

<a class="tag" onclick="toggleTagSearch(this)" data-content="#修改文件的副本数">#修改文件的副本数</a>
hadoop fs -setrep -w N -R   N就是修改之后的副本数
-w wait等待 修改副本客户端是否等待修改完毕再推出

[root@node3 ~]# hadoop fs -setrep 2 /small/1.txt
Replication 2 set: /small/1.txt

[root@node3 ~]# hadoop fs -setrep -w 2 /small/2.txt
Replication 2 set: /small/2.txt
Waiting for /small/2.txt ...
WARNING: the waiting time may be long for DECREASING the number of replications.
. done

<a class="tag" onclick="toggleTagSearch(this)" data-content="#企业中避免使用setrep修改文件的副本数。">#企业中避免使用setrep修改文件的副本数。</a>
副本的修改操作可能会影响hdfs正常的读写服务请求。
因此在实际工作中 事先根据数据的重要性在上传之前就决定该文件的备份数是多少 避免线上修改。
</code></pre>
<hr>
<h4 id="08-hadoop-hdfs" tabindex="-1">知识点08：Hadoop HDFS--工作机制--角色与角色职责</h4>
<ul>
<li>namenode 管理元数据 维护 namespace</li>
<li>datanode 管理数据</li>
</ul>
<hr>
<h4 id="09-hadoop-hdfs" tabindex="-1">知识点09：Hadoop HDFS--工作机制--上传文件流程（写文件流程）</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921162853674.png" alt="image-20210921162853674.png"><source media="(max-width:480px)" srcset="/img/optimized/4QD-6-gwI6-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/4QD-6-gwI6-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/4QD-6-gwI6-692.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/4QD-6-gwI6-692.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921162853674.png" alt="image-20210921162853674.png" width=""></picture></p>
<h4 id="10-hadoop-hdfs" tabindex="-1">知识点10：Hadoop HDFS--工作机制--下载文件流程（读文件流程）</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921162905659.png" alt="image-20210921162905659.png"><source media="(max-width:480px)" srcset="/img/optimized/B6iwSfqegE-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/B6iwSfqegE-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/B6iwSfqegE-698.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/B6iwSfqegE-698.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921162905659.png" alt="image-20210921162905659.png" width=""></picture></p>
<hr>
<h4 id="11-hadoop-hdfs-nn-dn" tabindex="-1">知识点11：Hadoop HDFS--工作机制--NN和DN之间的通信机制</h4>
<ul>
<li>
<p>dn启动时</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#datanode向nameNode进行注册">#datanode向nameNode进行注册</a> 并行汇报自己持有数据块信息

注册表示自己启动成功 汇报是高速namenode自己保存了哪些数据块
</code></pre>
</li>
<li>
<p>dn后续工作时</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#心跳机制">#心跳机制</a>
datanode每隔3S向namenode进行心跳 目的:报活   dfs.heartbeat.interval

<a class="tag" onclick="toggleTagSearch(this)" data-content="#数据块汇报机制">#数据块汇报机制</a> blockreport
datanode每隔6小时向nameNode进行数据块汇报自己数据块信息 dfs.blockreport.intervalMsec
</code></pre>
</li>
</ul>
<hr>
<h4 id="12-hadoop-hdfs-distcp-archive" tabindex="-1">知识点12：Hadoop HDFS--辅助工具（distcp、archive）</h4>
<p>12.1、跨集群复制数据 distcp（distributed copy）</p>
<ul>
<li>
<p>功能：实现在不同的hadoop集群之间进行数据复制同步。</p>
</li>
<li>
<p>用法：</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#同一个集群内">#同一个集群内</a> 复制操作
hadoop fs -cp /zookeeper.out /itcast

<a class="tag" onclick="toggleTagSearch(this)" data-content="#跨集群复制操作">#跨集群复制操作</a>
hadoop distcp hdfs://node1:8020/1.txt  hdfs:node5:8020/itcast
</code></pre>
</li>
</ul>
<p>12.2、文件归档工具 archive</p>
<ul>
<li>
<p>背景</p>
<pre><code>hdfs的架构设计不适合小文件存储的。
因为小文件不管多小 都需要一定的元数据记录它 元数据保存在内存中的，
如果集群小文件过多 就会造成内存被撑爆。 俗称 小文件吃内存。
</code></pre>
</li>
<li>
<p>archive功能</p>
<ul>
<li>将一批小文件归档一个档案文件。</li>
<li>底层是通过<mark>MapReduce程序将小文件进行合并的。启动yarn集群执行mr程序</mark>。</li>
<li>企业中可以根据时间 定时进行归档，比如一周创建一个档案。</li>
</ul>
<p>![image-20210921163445944](/img/user/czc知识库/计算机/Hadoop技术栈/资料讲义/源/day03--Hadoop HDFS/1、笔记、总结/hadoop离线day03--Hadoop HDFS.assets/image-20210921163445944.png)</p>
</li>
<li>
<p>使用</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#创建档案">#创建档案</a>
hadoop archive -archiveName test.har -p /small /outputdir

基于自己的需求 删除小文件 减少对内存的消耗
hadoop fs -rm /small/*

<a class="tag" onclick="toggleTagSearch(this)" data-content="#查看档案文件">#查看档案文件</a> --归档之后的样子
[root@node1 ~]# hadoop fs -ls hdfs://node1:8020/outputdir/test.har
Found 4 items
hdfs://node1:8020/outputdir/test.har/_SUCCESS
hdfs://node1:8020/outputdir/test.har/_index
hdfs://node1:8020/outputdir/test.har/_masterindex
hdfs://node1:8020/outputdir/test.har/part-0

<a class="tag" onclick="toggleTagSearch(this)" data-content="#查看档案文件">#查看档案文件</a> --归档之前的样子
[root@node1 ~]# hadoop fs -ls har://hdfs-node1:8020/outputdir/test.har
Found 3 items
 har://hdfs-node1:8020/outputdir/test.har/1.txt
 har://hdfs-node1:8020/outputdir/test.har/2.txt
 har://hdfs-node1:8020/outputdir/test.har/3.txt

<a class="tag" onclick="toggleTagSearch(this)" data-content="#从档案文件中提取文件">#从档案文件中提取文件</a>
[root@node1 ~]# hadoop fs -cp har://hdfs-node1:8020/outputdir/test.har/* /small/
[root@node1 ~]# hadoop fs -ls /small
Found 3 items
-rw-r--r--   3 root supergroup          2 2021-05-24 17:58 /small/1.txt
-rw-r--r--   3 root supergroup          2 2021-05-24 17:58 /small/2.txt
-rw-r--r--   3 root supergroup          2 2021-05-24 17:58 /small/3.txt
</code></pre>
</li>
<li>
<p>注意</p>
<ul>
<li>archive没有压缩的功能 就是简单的<mark>合二为一的操作 减少小文件个数</mark>。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="13-hadoop-hdfs-namenode" tabindex="-1">知识点13：Hadoop HDFS--namenode 安全模式</h4>
<ul>
<li>
<p>安全模式（safe mode）是HDFS集群处于一种保护状态，<mark>文件系统只可以读，不可以写</mark>。</p>
</li>
<li>
<p>安全模式如何进入离开的？</p>
<ul>
<li>
<p>自动进入离开</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#在HDFS集群刚启动时候">#在HDFS集群刚启动时候</a> 会自动进入 为了演示方便  使用单个进程逐个启动方式

<a class="tag" onclick="toggleTagSearch(this)" data-content="#step1：启动namenode">#step1：启动namenode</a>
hadoop-daemon.sh start namenode

<a class="tag" onclick="toggleTagSearch(this)" data-content="#step2">#step2</a>: 执行事务性操作 报错
[root@node1 ~]# hadoop fs -mkdir /aaaa
mkdir: Cannot create directory /aaaa. Name node is in safe mode.

Safe mode is ON. The reported blocks 0 needs additional 52 blocks to reach the threshold 0.9990 of total blocks 52. The number of live datanodes 0 has reached the minimum number 0. Safe mode will be turned off automatically once the thresholds have been reached.

<a class="tag" onclick="toggleTagSearch(this)" data-content="#1、条件1">#1、条件1</a>:已经汇报的block达到总数据块的 0.999
<a class="tag" onclick="toggleTagSearch(this)" data-content="#2、条件2">#2、条件2</a>:存活的dn数量大于等于0  说明这个条件不严格


<a class="tag" onclick="toggleTagSearch(this)" data-content="#step3">#step3</a>:依次手动启动datanode
hadoop-daemon.sh start datanode

Safe mode is ON. The reported blocks 52 has reached the threshold 0.9990 of total blocks 52. The number of live datanodes 2 has reached the minimum number 0. In safe mode extension. Safe mode will be turned off automatically in 25 seconds.
<a class="tag" onclick="toggleTagSearch(this)" data-content="#3、条件3">#3、条件3</a>:满足12条件的情况下 持续30s 结束自动离开安全模式

Safemode is off.


<a class="tag" onclick="toggleTagSearch(this)" data-content="#为什么集群刚启动的时候">#为什么集群刚启动的时候</a> 要进入安全模式 
文件系统元数据不完整 无法对外提供可高的文件服务  属于内部的元数据汇报、校验、构建的过程。

</code></pre>
</li>
<li>
<p>手动进入离开</p>
<pre><code class="language-shell">hdfs dfsadmin -safemode enter
hdfs dfsadmin -safemode leave

Safe mode is ON. It was turned on manually. Use &quot;hdfs dfsadmin -safemode leave&quot; to turn safe mode off.

<a class="tag" onclick="toggleTagSearch(this)" data-content="#运维人员可以手动进入安全模式">#运维人员可以手动进入安全模式</a> 进行集群的维护升级等动作 避免了群起群停浪费时间。
</code></pre>
</li>
</ul>
</li>
<li>
<p>安全模式的注意事项</p>
<ul>
<li>刚启动完hdfs集群之后 等安全模式介绍才可以正常使用文件系统 文件系统服务才是正常可用。</li>
<li>后续如果某些软件依赖HDFS工作，必须先启动HDFS且等安全模式结束才可以使用你的软件。</li>
<li>启动--&gt;启动成功--&gt;<mark>可用</mark>（安全模式结束）</li>
</ul>
</li>
</ul>
<hr>
<h4 id="14-hadoop-hdfs-namenode" tabindex="-1">知识点14：Hadoop HDFS--namenode元数据管理机制--整体概述</h4>
<ul>
<li>
<p>元数据</p>
<pre><code class="language-shell">元数据（Metadata），又称中介数据、中继数据，为描述数据的数据（data about data），主要是描述数据属性（property）的信息，用来支持如指示存储位置、历史数据、资源查找、文件记录等功能。

<a class="tag" onclick="toggleTagSearch(this)" data-content="#记录数据的数据">#记录数据的数据</a> 描述数据的数据
</code></pre>
</li>
<li>
<p>hdfs中元数据</p>
<ul>
<li><mark>文件系统的元数据</mark>（namespace、块的位置）</li>
<li>datanodes状态信息（健康、磁盘使用率）</li>
</ul>
</li>
<li>
<p>hdfs文件系统元数据存储位置</p>
<ul>
<li>内存中元数据</li>
<li>磁盘上元数据文件（fsimage edits log）</li>
</ul>
</li>
</ul>
<hr>
<h4 id="15-hadoop-hdfs-namenode" tabindex="-1">知识点15：Hadoop HDFS--namenode元数据相关目录文件</h4>
<ul>
<li>
<p>回想首次启动HDFS集群的时候 进行format操作</p>
<ul>
<li>
<p>本质就是初始化操作 初始化namenode工作目录和元数据文件。</p>
</li>
<li>
<p>元数据存储的目录由参数dfs.namenode.name.dir决定 在NN部署机器的本地linux文件系统中</p>
<pre><code>针对课程环境 最终目录

/export/data/hadoopdata/dfs/name
</code></pre>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="16-hadoop-hdfs-snn-checkpoint-secondary-name-node" tabindex="-1">知识点16：Hadoop HDFS--SNN概述和checkpoint，（SecondaryNameNode）</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921163622828.png" alt="image-20210921163622828.png"><source media="(max-width:480px)" srcset="/img/optimized/u0pj-ZHbP5-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/u0pj-ZHbP5-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/u0pj-ZHbP5-653.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/u0pj-ZHbP5-653.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921163622828.png" alt="image-20210921163622828.png" width=""></picture></p>
<ul>
<li>
<p>secondarynamenode要想成为namenode的备份 需要具备两个东西</p>
<ul>
<li>数据状态要和namenode保持一致。</li>
<li>承担和namenode一样的职责</li>
</ul>
</li>
<li>
<p><mark>secondarynamenode根本不是namenode的备份，其主要职责帮助nameNode进行元数据的合并</mark>。</p>
</li>
<li>
<p>checkpoint</p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921163636403.png" alt="image-20210921163636403.png"><source media="(max-width:480px)" srcset="/img/optimized/S-d8q4iYAR-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/S-d8q4iYAR-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/S-d8q4iYAR-643.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/S-d8q4iYAR-643.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day03--Hadoop%20HDFS/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday03--Hadoop%20HDFS.assets/image-20210921163636403.png" alt="image-20210921163636403.png" width=""></picture>checkpoint过程</p>
</li>
</ul>
<ol>
<li>namenode创建一个新的edits log，合并的时候客户端可以正常继续运行</li>
<li>将edits和fsimage发送给secondlynamenode机器</li>
<li>在secondlynamenode中，将fsimage加载到内存，</li>
<li>再把edits日志文件再执行一遍，数据合并完整</li>
<li>数据导出成新的镜像文件</li>
<li>新镜像文件发送到namenode</li>
</ol>
<p>我自己画的图：<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/3-HDFS_image-1.png" alt="3-HDFS_image-1.png"><source media="(max-width:480px)" srcset="/img/optimized/UFazIbmb6x-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/UFazIbmb6x-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/UFazIbmb6x-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/UFazIbmb6x-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/3-HDFS_image-1.png" alt="3-HDFS_image-1.png" width=""></picture></p>
<p>secondlynamenode所需内存和namenode一样多</p>
<p>默认参数：</p>
<ul>
<li>自动执行checkpoint的条件（默认参数）：100万次操作、一定时间后</li>
</ul>
<hr>
<h4 id="17-hadoop-hdfs" tabindex="-1">知识点17：Hadoop HDFS--元数据文件恢复方式</h4>
<ul>
<li>NameNode存储多目录</li>
<li>从SecondaryNameNode部分恢复</li>
</ul>
<hr>
<h4 id="今日作业" tabindex="-1">今日作业</h4>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#0、分布式文件系统应该具备哪些属性">#0、分布式文件系统应该具备哪些属性</a> 作用是什么
	分布式特性
	分块存储
	副本机制
	元数据记录
	抽象目录树
		符合人之常情  便于上手使用
	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#1、HDFS原理">#1、HDFS原理</a> 读写流程图  自己梳理。
	pipeline ack packet 3副本机制
	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#总结、概况nn">#总结、概况nn</a> dn角色职责
	分布式软件主从配合工作场景。
	大数据存储类软件都是这一个套路。 HBase Kafka ES

<a class="tag" onclick="toggleTagSearch(this)" data-content="#2、HDFS">#2、HDFS</a> shell基本操作

<a class="tag" onclick="toggleTagSearch(this)" data-content="#3、Archive">#3、Archive</a> 归档小文件
	面试：大数据如何处理小文件场景。HDFS   关键：合并
	上传前合并  在本地先把一批小文件合并成为大文件  python、java
	上传过程中合并 appendToFile 追加合并
	上传之后合并 archive 归档
	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#4、HDFS元数据管理机制">#4、HDFS元数据管理机制</a> SNN功能职责
	内存最新最全
	fsimage editslog
	SNN是NN的备份吗？！！
		是帮助NN合并元数据文件。保证不旧  不大  性能不受影响

<a class="tag" onclick="toggleTagSearch(this)" data-content="#5、HDFS安全模式是什么">#5、HDFS安全模式是什么</a> 
</code></pre>
</main>
<aside>
<div class="sidebar">
<div class="sidebar-container">
<div class="toc">
<div class="toc-title-container">
<div class="toc-title">
On this page
</div>
</div>
<div class="toc-container">
<nav class="toc">
<ol>
<li><a href="#hadoop-day03-hadoop-hdfs">hadoop离线day03--Hadoop HDFS</a>
<ol>
<li><a href="#今日课程学习目标">今日课程学习目标</a>
</li>
<li><a href="#今日课程内容大纲">今日课程内容大纲</a>
</li>
<li><a href="#01">知识点01：传统文件系统及其面临的挑战</a>
</li>
<li><a href="#02">知识点02：分布式文件存储系统核心特性与作用</a>
</li>
<li><a href="#03-hadoop-hdfs">知识点03：Hadoop HDFS--简介</a>
</li>
<li><a href="#04-hadoop-hdfs-strong-strong">知识点04：Hadoop HDFS--起源发展和设计目标</a>
</li>
<li><a href="#05-hadoop-hdfs">知识点05：Hadoop HDFS--核心重要特性解读</a>
</li>
<li><a href="#06-hadoop-hdfs-shell">知识点06：Hadoop HDFS--shell 操作--命令行功能及使用说明</a>
</li>
<li><a href="#07-hadoop-hdfs-shell">知识点07：Hadoop HDFS--shell 操作--常见命令操作</a>
</li>
<li><a href="#08-hadoop-hdfs">知识点08：Hadoop HDFS--工作机制--角色与角色职责</a>
</li>
<li><a href="#09-hadoop-hdfs">知识点09：Hadoop HDFS--工作机制--上传文件流程（写文件流程）</a>
</li>
<li><a href="#10-hadoop-hdfs">知识点10：Hadoop HDFS--工作机制--下载文件流程（读文件流程）</a>
</li>
<li><a href="#11-hadoop-hdfs-nn-dn">知识点11：Hadoop HDFS--工作机制--NN和DN之间的通信机制</a>
</li>
<li><a href="#12-hadoop-hdfs-distcp-archive">知识点12：Hadoop HDFS--辅助工具（distcp、archive）</a>
</li>
<li><a href="#13-hadoop-hdfs-namenode">知识点13：Hadoop HDFS--namenode 安全模式</a>
</li>
<li><a href="#14-hadoop-hdfs-namenode">知识点14：Hadoop HDFS--namenode元数据管理机制--整体概述</a>
</li>
<li><a href="#15-hadoop-hdfs-namenode">知识点15：Hadoop HDFS--namenode元数据相关目录文件</a>
</li>
<li><a href="#16-hadoop-hdfs-snn-checkpoint-secondary-name-node">知识点16：Hadoop HDFS--SNN概述和checkpoint，（SecondaryNameNode）</a>
</li>
<li><a href="#17-hadoop-hdfs">知识点17：Hadoop HDFS--元数据文件恢复方式</a>
</li>
<li><a href="#今日作业">今日作业</a>
</li>
</ol>
</li>
</ol>
</nav>
</div>
</div>
<div class="backlinks">
<div class="backlink-title" style="margin:4px 0!important">Pages mentioning this page</div>
<div class="backlink-list"><div class="backlink-card"><i icon-name="link"></i><a href="/czc知识库/计算机/Hadoop技术栈/Hadoop技术栈/" data-note-icon="" class="backlink">Hadoop技术栈</a>
</div></div>
</div>
</div>
</div>
</aside>
<style>#tooltip-wrapper{background:var(--background-primary);padding:1em;border-radius:4px;overflow:hidden;position:fixed;width:80%;max-width:400px;height:auto;max-height:300px;font-size:.8em;box-shadow:0 5px 10px rgba(0,0,0,.1);opacity:0;transition:opacity .1s;unicode-bidi:plaintext;overflow-y:scroll;z-index:10}#tooltip-wrapper:after{content:"";position:absolute;z-index:1;bottom:0;left:0;pointer-events:none;width:100%;unicode-bidi:plaintext;height:75px}</style>
<div style="opacity:0;display:none" id="tooltip-wrapper">
<div id="tooltip-content">
</div>
</div>
<iframe style="display:none;height:0;width:0" id="link-preview-iframe" src="">
</iframe>
<script>var opacityTimeout,contentTimeout,transitionDurationMs=100,iframe=document.getElementById("link-preview-iframe"),tooltipWrapper=document.getElementById("tooltip-wrapper"),tooltipContent=document.getElementById("tooltip-content"),linkHistories={};function hideTooltip(){opacityTimeout=setTimeout((function(){tooltipWrapper.style.opacity=0,contentTimeout=setTimeout((function(){tooltipContent.innerHTML="",tooltipWrapper.style.display="none"}),transitionDurationMs+1)}),transitionDurationMs)}function showTooltip(t){var e=t.target,o=e.getClientRects()[e.getClientRects().length-1],i=window.pageYOffset||document.documentElement.scrollTop,n=t.target.getAttribute("href");if(-1===n.indexOf("http")||-1!==n.indexOf(window.location.host)){let t=n.split("#")[0];linkHistories[t]?(tooltipContent.innerHTML=linkHistories[t],tooltipWrapper.style.display="block",setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)):(iframe.src=t,iframe.onload=function(){tooltipContentHtml="",tooltipContentHtml+='<div style="font-weight: bold; unicode-bidi: plaintext;">'+iframe.contentWindow.document.querySelector("h1").innerHTML+"</div>",tooltipContentHtml+=iframe.contentWindow.document.querySelector(".content").innerHTML,tooltipContent.innerHTML=tooltipContentHtml,linkHistories[t]=tooltipContentHtml,tooltipWrapper.style.display="block",tooltipWrapper.scrollTop=0,setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),console.log(e),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)}),tooltipWrapper.style.left=o.left-tooltipWrapper.offsetWidth/2+o.width/2+"px",window.innerHeight-o.top<tooltipWrapper.offsetHeight?tooltipWrapper.style.top=o.top+i-tooltipWrapper.offsetHeight-10+"px":window.innerHeight-o.top>tooltipWrapper.offsetHeight&&(tooltipWrapper.style.top=o.top+i+35+"px"),o.left+o.width/2<tooltipWrapper.offsetWidth/2?tooltipWrapper.style.left="10px":document.body.clientWidth-o.left-o.width/2<tooltipWrapper.offsetWidth/2&&(tooltipWrapper.style.left=document.body.clientWidth-tooltipWrapper.offsetWidth-20+"px")}}function setupListeners(t){t.addEventListener("mouseleave",(function(t){hideTooltip()})),tooltipWrapper.addEventListener("mouseleave",(function(t){hideTooltip()})),t.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout),showTooltip(t)})),tooltipWrapper.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout)}))}window.addEventListener("load",(function(t){document.querySelectorAll(".internal-link").forEach(setupListeners),document.querySelectorAll(".backlink-card a").forEach(setupListeners)}))</script>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
