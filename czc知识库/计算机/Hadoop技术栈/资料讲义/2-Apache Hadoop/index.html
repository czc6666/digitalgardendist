<!doctype html>
<html lang="zh-CN">
<head>
<title>2-Apache Hadoop</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.74516f71.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
<style></style>
</head>
<body class="theme-light markdown-preview-view markdown-rendered markdown-preview-section css-settings-manager mod-windows is-frameless is-maximized is-hidden-frameless is-focused obsidian-app theme-light show-inline-title show-ribbon show-view-header css-settings-manager theme-default line-style-solid folder-default blockquote-normal callout-normal checkbox-default tag-default link-default heading-default responsive-tile-height oz-show-all-num">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">czc&#39;s digital garden</h1>
</a>
</div>
<div class="search-button align-icon" onclick="toggleSearch()">
<span class="search-icon">
<i icon-name="search"></i>
</span>
<span class="search-text">
<span>Search</span>
<span style="font-size:.6rem;padding:2px 2px 0 6px;text-align:center;transform:translateY(4px)" class="search-keys">
CTRL + K
</span>
</span>
</div>
</nav>
<div class="search-container" id="globalsearch" onclick="toggleSearch()">
<div class="search-box">
<input type="search" id="term" placeholder="Start typing...">
<div id="search-results"></div>
<footer class="search-box-footer">
<div class="navigation-hint">
<span>Enter to select</span>
</div>
<div class="navigation-hint align-icon">
<i icon-name="arrow-up" aria-hidden="true"></i>
<i icon-name="arrow-down" aria-hidden="true"></i>
<span>to navigate</span>
</div>
<div class="navigation-hint">
<span>ESC to close</span>
</div>
</footer>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js"></script>
<script>document.addEventListener("DOMContentLoaded",init,!1),document.addEventListener("DOMContentLoaded",setCorrectShortcut,!1),window.toggleSearch=function(){document.getElementById("globalsearch").classList.contains("active")?document.getElementById("globalsearch").classList.remove("active"):(document.getElementById("globalsearch").classList.add("active"),document.getElementById("term").focus())},window.toggleTagSearch=function(e){console.log(e.textContent);const t=e.textContent;t&&(window.document.getElementById("term").value=t.trim(),window.toggleSearch(),window.search())};const loadingSvg='\n    <svg width="100" height="100" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg" stroke="#fff">\n      <g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2">\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="1.5s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="1.5s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="1.5s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="3s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="3s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="3s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="8">\n              <animate attributeName="r"\n                   begin="0s" dur="1.5s"\n                   values="6;1;2;3;4;5;6"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n      </g>\n  </svg>';function debounce(e,t,n){var a;return function(){var r=this,i=arguments,c=n&&!a;clearTimeout(a),a=setTimeout((function(){a=null,n||e.apply(r,i)}),t),c&&e.apply(r,i)}}function setCorrectShortcut(){navigator.platform.toUpperCase().indexOf("MAC")>=0&&document.querySelectorAll(".search-keys").forEach((e=>e.innerHTML="⌘ + K"))}function createIndex(e){const t=e=>e.toLowerCase().split(/([^a-z]|[^\x00-\x7F])/),n=new FlexSearch.Document({cache:!0,charset:"latin:extra",optimize:!0,index:[{field:"content",tokenize:"reverse",encode:t},{field:"title",tokenize:"forward",encode:t},{field:"tags",tokenize:"forward",encode:t}]});return e.forEach(((e,t)=>{n.add({id:t,title:e.title,content:e.content,tags:e.tags})})),n}async function init(){let e=!0;if(localStorage.getItem("searchIndex")){let{date:t,docs:n}=JSON.parse(localStorage.getItem("searchIndex"));if("2025-06-04T07:37:20.520Z"===t){e=!1;let t=createIndex(n);window.docs=n,window.index=t}}if(e){let e=await(await fetch("/searchIndex.json?v=2025-06-04T07:37:20.520Z")).json(),t=createIndex(e);localStorage.setItem("searchIndex",JSON.stringify({date:"2025-06-04T07:37:20.520Z",docs:e})),window.docs=e,window.index=t}document.addEventListener("keydown",(e=>{if((e.ctrlKey||e.metaKey)&&"k"===e.key&&(e.preventDefault(),toggleSearch()),"Escape"===e.key&&document.getElementById("globalsearch").classList.remove("active"),document.getElementById("globalsearch").classList.contains("active")){if("ArrowDown"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.nextElementSibling?t.nextElementSibling.classList.add("active"):document.querySelector(".searchresult").classList.add("active")):document.querySelector(".searchresult").classList.add("active");let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("ArrowUp"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.previousElementSibling?t.previousElementSibling.classList.add("active"):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling||e.classList.add("active")}))):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling&&e.classList.add("active")}));let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("Enter"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t&&(window.location.href=t.querySelector("a").href)}}}));const t=debounce(search,200,!1);field=document.querySelector("#term"),field.addEventListener("keydown",(e=>{"ArrowDown"!==e.key&&"ArrowUp"!==e.key&&t()})),resultsDiv=document.querySelector("#search-results");const n=new URL(location.href).searchParams;n.get("q")&&(field.setAttribute("value",n.get("q")),toggleSearch(),search())}async function search(){let e=field.value.trim();if(!e)return;if(e==lastSearch)return;console.log(`search for ${e}`),window.lastSearch=e,resultsDiv.innerHTML=loadingSvg;let t=offlineSearch(e),n="";if(!t.length){let t=document.createElement("p");return t.innerText=`No results for "${e}"`,resultsDiv.innerHTML="",void resultsDiv.appendChild(t)}n+='<div style="max-width:100%;">',t.forEach((e=>{e.tags&&e.tags.length>0?n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        <div class="header-meta">\n                            <div class="header-tags">\n                                ${e.tags.map((e=>'<a class="tag" href="JavaScript:Void(0);">#'+e+"</a>")).join("")}\n                            </div>\n                        </div>\n                        ${e.content}\n                    </div>\n                </div>`:n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        ${e.content}\n                    </div>\n                </div>`})),n+="</div>",resultsDiv.innerHTML=n}function truncate(e,t){return(e=e.replaceAll(/<[^>]*>/g,"")).length<t?e:e.substring(0,t-3)+"..."}function offlineSearch(e){let t=window.docs,n="#"===e[0]&&e.length>1?index.search(e.substring(1),[{field:"tags"}]):index.search(e,[{field:"title",limit:5},{field:"content",weight:10}]);const a=e=>{const t=n.filter((t=>t.field===e));return 0===t.length?[]:[...t[0].result]};return[...new Set([...a("title"),...a("content"),...a("tags")])].map((e=>{let n=t[e];return n.content=truncate(n.content,400),n.tags=n.tags.filter((e=>"gardenEntry"!=e&&"note"!=e)),n}))}window.lastSearch=""</script>
<main class="content cm-s-obsidian">
<header>
<h1 data-note-icon="">2-Apache Hadoop</h1>
<div class="header-meta">
<div class="header-tags">
</div>
<div class="timestamps"><div><i icon-name="calendar-plus"></i> <span class="human-date" data-date="2025-02-28T17:45:54.430+08:00"></span></div><div><i icon-name="calendar-clock"></i> <span class="human-date" data-date="2025-03-09T19:47:41.173+08:00"></span></div></div></div>
</header>
<h3 id="hadoop-day02-apache-hadoop" tabindex="-1">hadoop离线day02--Apache Hadoop</h3>
<hr>
<h4 id="今日课程学习目标" tabindex="-1">今日课程学习目标</h4>
<pre><code>了解Hadoop发展历史、生态圈
掌握Hadoop集群架构、角色
掌握Hadoop集群分布式安装部署
掌握Job HistoryServer功能
理解HDFS垃圾桶机制
</code></pre>
<h4 id="今日课程内容大纲" tabindex="-1">今日课程内容大纲</h4>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#Apache">#Apache</a> Hadoop入门
	介绍概念  
		狭义上hadoop指什么  指软件
        广义上hadoop指什么  指生态圈
	hadoop起源
	hadoop特性优点
<a class="tag" onclick="toggleTagSearch(this)" data-content="#Apache">#Apache</a> Hadoop搭建
	hadoop集群：主从架构
		分为两个集群，两个集群物理上在一起，逻辑上分离
			hdfs集群 
			yarn集群
	集群角色 集群规划
    集群配置
    format初始化
    启停脚本
    webUI页面
	hadoop初体验   现象与疑惑 后续学习方向
<a class="tag" onclick="toggleTagSearch(this)" data-content="#Apache">#Apache</a> hadoop辅助功能
	jobhistory服务 查看历史执行记录
	文件系统垃圾桶机制 回收站
</code></pre>
<hr>
<h4 id="01-apache-hadoop" tabindex="-1">知识点01：Apache Hadoop--概述与起源发展</h4>
<p>1.1、Hadoop介绍</p>
<ul>
<li>
<p>狭义上：hadoop指的是Apache一款java开源软件，是一个大数据分析处理平台。</p>
<ul>
<li>
<p>Hadoop <mark>HDFS：分布式文件系统</mark>。 解决了海量数据存储问题。</p>
<pre><code>Hadoop Distributed File System (HDFS™)
</code></pre>
</li>
<li>
<p>Hadoop <mark>MapReduce：分布式计算框架</mark>。解决海量数据计算问题。</p>
<pre><code>parallel processing of large data sets.
</code></pre>
</li>
<li>
<p>Hadoop <mark>YARN：集群资源管理和任务调度</mark>。</p>
<pre><code class="language-shell">A framework for job scheduling and cluster resource management.

<a class="tag" onclick="toggleTagSearch(this)" data-content="#资源指的是和程序运行相关的硬件资源">#资源指的是和程序运行相关的硬件资源</a>
cpu ram内存

<a class="tag" onclick="toggleTagSearch(this)" data-content="#任务调度">#任务调度</a>
集群资源繁忙的时候 如何分配资源给各个程序  调度
调度的关键是策略：先来后到  权重
</code></pre>
</li>
</ul>
</li>
<li>
<p>广义上：Hadoop指的是<mark>hadoop生态圈</mark>。</p>
<pre><code>提供了大数据的几乎所有软件。
采集、存储、导入、分析、挖掘、可视化、管理...
</code></pre>
</li>
</ul>
<p>1.2、Hadoop起源发展</p>
<ul>
<li>
<p>Hadoop之父--<mark>Doug Cutting</mark> 卡大爷</p>
</li>
<li>
<p>起源项目Apache Nutch。 致力于构建一个<mark>全网搜索引擎</mark>。</p>
<pre><code>1、爬取互联网网页 ---&gt;存储在哪里？ 海量数据存储问题

2、基于网页创建倒排索引。---&gt;如何计算？  海量数据计算问题
</code></pre>
</li>
<li>
<p>Google也在做搜索，也遇到这些问题，内部解决了。</p>
<ul>
<li>
<p><mark>google</mark>不想开源软件，但是又憋的难受，怕被人不知道，写论文发表。</p>
</li>
<li>
<p>前后写了<mark>3篇论文</mark>（谷歌是使用c实现的）。</p>
<pre><code>谷歌分布式文件系统（GFS）------&gt;HDFS
谷歌版MapReduce 系统------&gt;Hadoop MapReduce
bigtable----&gt;HBase
</code></pre>
</li>
<li>
<p>基于论文的影响 Nutch团队实现了相应的java版本开源组件。</p>
</li>
</ul>
</li>
<li>
<p>Nutch团队把HDFS和MapReduce抽取独立成为单独软件在<mark>2008年贡献给了Apache</mark>。开源。</p>
</li>
<li>
<p>Doug Cutting 看到他儿子在牙牙学语时，抱着黄色小象，亲昵的叫hadoop，他灵光一闪，就把这技术命名为 Hadoop，而且还用了黄色小象作为标示 Logo。</p>
</li>
</ul>
<hr>
<h4 id="02-apache-hadoop" tabindex="-1">知识点02：Apache Hadoop--特性优点（分布式、通用、简单易用）</h4>
<ul>
<li>
<p><mark>分布式、扩容能力</mark></p>
<pre><code>不再注重单机能力 看中的是集群的整体能力。
动态扩容、缩容。
</code></pre>
</li>
<li>
<p><mark>成本低</mark></p>
<pre><code>在集群下 单机成本很低 可以是普通服务器组成集群
意味着大数据处理不一定需要超级计算机。
</code></pre>
</li>
<li>
<p><mark>高效率 并发能力</mark></p>
</li>
<li>
<p><mark>可靠性</mark></p>
</li>
<li>
<p><strong><mark>通用性</mark></strong></p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#技术是相同的">#技术是相同的</a> 业务不相同的
<a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop精准区分技术和业务。">#hadoop精准区分技术和业务。</a>

做什么?(what need to do)----&gt;业务问题（20%）
怎么做?(how to do)-----&gt;技术问题（80%）

Hadoop把技术实现了 用户负责业务问题。

原来大数据这么简单 可以这么玩。
</code></pre>
</li>
</ul>
<hr>
<h4 id="03-apache-hadoop" tabindex="-1">知识点03：Apache Hadoop--发行版本与自身版本发展</h4>
<p>3.1、发行版本</p>
<ul>
<li>
<p><mark>官方社区版本</mark> Apache基金会官方</p>
<ul>
<li>版本新 功能最全的</li>
<li>不稳定 兼容性需要测试 bug多</li>
</ul>
</li>
<li>
<p><mark>商业版本</mark> 商业公司在官方版本之上进行商业化发行。著名：<mark>Cloudera</mark>、hotonWorks、MapR</p>
<ul>
<li>
<p>稳的一批 兼容性极好 技术支持 本地化支持 一键在线安装</p>
</li>
<li>
<p>版本不一定是最新的 辅助工具软件需要收费</p>
<pre><code>Cloudera发行的hadoop生态圈软件叫做CDH版本。
Cloudera’s Distribution Including Apache Hadoop。

https://www.cloudera.com/products/open-source/apache-hadoop/key-cdh-components.html

Hortonworks Data Platform (HDP)
</code></pre>
</li>
</ul>
</li>
<li>
<p>本课程中 使用的是<mark>Apache 3.3.0</mark>版本。</p>
</li>
</ul>
<p>3.2、Hadoop本身版本变化</p>
<ul>
<li>
<p>hadoop 1.x</p>
<pre><code>只有hdfs mapreduce. 架构过于垃圾 性能不高 当下企业中没人使用了。
</code></pre>
</li>
<li>
<p><mark>hadoop 2.x</mark></p>
<pre><code>hdfs  MapReduce  yarn.
</code></pre>
</li>
</ul>
<p>HDFS：分布式文件系统：解决海量数据存储问题<br>
MapReduce：分布式计算框架：解决海量数据计算问题<br>
yarn：分布式集群资源管理系统：分配硬件资源给程序、调度任务</p>
<ul>
<li>
<p>hadoop 3.x</p>
<pre><code>架构和2一样 性能做了优化
</code></pre>
</li>
</ul>
<hr>
<h4 id="04-apache-hadoop" tabindex="-1">知识点04：Apache Hadoop--集群架构与集群角色介绍</h4>
<ul>
<li>通常是有<mark>hdfs集群</mark>和<mark>yarn集群</mark>组成。两个集群都是标准的<mark>主从架构</mark>集群。</li>
<li>hdfs和yarn两个集群<strong>逻辑上分离 物理上在一起</strong>。</li>
<li>HDFS集群：解决了海量数据存储 分布式存储系统
<ul>
<li>主角色：namenode（NN）</li>
<li>从角色：datanode（DN）</li>
<li>主角色辅助角色&quot;秘书角色&quot;：secondarynamenode （SNN）</li>
</ul>
</li>
<li>YARN集群：集群资源管理 任务调度
<ul>
<li>主角色：resourcemanager（RM）</li>
<li>从角色：nodemanager（NM）</li>
</ul>
</li>
</ul>
<blockquote>
<p><mark>物理层面上只有HDFS和yarn集群，MapReduce集群是代码层面的</mark></p>
</blockquote>
<hr>
<h4 id="05-apache-hadoop-hadoop" tabindex="-1">知识点05：Apache Hadoop--集群部署--Hadoop安装部署模式</h4>
<ul>
<li>
<p>单机模式 Standalone</p>
<pre><code>一台机器，所有的角色在一个java进程中运行。 适合体验。
</code></pre>
</li>
<li>
<p>伪分布式</p>
<pre><code>一台机器 每个角色单独的java进程。 适合测试
</code></pre>
</li>
<li>
<p><mark>分布式 cluster</mark></p>
<pre><code>多台机器  每个角色运行在不同的机器上  生产测试都可以
</code></pre>
</li>
<li>
<p>高可用（持续可用）集群 HA</p>
<pre><code>在分布式的模式下 给主角色设置备份角色  实现了容错的功能 解决了单点故障
保证集群持续可用性。
</code></pre>
</li>
</ul>
<hr>
<h4 id="06-apache-hadoop" tabindex="-1">知识点06：Apache Hadoop--集群部署--了解源码编译</h4>
<blockquote>
<p><a href="https://archive.apache.org/dist/" target="_blank" class="external-link">https://archive.apache.org/dist/</a></p>
<p>Apache软件基金会的所有软件所有版本的下载地址.</p>
</blockquote>
<ul>
<li>
<p>源码下载地址</p>
<pre><code>https://archive.apache.org/dist/hadoop/common/

hadoop-3.3.0-src.tar.gz    source 源码包
hadoop-3.3.0.tar.gz        官方编译后安装包
</code></pre>
</li>
<li>
<p>对应java语言开发的项目软件来说，所谓的<mark>编译</mark>是什么？</p>
<pre><code>xxx.java(源码)----&gt;xxx.class(字节码)----&gt;jar包
</code></pre>
</li>
</ul>
<div class="callout" data-callout="note"><div class="callout-title"><div class="callout-title-inner"> <mark>正常来说，官方网站提供了安装包，可以直接使用，为什么要自己编译呢？</mark></div></div>
<div class="callout-content">
<p>
</p><ul>
<li><mark>修改源码</mark>之后需要重新编译。</li>
<li>官方提供的最大化编译 满足在各个平台运行，但是不一定彻底<mark>兼容本地库环境</mark>。</li>
<li>某些软件，官方只提供源码。</li>
</ul>
<p></p></div></div>
<pre><code>native library 本地库。
官方编译好的 Hadoop的安装包没有提供带 C程序访问的接口。主要是本地压缩支持、IO支持。
</code></pre>
<ul>
<li>
<p>怎么编译？</p>
<pre><code>在源码的根目录下有编译相关的文件BUILDING.txt 指导如何编译。
使用maven进行编译 联网jar.
</code></pre>
</li>
<li>
<p>可以使用课程提供编译好的安装包</p>
<pre><code class="language-shell">hadoop-3.3.0-Centos7-64-with-snappy.tar.gz
</code></pre>
</li>
</ul>
<hr>
<h4 id="07-apache-hadoop" tabindex="-1">知识点07：Apache Hadoop--集群部署--集群规划</h4>
<ul>
<li>
<p>Hadoop集群的规划</p>
<ul>
<li>
<p>根据<mark>软件和硬件的特性 合理的安排</mark>各个角色在不同的机器上。</p>
<ul>
<li>有冲突的尽量不部署在一起</li>
<li>有工作依赖尽量部署在一起</li>
<li>nodemanager 和datanode是基友</li>
</ul>
<pre><code class="language-properties">node1: namenode  datanode                    | resourcemanager  nodemanger
node2:			 datanode   secondarynamenode|			        nodemanger
node3:			 datanode                    |  		        nodemanger
</code></pre>
</li>
<li>
<p>Q：如果后续需要扩容hadoop集群，应该增加哪些角色呢？</p>
<pre><code class="language-properties">node4:  datanode  nodemanger
node5:  datanode  nodemanger
node6:  datanode  nodemanger
.....
</code></pre>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="08-apache-hadoop" tabindex="-1">知识点08：Apache Hadoop--集群部署--服务器基础环境准备</h4>
<blockquote>
<p>详细安装步骤参考课程资料：</p>
<p>《Python+大数据：hadoop离线阶段\02--Apache Hadoop\2、软件\hadoop-3.3.0\Hadoop3.3.0Linux编译安装.md》</p>
</blockquote>
<p>8.1、服务器基础环境准备</p>
<pre><code class="language-shell">ip、主机名
hosts映射 别忘了windows也配置
防火墙关闭
时间同步
免密登录  node1----&gt;node1 node2 node3
JDK安装
</code></pre>
<p>8.2、安装包目录结构</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#上传安装包到/export/server">#上传安装包到/export/server</a> 解压

 bin    <a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop核心脚本">#hadoop核心脚本</a> 最基础最底层脚本
 etc    <a class="tag" onclick="toggleTagSearch(this)" data-content="#配置目录">#配置目录</a>
 include
 lib
 libexec
 LICENSE.txt
 NOTICE.txt
 README.txt
 sbin  <a class="tag" onclick="toggleTagSearch(this)" data-content="#服务启动">#服务启动</a> 关闭 维护相关的脚本
 share <a class="tag" onclick="toggleTagSearch(this)" data-content="#官方自带实例">#官方自带实例</a>  hadoop相关依赖jar
</code></pre>
<hr>
<h4 id="09-apache-hadoop" tabindex="-1">知识点09：Apache Hadoop--集群部署--配置文件详解</h4>
<blockquote>
<p>官网文档：<a href="https://hadoop.apache.org/docs/r3.3.0/" target="_blank" class="external-link">https://hadoop.apache.org/docs/r3.3.0/</a></p>
</blockquote>
<ul>
<li>
<p>第一类 1个 <mark><strong><a href="http://hadoop-env.sh" target="_blank" class="external-link">hadoop-env.sh</a></strong></mark></p>
</li>
<li>
<p>第二类 4个 <mark>core|hdfs|mapred|yarn-site.xml</mark></p>
<blockquote>
<p>site表示的是用户定义的配置，会覆盖default中的默认配置。</p>
</blockquote>
<ul>
<li>
<p><mark>core-site.xml</mark> 核心模块配置</p>
</li>
<li>
<p><mark>hdfs-site.xml</mark> hdfs文件系统模块配置</p>
</li>
<li>
<p><mark>mapred-site.xml</mark> MapReduce模块配置</p>
</li>
<li>
<p><mark>yarn-site.xml</mark> yarn模块配置</p>
</li>
</ul>
</li>
<li>
<p>第三类 1个 <mark>workers</mark></p>
</li>
</ul>
<hr>
<h4 id="10-apache-hadoop-scp" tabindex="-1">知识点10：Apache Hadoop--集群部署--scp同步、环境变量配置</h4>
<ul>
<li>
<p>scp安装包到其他机器</p>
<pre><code class="language-shell">cd /export/server

scp -r hadoop-3.3.0 root@node2:$PWD
scp -r hadoop-3.3.0 root@node3:$PWD
</code></pre>
</li>
<li>
<p>Hadoop环境变量配置</p>
<pre><code class="language-shell">vim /etc/profile

export HADOOP_HOME=/export/server/hadoop-3.3.0
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin

source /etc/profile

<a class="tag" onclick="toggleTagSearch(this)" data-content="#别忘了">#别忘了</a> scp环境变量给其他两台机器哦
</code></pre>
</li>
</ul>
<hr>
<h4 id="11-apache-hadoop-namenode-format" tabindex="-1">知识点11：Apache Hadoop--集群部署--namenode format操作</h4>
<ul>
<li>
<p>format准确来说翻译成为<mark>初始化</mark>比较好。对namenode工作目录、初始文件进行生成。</p>
</li>
<li>
<p>通常在namenode所在的机器执行 <mark>执行一次。首次启动之前</mark></p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#在node1">#在node1</a> 部署namenode的这台机器上执行

hadoop namenode -format

<a class="tag" onclick="toggleTagSearch(this)" data-content="#执行成功">#执行成功</a> 日志会有如下显示
21/05/23 15:38:19 INFO common.Storage: Storage directory /export/data/hadoopdata/dfs/name has been successfully formatted.

[root@node1 server]# ll /export/data/hadoopdata/dfs/name/current/
total 16
-rw-r--r-- 1 root root 321 May 23 15:38 fsimage_0000000000000000000
-rw-r--r-- 1 root root  62 May 23 15:38 fsimage_0000000000000000000.md5
-rw-r--r-- 1 root root   2 May 23 15:38 seen_txid
-rw-r--r-- 1 root root 207 May 23 15:38 VERSION
</code></pre>
</li>
<li>
<p>Q：如果不小心初始化了多次，如何？</p>
<ul>
<li>
<p>现象：主从之间互相不识别。</p>
</li>
<li>
<p>解决</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#企业真实环境中">#企业真实环境中</a>    枪毙

<a class="tag" onclick="toggleTagSearch(this)" data-content="#学习环境">#学习环境</a>
删除每台机器上hadoop.tmp.dir配置指定的文件夹/export/data/hadoop-3.3.0。 
重新format。
</code></pre>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="12-apache-hadoop" tabindex="-1">知识点12：Apache Hadoop--集群启停--命令与状态日志查看</h4>
<p>12.1、单节点单进程逐个手动启动</p>
<ul>
<li>
<p>HDFS集群</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop2">#hadoop2</a>.x版本命令
hadoop-daemon.sh start|stop  namenode|datanode|secondarynamenode

<a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop3">#hadoop3</a>.x版本命令
hdfs --daemon start|stop namenode|datanode|secondarynamenode
</code></pre>
</li>
<li>
<p>YARN集群</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop2">#hadoop2</a>.x版本命令
yarn-daemon.sh start|stop resourcemanager|nodemanager

<a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop3">#hadoop3</a>.x版本命令
yarn --daemon start|stop resourcemanager|nodemanager
</code></pre>
</li>
<li>
<p>优点：精准的控制每个角色每个进程的启停。避免了群起群停（时间成本）。</p>
</li>
</ul>
<p>12.2、脚本一键启动</p>
<ul>
<li>
<p>前提：<mark>配置好免密登录。ssh</mark></p>
<pre><code>ssh-copy-id node1.itcast.cn
ssh-copy-id node2.itcast.cn
ssh-copy-id node3.itcast.cn
</code></pre>
</li>
<li>
<p>HDFS集群</p>
<pre><code>start-dfs.sh 
stop-dfs.sh 
</code></pre>
</li>
<li>
<p>YARN集群</p>
<pre><code class="language-shell">start-yarn.sh
stop-yarn.sh
</code></pre>
</li>
<li>
<p>更狠的</p>
<pre><code class="language-shell">start-all.sh
stop-all.sh

[root@node1 ~]# start-all.sh 
This script is Deprecated. Instead use start-dfs.sh and start-yarn.sh
</code></pre>
</li>
</ul>
<p>12.3、集群进程确认和错误排查</p>
<ul>
<li>
<p>确认是否成功</p>
<pre><code class="language-shell">[root@node1 ~]# jps
8000 DataNode
8371 NodeManager
8692 Jps
8264 ResourceManager
7865 NameNode
</code></pre>
</li>
<li>
<p>如果进程不在 <mark>看启动运行日志！！！！！！！！！！！！！</mark></p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#默认情况下">#默认情况下</a> 日志目录
cd /export/server/hadoop-3.3.0/logs/

<a class="tag" onclick="toggleTagSearch(this)" data-content="#注意找到对应进程名字">#注意找到对应进程名字</a> 以log结尾的文件
</code></pre>
</li>
</ul>
<hr>
<h4 id="13-apache-hadoop-web-ui" tabindex="-1">知识点13：Apache Hadoop--Web UI页面</h4>
<ul>
<li>
<p>Hadoop Web UI页面</p>
<ul>
<li>HDFS集群 http://namenode_host:9870</li>
<li>YARN集群 http://resourcemanager_host:8088</li>
</ul>
<pre><code>http://node1:9870/dfshealth.html#tab-overview
</code></pre>
</li>
</ul>
<hr>
<h4 id="14-apache-hadoop" tabindex="-1">知识点14：Apache Hadoop--初体验</h4>
<p>14.1、初体验之HD<mark>FS</mark></p>
<ul>
<li>
<p>本质就是存储文件的 和标准文件系统一样吗？</p>
<ul>
<li>也是有目录树结构，也是从根目录开始的。</li>
<li>文件是文件、文件夹是文件夹（对于zk来说）</li>
<li>和linux很相似</li>
<li>上传小文件好慢。<mark>为什么慢？和分布式有没有关系？</mark></li>
</ul>
</li>
</ul>
<p>14.2、体验之MapReduce+yarn</p>
<ul>
<li>
<p>MapReduce是分布式程序 yarn是资源管理 给程序提供运算资源。 Connecting to ResourceManager</p>
<pre><code class="language-shell">[root@node1 mapreduce]# pwd
/export/server/hadoop-3.3.0/share/hadoop/mapreduce

hadoop jar hadoop-mapreduce-examples-3.3.0.jar pi  2 2
</code></pre>
</li>
<li>
<p>MR程序运行首先连接YRAN ResourceManager，连接它干什么的？<mark>要资源</mark>。</p>
</li>
<li>
<p>MR程序好像是两个阶段 ，<mark>先Map 再Reduce</mark>。</p>
</li>
<li>
<p>数据量这么小的情况下，为什么MR这么慢？ MR适合处理大数据场景还是小数据场景？</p>
</li>
</ul>
<hr>
<h4 id="15-apache-hadoop-jobhistory" tabindex="-1">知识点15：Apache Hadoop--jobhistory服务配置与功能</h4>
<ul>
<li>
<p>背景</p>
<ul>
<li>默认情况下，yarn上关于MapReduce程序执行历史信息、执行记录不会永久存储；一旦yarn集群重启 之前的信息就会消失。</li>
<li>MR程序分布式执行也不利于日志的集中查看，开启<strong>jobhistory服务</strong>再配合<strong>YARN日志聚集</strong>功能可以实现集中查询日志</li>
</ul>
</li>
<li>
<p>功能</p>
<pre><code>保存yarn上已经完成的MapReduce的执行信息。
</code></pre>
</li>
<li>
<p>配置</p>
<ul>
<li>
<p>因为需求修改配置。<mark>重启hadoop集群</mark>才能生效。</p>
</li>
<li>
<p>因为涉及配置文件的修改，需要集群每台机器都修改，并且在重启后生效</p>
<pre><code class="language-xml">vim mapred-site.xml

&lt;property&gt;
	&lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
	&lt;value&gt;node1:10020&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
	&lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
	&lt;value&gt;node1:19888&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>scp同步给其他机器</p>
<pre><code class="language-shell">scp /export/server/hadoop-3.3.0/etc/hadoop/mapred-site.xml node2:/export/server/hadoop-3.3.0/etc/hadoop/

scp /export/server/hadoop-3.3.0/etc/hadoop/mapred-site.xml node3:/export/server/hadoop-3.3.0/etc/hadoop/
</code></pre>
</li>
<li>
<p>重启hadoop集群</p>
</li>
<li>
<p>自己手动启停jobhistory服务。</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop2">#hadoop2</a>.x版本命令
mr-jobhistory-daemon.sh start|stop historyserver

<a class="tag" onclick="toggleTagSearch(this)" data-content="#hadoop3">#hadoop3</a>.x版本命令
mapred --daemon start|stop historyserver

[root@node1 ~]# jps
13794 JobHistoryServer
13060 DataNode
12922 NameNode
13436 NodeManager
13836 Jps
13327 ResourceManager
</code></pre>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="16-apache-hadoop-hdfs" tabindex="-1">知识点16：Apache Hadoop--HDFS垃圾桶机制</h4>
<ul>
<li>
<p>背景：垃圾桶在windows叫做回收站</p>
<pre><code class="language-shell">在默认情况下 hdfs没有垃圾桶 意味着删除操作直接物理删除文件。

[root@node1 ~]# hadoop fs -rm /itcast/1.txt
Deleted /itcast/1.txt
</code></pre>
</li>
<li>
<p>功能：和回收站一种 在删除数据的时候 先去垃圾桶 如果后悔可以复原。</p>
</li>
<li>
<p>配置</p>
<pre><code class="language-xml">在core-site.xml中开启垃圾桶机制

指定保存在垃圾桶的时间。单位分钟

&lt;property&gt;
	&lt;name&gt;fs.trash.interval&lt;/name&gt;
	&lt;value&gt;1440&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>集群同步配置 重启hadoop服务。</p>
<pre><code class="language-shell">[root@node1 hadoop]# pwd
/export/server/hadoop-3.3.0/etc/hadoop
[root@node1 hadoop]# scp core-site.xml node2:$PWD
core-site.xml                                              100% 1027   898.7KB/s   00:00    
[root@node1 hadoop]# scp core-site.xml node3:$PWD
core-site.xml 
</code></pre>
</li>
<li>
<p>垃圾桶使用</p>
<ul>
<li>
<p>配置好之后 再删除文件 直接进入垃圾桶</p>
<pre><code>[root@node1 ~]# hadoop fs -rm /itcast.txt
INFO fs.TrashPolicyDefault: Moved: 'hdfs://node1:8020/itcast.txt' to trash at: hdfs://node1:8020/user/root/.Trash/Current/itcast.txt
</code></pre>
</li>
</ul>
</li>
<li>
<p>垃圾桶的本质就是hdfs上的一个隐藏目录。</p>
<pre><code>  hdfs://node1:8020/user/用户名/.Trash/Current
</code></pre>
</li>
<li>
<p>后悔了 需要恢复怎么做？</p>
<pre><code>  hadoop fs -cp /user/root/.Trash/Current/itcast.txt /
</code></pre>
</li>
<li>
<p>就想直接删除文件怎么做？</p>
<pre><code class="language-shell">  hadoop fs -rm -skipTrash /itcast.txt
   
  [root@node1 ~]#  hadoop fs -rm -skipTrash /itcast.txt
  Deleted /itcast.txt
</code></pre>
</li>
</ul>
<hr>
<h4 id="今日作业" tabindex="-1">今日作业</h4>
<ul>
<li>复习讲义，课堂笔记</li>
<li>搭建Hadoop集群</li>
<li>预先Hadoop HDFS
<ul>
<li>本质就是文件系统 和linux很类似 学习成本使用成本很低</li>
<li>其次是分布式的文件系统 分布式使得它的底层原理特性很多。</li>
</ul>
</li>
</ul>
<hr>
<h4 id="hadoop" tabindex="-1">Hadoop配置文件参考</h4>
<ul>
<li>
<p><a href="http://hadoop-env.sh" target="_blank" class="external-link">hadoop-env.sh</a></p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#java">#java</a> home
export JAVA_HOME=/export/server/jdk1.8.0_241

<a class="tag" onclick="toggleTagSearch(this)" data-content="#Hadoop各个组件启动运行身份">#Hadoop各个组件启动运行身份</a>
export HDFS_NAMENODE_USER=root
export HDFS_DATANODE_USER=root
export HDFS_SECONDARYNAMENODE_USER=root
export YARN_RESOURCEMANAGER_USER=root
export YARN_NODEMANAGER_USER=root 
</code></pre>
</li>
<li>
<p>core-site.xml</p>
<pre><code class="language-xml">&lt;!-- 设置默认使用的文件系统 Hadoop支持file、HDFS、GFS、ali|Amazon云等文件系统 --&gt;
&lt;property&gt;
    &lt;name&gt;fs.defaultFS&lt;/name&gt;
    &lt;value&gt;hdfs://node1:8020&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 设置Hadoop本地保存数据路径 --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.tmp.dir&lt;/name&gt;
    &lt;value&gt;/export/data/hadoop-3.3.0&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 设置HDFS web UI用户身份 --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.http.staticuser.user&lt;/name&gt;
    &lt;value&gt;root&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 整合hive 用户代理设置 --&gt;
&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.root.hosts&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;hadoop.proxyuser.root.groups&lt;/name&gt;
    &lt;value&gt;*&lt;/value&gt;
&lt;/property&gt;
&lt;!-- 文件系统垃圾桶保存时间 单位：分 --&gt;
&lt;property&gt;
    &lt;name&gt;fs.trash.interval&lt;/name&gt;
    &lt;value&gt;1440&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>hdfs-site.xml</p>
<pre><code class="language-xml">&lt;!-- 设置SNN进程运行机器位置信息 --&gt;
&lt;property&gt;
    &lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
    &lt;value&gt;node2:9868&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>mapred-site.xml</p>
<pre><code class="language-xml">&lt;!-- 设置MR程序默认运行模式： yarn集群模式 local本地模式 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.framework.name&lt;/name&gt;
  &lt;value&gt;yarn&lt;/value&gt;
&lt;/property&gt;

&lt;!-- MR程序历史服务器端地址 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.jobhistory.address&lt;/name&gt;
  &lt;value&gt;node1:10020&lt;/value&gt;
&lt;/property&gt;
 
&lt;!-- 历史服务器web端地址 --&gt;
&lt;property&gt;
  &lt;name&gt;mapreduce.jobhistory.webapp.address&lt;/name&gt;
  &lt;value&gt;node1:19888&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;yarn.app.mapreduce.am.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;mapreduce.map.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
  &lt;name&gt;mapreduce.reduce.env&lt;/name&gt;
  &lt;value&gt;HADOOP_MAPRED_HOME=${HADOOP_HOME}&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>yarn-site.xml</p>
<pre><code class="language-xml">&lt;!-- 设置YARN集群主角色运行机器位置 --&gt;
&lt;property&gt;
	&lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;
	&lt;value&gt;node1&lt;/value&gt;
&lt;/property&gt;

&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;
    &lt;value&gt;mapreduce_shuffle&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 是否将对容器实施物理内存限制 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.pmem-check-enabled&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 是否将对容器实施虚拟内存限制。 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.nodemanager.vmem-check-enabled&lt;/name&gt;
    &lt;value&gt;false&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 开启日志聚集 --&gt;
&lt;property&gt;
  &lt;name&gt;yarn.log-aggregation-enable&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 设置yarn历史服务器地址 --&gt;
&lt;property&gt;
    &lt;name&gt;yarn.log.server.url&lt;/name&gt;
    &lt;value&gt;http://node1:19888/jobhistory/logs&lt;/value&gt;
&lt;/property&gt;

&lt;!-- 日志保存的时间 7天 --&gt;
&lt;property&gt;
  &lt;name&gt;yarn.log-aggregation.retain-seconds&lt;/name&gt;
  &lt;value&gt;604800&lt;/value&gt;
&lt;/property&gt;
</code></pre>
</li>
<li>
<p>workers</p>
<pre><code>node1.itcast.cn
node2.itcast.cn
node3.itcast.cn
</code></pre>
</li>
</ul>
</main>
<aside>
<div class="sidebar">
<div class="sidebar-container">
<div class="toc">
<div class="toc-title-container">
<div class="toc-title">
On this page
</div>
</div>
<div class="toc-container">
<nav class="toc">
<ol>
<li><a href="#hadoop-day02-apache-hadoop">hadoop离线day02--Apache Hadoop</a>
<ol>
<li><a href="#今日课程学习目标">今日课程学习目标</a>
</li>
<li><a href="#今日课程内容大纲">今日课程内容大纲</a>
</li>
<li><a href="#01-apache-hadoop">知识点01：Apache Hadoop--概述与起源发展</a>
</li>
<li><a href="#02-apache-hadoop">知识点02：Apache Hadoop--特性优点（分布式、通用、简单易用）</a>
</li>
<li><a href="#03-apache-hadoop">知识点03：Apache Hadoop--发行版本与自身版本发展</a>
</li>
<li><a href="#04-apache-hadoop">知识点04：Apache Hadoop--集群架构与集群角色介绍</a>
</li>
<li><a href="#05-apache-hadoop-hadoop">知识点05：Apache Hadoop--集群部署--Hadoop安装部署模式</a>
</li>
<li><a href="#06-apache-hadoop">知识点06：Apache Hadoop--集群部署--了解源码编译</a>
</li>
<li><a href="#07-apache-hadoop">知识点07：Apache Hadoop--集群部署--集群规划</a>
</li>
<li><a href="#08-apache-hadoop">知识点08：Apache Hadoop--集群部署--服务器基础环境准备</a>
</li>
<li><a href="#09-apache-hadoop">知识点09：Apache Hadoop--集群部署--配置文件详解</a>
</li>
<li><a href="#10-apache-hadoop-scp">知识点10：Apache Hadoop--集群部署--scp同步、环境变量配置</a>
</li>
<li><a href="#11-apache-hadoop-namenode-format">知识点11：Apache Hadoop--集群部署--namenode format操作</a>
</li>
<li><a href="#12-apache-hadoop">知识点12：Apache Hadoop--集群启停--命令与状态日志查看</a>
</li>
<li><a href="#13-apache-hadoop-web-ui">知识点13：Apache Hadoop--Web UI页面</a>
</li>
<li><a href="#14-apache-hadoop">知识点14：Apache Hadoop--初体验</a>
</li>
<li><a href="#15-apache-hadoop-jobhistory">知识点15：Apache Hadoop--jobhistory服务配置与功能</a>
</li>
<li><a href="#16-apache-hadoop-hdfs">知识点16：Apache Hadoop--HDFS垃圾桶机制</a>
</li>
<li><a href="#今日作业">今日作业</a>
</li>
<li><a href="#hadoop">Hadoop配置文件参考</a>
</li>
</ol>
</li>
</ol>
</nav>
</div>
</div>
<div class="backlinks">
<div class="backlink-title" style="margin:4px 0!important">Pages mentioning this page</div>
<div class="backlink-list"><div class="backlink-card"><i icon-name="link"></i><a href="/czc知识库/计算机/Hadoop技术栈/Hadoop技术栈/" data-note-icon="" class="backlink">Hadoop技术栈</a>
</div></div>
</div>
</div>
</div>
</aside>
<style>#tooltip-wrapper{background:var(--background-primary);padding:1em;border-radius:4px;overflow:hidden;position:fixed;width:80%;max-width:400px;height:auto;max-height:300px;font-size:.8em;box-shadow:0 5px 10px rgba(0,0,0,.1);opacity:0;transition:opacity .1s;unicode-bidi:plaintext;overflow-y:scroll;z-index:10}#tooltip-wrapper:after{content:"";position:absolute;z-index:1;bottom:0;left:0;pointer-events:none;width:100%;unicode-bidi:plaintext;height:75px}</style>
<div style="opacity:0;display:none" id="tooltip-wrapper">
<div id="tooltip-content">
</div>
</div>
<iframe style="display:none;height:0;width:0" id="link-preview-iframe" src="">
</iframe>
<script>var opacityTimeout,contentTimeout,transitionDurationMs=100,iframe=document.getElementById("link-preview-iframe"),tooltipWrapper=document.getElementById("tooltip-wrapper"),tooltipContent=document.getElementById("tooltip-content"),linkHistories={};function hideTooltip(){opacityTimeout=setTimeout((function(){tooltipWrapper.style.opacity=0,contentTimeout=setTimeout((function(){tooltipContent.innerHTML="",tooltipWrapper.style.display="none"}),transitionDurationMs+1)}),transitionDurationMs)}function showTooltip(t){var e=t.target,o=e.getClientRects()[e.getClientRects().length-1],i=window.pageYOffset||document.documentElement.scrollTop,n=t.target.getAttribute("href");if(-1===n.indexOf("http")||-1!==n.indexOf(window.location.host)){let t=n.split("#")[0];linkHistories[t]?(tooltipContent.innerHTML=linkHistories[t],tooltipWrapper.style.display="block",setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)):(iframe.src=t,iframe.onload=function(){tooltipContentHtml="",tooltipContentHtml+='<div style="font-weight: bold; unicode-bidi: plaintext;">'+iframe.contentWindow.document.querySelector("h1").innerHTML+"</div>",tooltipContentHtml+=iframe.contentWindow.document.querySelector(".content").innerHTML,tooltipContent.innerHTML=tooltipContentHtml,linkHistories[t]=tooltipContentHtml,tooltipWrapper.style.display="block",tooltipWrapper.scrollTop=0,setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),console.log(e),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)}),tooltipWrapper.style.left=o.left-tooltipWrapper.offsetWidth/2+o.width/2+"px",window.innerHeight-o.top<tooltipWrapper.offsetHeight?tooltipWrapper.style.top=o.top+i-tooltipWrapper.offsetHeight-10+"px":window.innerHeight-o.top>tooltipWrapper.offsetHeight&&(tooltipWrapper.style.top=o.top+i+35+"px"),o.left+o.width/2<tooltipWrapper.offsetWidth/2?tooltipWrapper.style.left="10px":document.body.clientWidth-o.left-o.width/2<tooltipWrapper.offsetWidth/2&&(tooltipWrapper.style.left=document.body.clientWidth-tooltipWrapper.offsetWidth-20+"px")}}function setupListeners(t){t.addEventListener("mouseleave",(function(t){hideTooltip()})),tooltipWrapper.addEventListener("mouseleave",(function(t){hideTooltip()})),t.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout),showTooltip(t)})),tooltipWrapper.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout)}))}window.addEventListener("load",(function(t){document.querySelectorAll(".internal-link").forEach(setupListeners),document.querySelectorAll(".backlink-card a").forEach(setupListeners)}))</script>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
