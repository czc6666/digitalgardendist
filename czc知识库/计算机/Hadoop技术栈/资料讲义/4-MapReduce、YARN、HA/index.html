<!doctype html>
<html lang="zh-CN">
<head>
<title>4-MapReduce、YARN、HA</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.74516f71.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
<style></style>
</head>
<body class="theme-light markdown-preview-view markdown-rendered markdown-preview-section css-settings-manager mod-windows is-frameless is-maximized is-hidden-frameless is-focused obsidian-app theme-light show-inline-title show-ribbon show-view-header css-settings-manager theme-default line-style-solid folder-default blockquote-normal callout-normal checkbox-default tag-default link-default heading-default responsive-tile-height oz-show-all-num">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">czc&#39;s digital garden</h1>
</a>
</div>
<div class="search-button align-icon" onclick="toggleSearch()">
<span class="search-icon">
<i icon-name="search"></i>
</span>
<span class="search-text">
<span>Search</span>
<span style="font-size:.6rem;padding:2px 2px 0 6px;text-align:center;transform:translateY(4px)" class="search-keys">
CTRL + K
</span>
</span>
</div>
</nav>
<div class="search-container" id="globalsearch" onclick="toggleSearch()">
<div class="search-box">
<input type="search" id="term" placeholder="Start typing...">
<div id="search-results"></div>
<footer class="search-box-footer">
<div class="navigation-hint">
<span>Enter to select</span>
</div>
<div class="navigation-hint align-icon">
<i icon-name="arrow-up" aria-hidden="true"></i>
<i icon-name="arrow-down" aria-hidden="true"></i>
<span>to navigate</span>
</div>
<div class="navigation-hint">
<span>ESC to close</span>
</div>
</footer>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js"></script>
<script>document.addEventListener("DOMContentLoaded",init,!1),document.addEventListener("DOMContentLoaded",setCorrectShortcut,!1),window.toggleSearch=function(){document.getElementById("globalsearch").classList.contains("active")?document.getElementById("globalsearch").classList.remove("active"):(document.getElementById("globalsearch").classList.add("active"),document.getElementById("term").focus())},window.toggleTagSearch=function(e){console.log(e.textContent);const t=e.textContent;t&&(window.document.getElementById("term").value=t.trim(),window.toggleSearch(),window.search())};const loadingSvg='\n    <svg width="100" height="100" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg" stroke="#fff">\n      <g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2">\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="1.5s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="1.5s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="1.5s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="3s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="3s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="3s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="8">\n              <animate attributeName="r"\n                   begin="0s" dur="1.5s"\n                   values="6;1;2;3;4;5;6"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n      </g>\n  </svg>';function debounce(e,t,n){var a;return function(){var r=this,i=arguments,c=n&&!a;clearTimeout(a),a=setTimeout((function(){a=null,n||e.apply(r,i)}),t),c&&e.apply(r,i)}}function setCorrectShortcut(){navigator.platform.toUpperCase().indexOf("MAC")>=0&&document.querySelectorAll(".search-keys").forEach((e=>e.innerHTML="⌘ + K"))}function createIndex(e){const t=e=>e.toLowerCase().split(/([^a-z]|[^\x00-\x7F])/),n=new FlexSearch.Document({cache:!0,charset:"latin:extra",optimize:!0,index:[{field:"content",tokenize:"reverse",encode:t},{field:"title",tokenize:"forward",encode:t},{field:"tags",tokenize:"forward",encode:t}]});return e.forEach(((e,t)=>{n.add({id:t,title:e.title,content:e.content,tags:e.tags})})),n}async function init(){let e=!0;if(localStorage.getItem("searchIndex")){let{date:t,docs:n}=JSON.parse(localStorage.getItem("searchIndex"));if("2025-06-04T07:37:20.520Z"===t){e=!1;let t=createIndex(n);window.docs=n,window.index=t}}if(e){let e=await(await fetch("/searchIndex.json?v=2025-06-04T07:37:20.520Z")).json(),t=createIndex(e);localStorage.setItem("searchIndex",JSON.stringify({date:"2025-06-04T07:37:20.520Z",docs:e})),window.docs=e,window.index=t}document.addEventListener("keydown",(e=>{if((e.ctrlKey||e.metaKey)&&"k"===e.key&&(e.preventDefault(),toggleSearch()),"Escape"===e.key&&document.getElementById("globalsearch").classList.remove("active"),document.getElementById("globalsearch").classList.contains("active")){if("ArrowDown"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.nextElementSibling?t.nextElementSibling.classList.add("active"):document.querySelector(".searchresult").classList.add("active")):document.querySelector(".searchresult").classList.add("active");let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("ArrowUp"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.previousElementSibling?t.previousElementSibling.classList.add("active"):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling||e.classList.add("active")}))):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling&&e.classList.add("active")}));let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("Enter"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t&&(window.location.href=t.querySelector("a").href)}}}));const t=debounce(search,200,!1);field=document.querySelector("#term"),field.addEventListener("keydown",(e=>{"ArrowDown"!==e.key&&"ArrowUp"!==e.key&&t()})),resultsDiv=document.querySelector("#search-results");const n=new URL(location.href).searchParams;n.get("q")&&(field.setAttribute("value",n.get("q")),toggleSearch(),search())}async function search(){let e=field.value.trim();if(!e)return;if(e==lastSearch)return;console.log(`search for ${e}`),window.lastSearch=e,resultsDiv.innerHTML=loadingSvg;let t=offlineSearch(e),n="";if(!t.length){let t=document.createElement("p");return t.innerText=`No results for "${e}"`,resultsDiv.innerHTML="",void resultsDiv.appendChild(t)}n+='<div style="max-width:100%;">',t.forEach((e=>{e.tags&&e.tags.length>0?n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        <div class="header-meta">\n                            <div class="header-tags">\n                                ${e.tags.map((e=>'<a class="tag" href="JavaScript:Void(0);">#'+e+"</a>")).join("")}\n                            </div>\n                        </div>\n                        ${e.content}\n                    </div>\n                </div>`:n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        ${e.content}\n                    </div>\n                </div>`})),n+="</div>",resultsDiv.innerHTML=n}function truncate(e,t){return(e=e.replaceAll(/<[^>]*>/g,"")).length<t?e:e.substring(0,t-3)+"..."}function offlineSearch(e){let t=window.docs,n="#"===e[0]&&e.length>1?index.search(e.substring(1),[{field:"tags"}]):index.search(e,[{field:"title",limit:5},{field:"content",weight:10}]);const a=e=>{const t=n.filter((t=>t.field===e));return 0===t.length?[]:[...t[0].result]};return[...new Set([...a("title"),...a("content"),...a("tags")])].map((e=>{let n=t[e];return n.content=truncate(n.content,400),n.tags=n.tags.filter((e=>"gardenEntry"!=e&&"note"!=e)),n}))}window.lastSearch=""</script>
<main class="content cm-s-obsidian">
<header>
<h1 data-note-icon="">4-MapReduce、YARN、HA</h1>
<div class="header-meta">
<div class="header-tags">
</div>
<div class="timestamps"><div><i icon-name="calendar-plus"></i> <span class="human-date" data-date="2025-02-28T17:45:55.531+08:00"></span></div><div><i icon-name="calendar-clock"></i> <span class="human-date" data-date="2025-03-11T22:53:40.000+08:00"></span></div></div></div>
</header>
<h3 id="hadoop-day04-hadoop-map-reduce-yarn-ha" tabindex="-1">hadoop离线day04--Hadoop MapReduce、YARN、HA</h3>
<hr>
<h4 id="今日课程学习目标" tabindex="-1">今日课程学习目标</h4>
<pre><code>理解分布式计算分而治之的思想
学会提交MapReduce程序
掌握MapReduce执行流程
掌握YARN功能与架构组件
掌握程序提交YARN交互流程
理解YARN调度策略
掌握Hadoop HA实现原理
</code></pre>
<h4 id="今日课程内容大纲" tabindex="-1">今日课程内容大纲</h4>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#1、初识MapReduce">#1、初识MapReduce</a>
	MapReduce背后的思想	先分再合，分而治之
	MapReduce设计构思
	官方MapReduce示例
    MapReduce Python接口
    	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#2、MapReduce基本原理">#2、MapReduce基本原理</a>
	整体流程梳理
	map阶段执行流程
	reduce阶段执行流程
	shuffle机制
	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#3、Hadoop">#3、Hadoop</a> YARN
	介绍：集群资源管理 任务调度
	3大组件 架构
	程序在yarn运行流程：以mr程序提交为例
	yarn调度器
    
<a class="tag" onclick="toggleTagSearch(this)" data-content="#4、Hadoop">#4、Hadoop</a> HA集群
	高可用概念：持续可用 一直可用
		解决单点故障问题  主备集群
	Hadoop HDFS HA实现方案--QJM、YARN HA
	搭建HA集群
</code></pre>
<hr>
<h4 id="01-hadoop-map-reduce" tabindex="-1">知识点01：Hadoop MapReduce--理解分而治之的思想</h4>
<ul>
<li>
<p>核心：<mark><strong>先分再合，分而治之</strong></mark>。：拆分，求解，合并</p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921164038462.png" alt="image-20210921164038462.png"><source media="(max-width:480px)" srcset="/img/optimized/fs6zmYxxWU-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/fs6zmYxxWU-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/fs6zmYxxWU-530.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/fs6zmYxxWU-530.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921164038462.png" alt="image-20210921164038462.png" width=""></picture></p>
</li>
<li>
<p>使用场景：面对复杂的任务、庞大的任务如何高效处理？</p>
</li>
<li>
<p>步骤</p>
<ul>
<li>
<p>分的阶段（<mark><strong>局部并行计算</strong></mark>）--map</p>
<pre><code class="language-shell">把复杂的任务拆分成若干个小的任务。
拆分的目的以并行方式处理小任务提高效率。

<a class="tag" onclick="toggleTagSearch(this)" data-content="#前提：任务可以拆分，拆分之后没有依赖关系。">#前提：任务可以拆分，拆分之后没有依赖关系。</a>
结果：每个任务处理完都是一个局部的结果。
 
map侧重于映射（对应关系）  任务1--&gt;结果1  任务2--&gt;结果2
</code></pre>
</li>
<li>
<p>汇总阶段（<strong><mark>全局汇总计算</mark></strong>）--reduce</p>
<pre><code>把上一个分的阶段局部结果进行全局汇总 得到最终结果。

reduce指的是结果数量的减少 汇总。
</code></pre>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="02-hadoop-map-reduce" tabindex="-1">知识点02：Hadoop MapReduce--官方团队设计构思</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image.png" alt="4-MapReduce、YARN、HA_image.png"><source media="(max-width:480px)" srcset="/img/optimized/zkQgCSfYhp-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/zkQgCSfYhp-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/zkQgCSfYhp-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/zkQgCSfYhp-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image.png" alt="4-MapReduce、YARN、HA_image.png" width=""></picture></p>
<p>!<a class="internal-link is-unresolved" href="/404" target="">Pasted image 20250309210336.png</a></p>
<p>!<a class="internal-link is-unresolved" href="/404" target="">Pasted image 20250309211508.png</a></p>
<ul>
<li>
<p>如何面对大数据场景</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#使用MapReduce思路来处理大数据。">#使用MapReduce思路来处理大数据。</a>

先把数据集拆分若干个小的数据集，前提是可以拆分并且拆分之后没有依赖。
拆分之后可以并行计算提高计算。

再通过全局汇总计算得出最终结果。
</code></pre>
</li>
<li>
<p>构建了函数式编程模型Map Reduce</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#函数本质就是映射。">#函数本质就是映射。</a>
f(x)=2x+1
	当x=1 f(1)=3
	当x=2 f(2)=5
x--&gt;f(x) 一一对应的映射关系。	

<a class="tag" onclick="toggleTagSearch(this)" data-content="#对应MapReduce来说">#对应MapReduce来说</a> 每个阶段都是输入数据经过处理对应着输出。
 MapReduce处理的数据类型是&lt;key,value&gt;键值对。
 实际使用中 考虑每个阶段输入输出 key value是什么。
</code></pre>
</li>
<li>
<p>统一构架，隐藏系统层细节</p>
<pre><code>精准的把技术问题和业务问题区分。  技术是通用的 业务不通用的。
	hadoop实现了底层所有的技术问题。 ---&gt;90%代码   怎么做(how to do)
	用户实现业务问题               ---&gt;10%代码    做什么(what need to do)
	
使用简单不代表技术简单 只能说MapReduce底层封装太漂亮。
</code></pre>
</li>
</ul>
<hr>
<h4 id="03-hadoop-map-reduce-mr-yarn" tabindex="-1">知识点03：Hadoop MapReduce官方示例--计算圆周率（如何提交mr到yarn）</h4>
<blockquote>
<p>最终MR程序需要用户的代码和Hadoop自己实现的代码整合在一起 才能叫做完整MR程序。</p>
<p>由于当下企业中MapReduce计算引擎已经日薄西山，所以很少涉及到MapReduce编程了。</p>
<p>可以通过官方提供的示例来感受MapReduce。</p>
</blockquote>
<hr>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921165418451.png" alt="image-20210921165418451.png"><source media="(max-width:480px)" srcset="/img/optimized/2ycXhC9Y2B-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/2ycXhC9Y2B-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/2ycXhC9Y2B-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/2ycXhC9Y2B-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921165418451.png" alt="image-20210921165418451.png" width=""></picture></p>
<ul>
<li>
<p>提交程序</p>
<pre><code class="language-shell">[root@node1 mapreduce]# pwd
/export/server/hadoop-3.3.0/share/hadoop/mapreduce

[root@node1 mapreduce]# hadoop jar hadoop-mapreduce-examples-3.3.0.jar pi 10 50


<a class="tag" onclick="toggleTagSearch(this)" data-content="#第一个参数：pi表示MapReduce程序执行圆周率计算任务；">#第一个参数：pi表示MapReduce程序执行圆周率计算任务；</a>
<a class="tag" onclick="toggleTagSearch(this)" data-content="#第二个参数：用于指定map阶段运行的任务task次数，并发度，这里是10；">#第二个参数：用于指定map阶段运行的任务task次数，并发度，这里是10；</a>
<a class="tag" onclick="toggleTagSearch(this)" data-content="#第三个参数：用于指定每个map任务取样的个数，这里是50。">#第三个参数：用于指定每个map任务取样的个数，这里是50。</a>
</code></pre>
</li>
<li>
<p>执行过程日志观察与梳理</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#mr程序的执行需要硬件资源（cpu">#mr程序的执行需要硬件资源（cpu</a> ram） 而yarn正好管理这些资源 所以第一步首先连接yarn申请资源

<a class="tag" onclick="toggleTagSearch(this)" data-content="#mr程序分为两步">#mr程序分为两步</a>
  - map阶段
  - reduce阶段

<a class="tag" onclick="toggleTagSearch(this)" data-content="#每个阶段都会运行task任务">#每个阶段都会运行task任务</a>
	map阶段的任务叫做maptask
	reduce阶段的任务叫做reducetask.
</code></pre>
</li>
</ul>
<hr>
<h4 id="04-hadoop-map-reduce-word-count" tabindex="-1">知识点04：Hadoop MapReduce官方示例--单词统计(WordCount)需求剖析</h4>
<ul>
<li>
<p>背景</p>
<pre><code>网页倒排索引 统计关键字在页面中出现的次数。
</code></pre>
</li>
<li>
<p>业务需求</p>
<pre><code>统计文件中每个单词出现的总次数。
</code></pre>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921165840419.png" alt="image-20210921165840419.png"><source media="(max-width:480px)" srcset="/img/optimized/ztCgZTrKad-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/ztCgZTrKad-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/ztCgZTrKad-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/ztCgZTrKad-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921165840419.png" alt="image-20210921165840419.png" width=""></picture></p>
</li>
<li>
<p>实现思路</p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730201523040.png" alt="image-20210730201523040.png"><source media="(max-width:480px)" srcset="/img/optimized/mcuPbukBt2-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/mcuPbukBt2-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/mcuPbukBt2-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/mcuPbukBt2-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730201523040.png" alt="image-20210730201523040.png" width=""></picture></p>
</li>
</ul>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#map阶段的核心：把输入的数据经过切割，全部标记1，因此输出就是">#map阶段的核心：把输入的数据经过切割，全部标记1，因此输出就是</a>&lt;单词，1&gt;。

<a class="tag" onclick="toggleTagSearch(this)" data-content="#shuffle阶段核心：经过默认的排序分区分组，key相同的单词会作为一组数据构成新的kv对。">#shuffle阶段核心：经过默认的排序分区分组，key相同的单词会作为一组数据构成新的kv对。</a>

<a class="tag" onclick="toggleTagSearch(this)" data-content="#reduce阶段核心：处理shuffle完的一组数据，该组数据就是该单词所有的键值对。对所有的1进行累加求和，就是单词的总次数。">#reduce阶段核心：处理shuffle完的一组数据，该组数据就是该单词所有的键值对。对所有的1进行累加求和，就是单词的总次数。</a>

<a class="tag" onclick="toggleTagSearch(this)" data-content="#读取数据组件">#读取数据组件</a>  写出数据组件MR框架已经封装好（自带）
</code></pre>
<ul>
<li>
<p>程序提交</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#上传课程资料中的文本文件1">#上传课程资料中的文本文件1</a>.txt到HDFS文件系统的/input目录下，如果没有这个目录，使用shell创建
	hadoop fs -mkdir /input	
	hadoop fs -put 1.txt /input

<a class="tag" onclick="toggleTagSearch(this)" data-content="#准备好之后，执行官方MapReduce实例，对上述文件进行单词次数统计">#准备好之后，执行官方MapReduce实例，对上述文件进行单词次数统计</a>
	第一个参数：wordcount表示执行单词统计任务；
	第二个参数：指定输入文件的路径；
	第三个参数：指定输出结果的路径（该路径不能已存在）
	

[root@node1 mapreduce]# pwd
/export/server/hadoop-3.3.0/share/hadoop/mapreduce

[root@node1 mapreduce]# hadoop jar hadoop-mapreduce-examples-3.3.0.jar wordcount /input /output
</code></pre>
</li>
</ul>
<hr>
<h4 id="05-hadoop-map-reduce-wordcount-java" tabindex="-1">知识点05：Hadoop MapReduce官方示例--Wordcount--java代码梳理</h4>
<ul>
<li>
<p>mapper</p>
<pre><code class="language-java">public class WordCountMapper extends Mapper&lt;LongWritable, Text,Text, IntWritable&gt; {
    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        //每一次读取到一行内容
        String line = value.toString();
        //根据分隔符进行切割
        String[] words = line.split(&quot;\\s+&quot;);
        //遍历单词数组
        for (String word : words) {
            //输出数据 把每个单词标记1   &lt;单词，1&gt;
            //使用框架提供的上下文对象 进行数据的输出
            context.write(new Text(word),new IntWritable(1));
        }
    }
}
</code></pre>
</li>
<li>
<p>reducer</p>
<pre><code class="language-java">public class WordCountReducer extends Reducer&lt;Text, IntWritable,Text,IntWritable&gt; {
    /**
     * Q: 当所有的数据来到reducer之后 内部有什么行为？
     *    &lt;hello,1&gt;&lt;hadoop,1&gt;&lt;hello,1&gt;&lt;hello,1&gt;&lt;hadoop,1&gt;
          
          1、所有的数据排序  排序规则：key的字典序  a-z
     *    &lt;hadoop,1&gt;&lt;hadoop,1&gt;&lt;hello,1&gt;&lt;hello,1&gt;&lt;hello,1&gt;
     *
          2、分组grouping  分组规则：key相同的分为一组
     *      &lt;hadoop,1&gt;&lt;hadoop,1&gt;
     *      &lt;hello,1&gt;&lt;hello,1&gt;&lt;hello,1&gt;
          
          3、每组构成一个新的kv对 去调用reduce方法
     *      新key: 该组共同的key
     *      新value: 该组所有的value组成的一个迭代器Iterable（理解为类似于集合数据结构）
     *      &lt;hadoop,1&gt;&lt;hadoop,1&gt;       ----&gt;  &lt;hadoop,Iterable[1,1]&gt;
     *      &lt;hello,1&gt;&lt;hello,1&gt;&lt;hello,1&gt; ---&gt;  &lt;hello,Iterable[1,1,1]&gt;
     */
    @Override
    protected void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        //定义个统计变量
        int count = 0;
        //遍历迭代器
        for (IntWritable value : values) {
            //累加
            count += value.get();
        }
        //使用上下文输出结果
        context.write(key,new IntWritable(count));
        }
}

</code></pre>
</li>
</ul>
<hr>
<h4 id="06-hadoop-map-reduce-python" tabindex="-1">知识点06：Hadoop MapReduce--python接口接入</h4>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#虽然Hadoop是用Java编写的一个框架">#虽然Hadoop是用Java编写的一个框架</a>, 但是并不意味着他只能使用Java语言来操作；

<a class="tag" onclick="toggleTagSearch(this)" data-content="#在Hadoop-0">#在Hadoop-0</a>.14.1版本后, Hadoop支持了Python和C++语言;

<a class="tag" onclick="toggleTagSearch(this)" data-content="#在Python中的sys包中存在stdin和stdout（输入输出流）">#在Python中的sys包中存在stdin和stdout（输入输出流）</a>, 可以利用这个方式来进行MapReduce的编写；

<a class="tag" onclick="toggleTagSearch(this)" data-content="#在Hadoop的文档中提到了Hadoop">#在Hadoop的文档中提到了Hadoop</a> Streaming, 可以使用流的方式来操作它；
	https://hadoop.apache.org/docs/r3.3.0/hadoop-streaming/HadoopStreaming.html
</code></pre>
<ul>
<li>
<p><a href="http://mapper.py" target="_blank" class="external-link">mapper.py</a></p>
<pre><code class="language-python">import sys

for line in sys.stdin:
    # 捕获输入流
    line = line.strip()
    # 根据分隔符切割单词
    words = line.split()
    # 遍历单词列表 每个标记1
    for word in words:
        print(&quot;%s\t%s&quot; % (word, 1))
</code></pre>
</li>
<li>
<p><a href="http://reducer.py" target="_blank" class="external-link">reducer.py</a></p>
<pre><code class="language-python">import sys
# 保存单词次数的字典 key:单词 value：总次数
word_dict = {}

for line in sys.stdin:

    line = line.strip()
    word, count = line.split('\t')

    # count类型转换
    try:
        count = int(count)
    except ValueError:
        continue
    # 如果单词位于字典中 +1，如果不存在 保存并设初始值1
    if word in word_dict:
        word_dict[word] += 1
    else:
        word_dict.setdefault(word, 1)
# 结果遍历输出
for k, v in word_dict.items():
    print('%s\t%s' % (k, v))
</code></pre>
</li>
</ul>
<hr>
<h4 id="07-hadoop-map-reduce-hadoop-streaing-python" tabindex="-1">知识点07：Hadoop MapReduce--Hadoop Streaing提交python脚本</h4>
<ul>
<li>
<p>Python3在Linux安装</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#1、安装编译相关工具">#1、安装编译相关工具</a>
yum -y groupinstall &quot;Development tools&quot;

yum -y install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gdbm-devel db4-devel libpcap-devel xz-devel

yum install libffi-devel -y

<a class="tag" onclick="toggleTagSearch(this)" data-content="#2、解压Python安装包">#2、解压Python安装包</a>
tar -zxvf  Python-3.8.5.tgz

<a class="tag" onclick="toggleTagSearch(this)" data-content="#3、编译、安装Python">#3、编译、安装Python</a>
mkdir /usr/local/python3 <a class="tag" onclick="toggleTagSearch(this)" data-content="#创建编译安装目录">#创建编译安装目录</a>
cd Python-3.8.5
./configure --prefix=/usr/local/python3
make &amp;&amp; make install  <a class="tag" onclick="toggleTagSearch(this)" data-content="#make编译c源码">#make编译c源码</a> make install 编译后的安装

<a class="tag" onclick="toggleTagSearch(this)" data-content="#安装过，出现下面两行就成功了">#安装过，出现下面两行就成功了</a>
Installing collected packages: setuptools, pip
Successfully installed pip-20.1.1 setuptools-47.1.0


<a class="tag" onclick="toggleTagSearch(this)" data-content="#4、创建软连接">#4、创建软连接</a>
# 查看当前python软连接
[root@node2 Python-3.8.5]# ll /usr/bin/ |grep python
-rwxr-xr-x.   1 root root      11232 Aug 13  2019 abrt-action-analyze-python
lrwxrwxrwx.   1 root root          7 May 17 11:36 python -&gt; python2
lrwxrwxrwx.   1 root root          9 May 17 11:36 python2 -&gt; python2.7
-rwxr-xr-x.   1 root root       7216 Aug  7  2019 python2.7


<a class="tag" onclick="toggleTagSearch(this)" data-content="#默认系统安装的是python2">#默认系统安装的是python2</a>.7 删除python软连接
rm -rf /usr/bin/python

<a class="tag" onclick="toggleTagSearch(this)" data-content="#配置软连接为python3">#配置软连接为python3</a>
ln -s /usr/local/python3/bin/python3 /usr/bin/python

<a class="tag" onclick="toggleTagSearch(this)" data-content="#这个时候看下python默认版本">#这个时候看下python默认版本</a>
python -V

<a class="tag" onclick="toggleTagSearch(this)" data-content="#删除默认pip软连接，并添加pip3新的软连接">#删除默认pip软连接，并添加pip3新的软连接</a>
rm -rf /usr/bin/pip
ln -s /usr/local/python3/bin/pip3 /usr/bin/pip


<a class="tag" onclick="toggleTagSearch(this)" data-content="#5、更改yum配置">#5、更改yum配置</a>
<a class="tag" onclick="toggleTagSearch(this)" data-content="#因为yum要用到python2才能执行，否则会导致yum不能正常使用（不管安装">#因为yum要用到python2才能执行，否则会导致yum不能正常使用（不管安装</a> python3的那个版本，都必须要做的）
vi /usr/bin/yum 
把 #! /usr/bin/python 修改为 #! /usr/bin/python2 

vi /usr/libexec/urlgrabber-ext-down 
把 #! /usr/bin/python 修改为 #! /usr/bin/python2

vi /usr/bin/yum-config-manager
#!/usr/bin/python 改为 #!/usr/bin/python2
</code></pre>
</li>
<li>
<p>代码的本地测试</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#上传待处理文件">#上传待处理文件</a> 和Python脚本到Linux上
[root@node2 ~]# pwd
/root
[root@node2 ~]# ll
-rw-r--r--  1 root  root        105 May 18 15:12 1.txt
-rwxr--r--  1 root  root        340 Jul 21 16:16 mapper.py
-rwxr--r--  1 root  root        647 Jul 21 16:18 reducer.py


<a class="tag" onclick="toggleTagSearch(this)" data-content="#使用shell管道符运行脚本测试">#使用shell管道符运行脚本测试</a>
[root@node2 ~]# cat 1.txt | python mapper.py |sort|python reducer.py 
allen   4
apple   3
hadoop  1
hello   5
mac     1
spark   2
tom     2
</code></pre>
</li>
<li>
<p>代码提交集群执行</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#上传处理的文件到hdfs">#上传处理的文件到hdfs</a>
<a class="tag" onclick="toggleTagSearch(this)" data-content="#上传Python脚本到linux">#上传Python脚本到linux</a>

<a class="tag" onclick="toggleTagSearch(this)" data-content="#提交程序执行">#提交程序执行</a>
hadoop jar /export/server/hadoop-3.3.0/share/hadoop/tools/lib/hadoop-streaming-3.3.0.jar \
-D mapred.reduce.tasks=1 \
-mapper &quot;python mapper.py&quot; \
-reducer &quot;python reducer.py&quot; \
-file mapper.py -file reducer.py \
-input /wordcount/input/* \
-output /wordcount/outpy
</code></pre>
</li>
</ul>
<hr>
<h4 id="08-hadoop-map-reduce" tabindex="-1">知识点08：Hadoop MapReduce--输入输出路径及注意事项</h4>
<ul>
<li>
<p>数据都是以&lt;key,value&gt;键值对的形式存在的。不管是输入还是输出。</p>
</li>
<li>
<p>关于inputpath</p>
<ul>
<li>指向的是一个文件，mr就处理这一个文件</li>
<li>指向的是一个目录，mr就处理该目录下所有的文件 整体当做数据集处理。</li>
</ul>
</li>
<li>
<p>关于outputpath</p>
<ul>
<li>要求指定的目录为空目录 不能够存储 否则执行校验失败</li>
</ul>
<pre><code>FileAlreadyExistsException: Output directory file:/D:/datasets/wordcount/output already exists
</code></pre>
</li>
</ul>
<hr>
<h4 id="09-hadoop-map-reduce-map" tabindex="-1">知识点09：Hadoop MapReduce--工作机制--map阶段执行流程</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224715586.png" alt="image-20210730224715586.png"><source media="(max-width:480px)" srcset="/img/optimized/i0zX-D3DUX-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/i0zX-D3DUX-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/i0zX-D3DUX-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/i0zX-D3DUX-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224715586.png" alt="image-20210730224715586.png" width=""></picture></p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224727842.png" alt="image-20210730224727842.png"><source media="(max-width:480px)" srcset="/img/optimized/CCYKE7KYdM-411.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/CCYKE7KYdM-411.jpeg">
<img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224727842.png" alt="image-20210730224727842.png" width=""></picture></p>
<ul>
<li>
<p>maptask并行度个数机制：逻辑切片机制。</p>
</li>
<li>
<p>影响maptask个数的因素有</p>
<pre><code>文件的个数
文件的大小
split size=block size  切片的大小受数据块的大小控制 
</code></pre>
</li>
</ul>
<hr>
<h4 id="10-hadoop-map-reduce-reduce" tabindex="-1">知识点10：Hadoop MapReduce--工作机制--reduce阶段执行流程</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224735604.png" alt="image-20210730224735604.png"><source media="(max-width:480px)" srcset="/img/optimized/ojGY5VjCjK-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/ojGY5VjCjK-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/ojGY5VjCjK-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/ojGY5VjCjK-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224735604.png" alt="image-20210730224735604.png" width=""></picture></p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-3.png" alt="4-MapReduce、YARN、HA_image-3.png"><source media="(max-width:480px)" srcset="/img/optimized/XKwqlCEAzV-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/XKwqlCEAzV-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/XKwqlCEAzV-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/XKwqlCEAzV-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-3.png" alt="4-MapReduce、YARN、HA_image-3.png" width=""></picture></p>
<p>1、拉取复制数据<br>
2、拉取来的数据进行merge合并、sort排序<br>
规则：key的字典序排序a--z<br>
3、排序之后的数据进行分组<br>
分组规则：key相同的分为一组<br>
4、一组去调用-次reduce方法进行聚合处理<br>
业务逻辑处理<br>
5、TextOutPutFormat默认的输出数据组件</p>
<hr>
<p>探究：<br>
1、reducetask个数能否改变，难道只能有--个吗？<br>
2、rcducctask个数改变和最终输出的结果文件个数有啥关系。<br>
默认情况下，MR程序永远只有-一个reducetask</p>
<ul>
<li>影响reducetask个数的因素
<ul>
<li>
<p>只要用户不设置 永远默认1个</p>
</li>
<li>
<p>用户也可以通过代码进行设置 设置为几 就是几</p>
<pre><code>
当reducetask&gt;=2，数据就会分区了。

</code></pre>
</li>
</ul>
</li>
</ul>
<p>MR的分区（partition）问题：<br>
当MR程序中，reducetask个数&gt;=2个的时候，对于	maptask就会涉及到一个棘手的问题：<br>
其输出的结果应该交给哪一个reducetask来处理？<br>
这个问题就是MR的分区问题Partition。</p>
<p>关键就是分区的规则：<br>
分区的关键就是分区规则默认规则<strong>HashPartitioner哈希取模</strong><br>
&lt;key,value&gt;<br>
key.hashcode % ReduceTask个数 == 余数 == 分区编号<br>
默认这个规则不会保证数据平均分区，	但是会保证，只要map输出的key-样就会到同一个分区中</p>
<hr>
<h4 id="11-hadoop-map-reduce-shuffle" tabindex="-1">知识点11：Hadoop MapReduce--工作机制--shuffle机制</h4>
<ul>
<li>Shuffle的本意是洗牌、混洗的意思，把一组有规则的数据尽量打乱成无规则的数据。</li>
<li>而在MapReduce中，Shuffle更像是洗牌的逆过程，指的是将map端的无规则输出按指定的规则“打乱”成具有一定规则的数据，以便reduce端接收处理。</li>
<li>shuffle是Mapreduce的核心，它分布在Mapreduce的map阶段和reduce阶段。</li>
<li>一般把从Map产生输出开始到Reduce取得数据作为输入之前的过程称作shuffle。</li>
</ul>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224743959.png" alt="image-20210730224743959.png"><source media="(max-width:480px)" srcset="/img/optimized/PZIL6XIIRG-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/PZIL6XIIRG-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/PZIL6XIIRG-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/PZIL6XIIRG-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224743959.png" alt="image-20210730224743959.png" width=""></picture></p>
<p>Map端Shuffle<br>
Collect阶段：将MapTask的结果收集输出到默认大小为100M的环形缓冲区，保存之前会对key进行分区的计算，默<br>
认Hash分区。<br>
Spill阶段：当内存中的数据量达到一定的阀值的时候，就会将数据写入本地磁盘，在将数据写入磁盘之前需要对<br>
数据进行一次排序的操作，如果配置了combiner，还会将有相同分区号和key的数据进行排序。<br>
Merge阶段：把所有溢出的临时文件进行一次合并操作，以确保一个MapTask最终只产生一个中间数据文件。<br>
Reducer端shuffle<br>
Copy阶段：ReduceTask启动Fetcher线程到已经完成MapTask的节点上复制一份属于自己的数据。<br>
Merge阶段：在ReduceTask远程复制数据的同时，会在后台开启两个线程对内存到本地的数据文件进行合并操作。<br>
Sort阶段：在对数据进行合并的同时，会进行排序操作，由于MapTask阶段已经对数据进行了局部的排序，	ReduceTask只需保证Copy的数据的最终整体有效性即可。<br>
shuffle的弊端<br>
Shuffle是MapReduce程序的核心与精髓，是MapReduce的灵魂所在。<br>
Shuffle也是MapReduce被垢病最多的地方所在。MapReduce相比较于Spark、Flink计算引l擎慢的原因，跟Shuffle机制有很大的关系。<br>
suffle中频繁涉及到数据在内存、磁盘之间的多次往复</p>
<hr>
<h4 id="---------------------------------" tabindex="-1">---------------------------------</h4>
<h4 id="12-hadoop-yarn" tabindex="-1">知识点12：Hadoop YARN--功能职责概述</h4>
<ul>
<li>
<p>yarn是一个<mark>通用资源管理系统</mark>和<mark>调度平台</mark>。</p>
<pre><code>资源指的跟程序运行相关的硬件资源  比如：CPU RAM 
</code></pre>
</li>
<li>
<p>资源管理系统：集群的硬件资源，和程序运行相关，比如内存、CPU等。</p>
</li>
<li>
<p>调度平台：多个程序同时申请计算资源如何分配，调度的规则（算法）。</p>
</li>
<li>
<p>通用：不仅仅支持MapReduce程序，理论上支持各种计算程序。YARN不关心你干什么，只关心你要资源，在有的情况下给你，用完之后还我。</p>
</li>
</ul>
<p><strong>简介</strong></p>
<ul>
<li>可以把HadoopYARN理解为相当于一个分布式的操作系统平台，而MapReduce等计算程序则相当于运行于操作系统之上的应用程序，YARN为这些程序提供运算所需的资源（内存、CPU等）。</li>
<li>Hadoop能有今天这个地位，YARN可以说是功不可没。因为有了YARN，更多计算框架可以接入到HDFS中，而不单单是MapReduce，正式因为YARN的包容，使得其他计算框架能专注于计算性能的提升。</li>
<li>HDFS可能不是最优秀的大数据存储系统，但却是应用最广泛的大数据存储系统，YARN功不可没。</li>
</ul>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173212023.png" alt="image-20210921173212023.png"><source media="(max-width:480px)" srcset="/img/optimized/2S_Yxvf96P-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/2S_Yxvf96P-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/2S_Yxvf96P-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/2S_Yxvf96P-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173212023.png" alt="image-20210921173212023.png" width=""></picture></p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-4.png" alt="4-MapReduce、YARN、HA_image-4.png"><source media="(max-width:480px)" srcset="/img/optimized/4kCUsIi7_k-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/4kCUsIi7_k-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/4kCUsIi7_k-666.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/4kCUsIi7_k-666.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-4.png" alt="4-MapReduce、YARN、HA_image-4.png" width=""></picture></p>
<hr>
<h4 id="13-hadoop-yarn-yarn3" tabindex="-1">知识点13：Hadoop YARN--集群架构、yarn3大组件</h4>
<p>官方给的图↓<br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173320913.png" alt="image-20210921173320913.png"><source media="(max-width:480px)" srcset="/img/optimized/uLjNjNoj2G-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/uLjNjNoj2G-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/uLjNjNoj2G-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/uLjNjNoj2G-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173320913.png" alt="image-20210921173320913.png" width=""></picture></p>
<ul>
<li>
<p>物理层面上-2个组件</p>
<ul>
<li>
<p>主角色 <mark>resourcemanager</mark> RM</p>
<p>ResourceManager 负责整个集群的资源管理和分配，是一个全局的资源管理系统。<br>
是程序申请资源的唯一入口 负载调度。</p>
</li>
<li>
<p>从角色 <mark>nodemanager</mark> NM</p>
<p>nodemanager 负责每台机器上具体的资源管理 负责启动 关闭container容器</p>
</li>
</ul>
</li>
<li>
<p>程序内部--1个组件</p>
<ul>
<li><mark>ApplicationMaster</mark> AM</li>
</ul>
<pre><code class="language-shell">yarn作为通用资源管理系统 不关心程序的种类和程序内部的执行情况？

谁来关心程序内部执行情况？
比如MapReduce程序来说，先maptask 再运行reducetask.

需要一个组件来管理程序执行情况  程序内部的资源申请 各阶段执行情况的监督

<a class="tag" onclick="toggleTagSearch(this)" data-content="#为了解决这个问题">#为了解决这个问题</a> yarn提供了第三个组件 applicationmaster 
(男)主人，雇主; 主宰; 主人; 有控制力的人; 能手; 擅长…者;

<a class="tag" onclick="toggleTagSearch(this)" data-content="#把applicationmaster称之为程序内部的老大角色">#把applicationmaster称之为程序内部的老大角色</a> 负责程序内部的执行情况

<a class="tag" onclick="toggleTagSearch(this)" data-content="#AM针对不同类型的程序有不同的具体实现">#AM针对不同类型的程序有不同的具体实现</a>
yarn默认实现了MapReduce的AM  名字叫做MrAppMaster.
其他软件比如spark flink需要实现自己的AM 才能在yarn运行。


<a class="tag" onclick="toggleTagSearch(this)" data-content="#结论：在上述设计模式下">#结论：在上述设计模式下</a>  任何种类程序在yarn运行，首先都是申请资源运行AM角色，然后由AM控制程序内部具体的执行。
</code></pre>
</li>
</ul>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-5.png" alt="4-MapReduce、YARN、HA_image-5.png"><source media="(max-width:480px)" srcset="/img/optimized/NKXOVXXpbM-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/NKXOVXXpbM-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/NKXOVXXpbM-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/NKXOVXXpbM-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-5.png" alt="4-MapReduce、YARN、HA_image-5.png" width=""></picture></p>
<hr>
<h4 id="14-hadoop-yarn-mr-yarn" tabindex="-1">知识点14：Hadoop YARN--MR程序提交YARN流程</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224812277.png" alt="image-20210730224812277.png"><source media="(max-width:480px)" srcset="/img/optimized/vzRrhabMRC-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/vzRrhabMRC-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/vzRrhabMRC-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/vzRrhabMRC-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210730224812277.png" alt="image-20210730224812277.png" width=""></picture></p>
<p><strong>流程</strong></p>
<ol>
<li>客户端提交，客户端连接resourceManager请求资源运行本次程序的AM（Application是 Manager）</li>
<li>RM指定NM预留资源，配合客户端启动容器container（图中MR App Mstr）客户端到指定的NM上，通过和NM的配合启动容器运行AM进程</li>
<li>AM启动向RM进行注册，保持通信</li>
<li>NM根据切片个数，向RM申请与之对应的容器运行MapTask
<ol>
<li>Resource Scheduler：申请安排至调度队列中，根据调度策略该你执行你猜执行</li>
</ol>
</li>
<li>AM根据申请的容器到各个机器上和NM配合启动容器运行MapTask并监督其执行情况</li>
<li>AM根据ReduceTask个数申请容器运行，过程同上</li>
<li>整个MR程序执行过程中，都是AM在申请资源、监督执行，并且把执行的情况汇报给RM（所以网页里才看得到）</li>
<li>程序运行完毕AM向RM申请回收资源，并且申请注销自己</li>
</ol>
<p><strong>注意：</strong><br>
1、YARN只负责分配资源回收资源不负责程序内部的逻辑<br>
2、不管是客户端、还是AM，只要想申请新的资源，必须找RM，因为RM才是资源分配的唯一仲裁者<br>
3、真正负责操心程序内部执行情况的是AM，每个程序都有自己的AM<br>
MR ---&gt; MrAppMaster<br>
SparkFlink叫什么呢？后面好好学习。</p>
<hr>
<h4 id="15-hadoop-yarn-scheduler" tabindex="-1">知识点15：Hadoop YARN--scheduler调度策略</h4>
<ul>
<li>
<p>所谓的调度器指的是当集群繁忙的时候 如何给申请资源的程序分配资源</p>
</li>
<li>
<p>scheduler属于ResourceManager功能</p>
</li>
<li>
<p>YARN3大调度策略</p>
<ul>
<li>FIFO Scheduler 先进先出策略：绝对公平，不适合共享<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-7.png" alt="4-MapReduce、YARN、HA_image-7.png"><source media="(max-width:480px)" srcset="/img/optimized/GWp2JtKklq-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/GWp2JtKklq-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/GWp2JtKklq-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/GWp2JtKklq-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-7.png" alt="4-MapReduce、YARN、HA_image-7.png" width=""></picture></li>
<li><strong><mark>capacity Scheduler 容量调度策略</mark></strong>：默认策略，队列内部依旧是先进先出，没大程序的时候，大程序队列就浪费了<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-8.png" alt="4-MapReduce、YARN、HA_image-8.png"><source media="(max-width:480px)" srcset="/img/optimized/PgGrOG_GC5-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/PgGrOG_GC5-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/PgGrOG_GC5-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/PgGrOG_GC5-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-8.png" alt="4-MapReduce、YARN、HA_image-8.png" width=""></picture></li>
<li>Fair Sheduler 公平调度策略：<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-9.png" alt="4-MapReduce、YARN、HA_image-9.png"><source media="(max-width:480px)" srcset="/img/optimized/YWMnuooin4-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/YWMnuooin4-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/YWMnuooin4-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/YWMnuooin4-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-9.png" alt="4-MapReduce、YARN、HA_image-9.png" width=""></picture><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-10.png" alt="4-MapReduce、YARN、HA_image-10.png"><source media="(max-width:480px)" srcset="/img/optimized/wD8x_IbTIq-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/wD8x_IbTIq-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/wD8x_IbTIq-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/wD8x_IbTIq-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-10.png" alt="4-MapReduce、YARN、HA_image-10.png" width=""></picture></li>
</ul>
</li>
<li>
<p>Apache Hadoop版本默认策略是capacity 。CDH商业版本默认策略是Fair。</p>
<ul>
<li>默认情况下，整个yarn集群在capacity策略下，划分为一个队列 名字叫做default，占整个集群资源的100.</li>
</ul>
</li>
<li>
<p>决定调度策略的参数</p>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#yarn-site">#yarn-site</a>.xml

yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.capacity.CapacityScheduler

<a class="tag" onclick="toggleTagSearch(this)" data-content="#还可以在yarn">#还可以在yarn</a> 8088页面查看
</code></pre>
</li>
</ul>
<hr>
<h4 id="16-hadoop-yarn-capacity" tabindex="-1">知识点16：Hadoop YARN--capacity配置示例说明</h4>
<ul>
<li>prod 生产环境 线上环境</li>
<li>dev 开发环境</li>
</ul>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921172135028.png" alt="image-20210921172135028.png"><source media="(max-width:480px)" srcset="/img/optimized/QCulflRkvJ-498.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/QCulflRkvJ-498.jpeg">
<img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921172135028.png" alt="image-20210921172135028.png" width=""></picture><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-11.png" alt="4-MapReduce、YARN、HA_image-11.png"><source media="(max-width:480px)" srcset="/img/optimized/UDgGGXP2hY-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/UDgGGXP2hY-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/UDgGGXP2hY-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/UDgGGXP2hY-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-11.png" alt="4-MapReduce、YARN、HA_image-11.png" width=""></picture></p>
<h4 id="---------------------------------------" tabindex="-1">---------------------------------------</h4>
<h4 id="17-hadoop-ha" tabindex="-1">知识点17：Hadoop HA集群--什么是高可用、实现高可用注意事项</h4>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173435657.png" alt="image-20210921173435657.png"><source media="(max-width:480px)" srcset="/img/optimized/bhbxR6VUQw-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/bhbxR6VUQw-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/bhbxR6VUQw-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/bhbxR6VUQw-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173435657.png" alt="image-20210921173435657.png" width=""></picture></p>
<p><strong>背景知识：</strong><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-13.png" alt="4-MapReduce、YARN、HA_image-13.png"><source media="(max-width:480px)" srcset="/img/optimized/F--UhhRGHR-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/F--UhhRGHR-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/F--UhhRGHR-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/F--UhhRGHR-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-13.png" alt="4-MapReduce、YARN、HA_image-13.png" width=""></picture><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-14.png" alt="4-MapReduce、YARN、HA_image-14.png"><source media="(max-width:480px)" srcset="/img/optimized/8N52f1MriX-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/8N52f1MriX-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/8N52f1MriX-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/8N52f1MriX-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-14.png" alt="4-MapReduce、YARN、HA_image-14.png" width=""></picture><br>
、<br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-12.png" alt="4-MapReduce、YARN、HA_image-12.png"><source media="(max-width:480px)" srcset="/img/optimized/yTe6b3xaih-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/yTe6b3xaih-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/yTe6b3xaih-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/yTe6b3xaih-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-12.png" alt="4-MapReduce、YARN、HA_image-12.png" width=""></picture><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-15.png" alt="4-MapReduce、YARN、HA_image-15.png"><source media="(max-width:480px)" srcset="/img/optimized/QQy1GRdzzg-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/QQy1GRdzzg-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/QQy1GRdzzg-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/QQy1GRdzzg-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-15.png" alt="4-MapReduce、YARN、HA_image-15.png" width=""></picture></p>
<h4 id="18-hadoop-ha-hdfs-ha-qjm" tabindex="-1">知识点18：Hadoop HA集群--HDFS HA--QJM实现原理</h4>
<p>QJM解决单点故障</p>
<ul>
<li>
<p>Hadoop中单点故障</p>
<ul>
<li>NameNode</li>
<li>Resourcemanager</li>
</ul>
</li>
<li>
<p>NameNode HA ---<mark>QJM共享日志集群方案</mark><br>
<strong>Quorum Journal Manager介绍</strong><br>
QJM全称QuorumJournal Manager（仲裁日总管理器），是Hadoop官方推荐的HDFS HA解决方案之一。<br>
使用zookeeper中zKFC来实现主备切换；<br>
使用JournalNode（JN）集群实现editslog的共享以达到数据同步的目的。</p>
<ul>
<li>zkfc 实现主备切换避免<strong>脑裂</strong><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-17.png" alt="4-MapReduce、YARN、HA_image-17.png"><source media="(max-width:480px)" srcset="/img/optimized/UUyftNvDks-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/UUyftNvDks-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/UUyftNvDks-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/UUyftNvDks-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-17.png" alt="4-MapReduce、YARN、HA_image-17.png" width=""></picture><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-18.png" alt="4-MapReduce、YARN、HA_image-18.png"><source media="(max-width:480px)" srcset="/img/optimized/aIeSWdV-Zc-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/aIeSWdV-Zc-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/aIeSWdV-Zc-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/aIeSWdV-Zc-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-18.png" alt="4-MapReduce、YARN、HA_image-18.png" width=""></picture></li>
<li>jn（Journal Node）集群 editslog编辑日志<strong>同步</strong><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-19.png" alt="4-MapReduce、YARN、HA_image-19.png"><source media="(max-width:480px)" srcset="/img/optimized/y-EtzfkGC6-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/y-EtzfkGC6-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/y-EtzfkGC6-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/y-EtzfkGC6-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-19.png" alt="4-MapReduce、YARN、HA_image-19.png" width=""></picture></li>
</ul>
</li>
</ul>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173452718.png" alt="image-20210921173452718.png"><source media="(max-width:480px)" srcset="/img/optimized/n0HOPIQwG3-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/n0HOPIQwG3-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/n0HOPIQwG3-662.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/n0HOPIQwG3-662.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173452718.png" alt="image-20210921173452718.png" width=""></picture></p>
<hr>
<h4 id="19-hadoop-ha-yarn-ha" tabindex="-1">知识点19：Hadoop HA集群--YARN HA</h4>
<ul>
<li>
<p>Resourcemanager HA --基于zk实现</p>
<ul>
<li>RM需要维护的数据量很少 不像NN需要同步文件系统大量的元数据。直接基于zk即可完成</li>
<li>别忘了 zk也是一个分布式小文件存储系统。</li>
</ul>
</li>
<li>
<p>Hadoop HA集群搭建 难点就是配置文件的编写</p>
</li>
</ul>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-20.png" alt="4-MapReduce、YARN、HA_image-20.png"><source media="(max-width:480px)" srcset="/img/optimized/0E9rwpTPte-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/0E9rwpTPte-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/0E9rwpTPte-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/0E9rwpTPte-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-20.png" alt="4-MapReduce、YARN、HA_image-20.png" width=""></picture><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173504825.png" alt="image-20210921173504825.png"><source media="(max-width:480px)" srcset="/img/optimized/Bp_P1Qrgc--500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/Bp_P1Qrgc--500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/Bp_P1Qrgc--585.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/Bp_P1Qrgc--585.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E8%AE%A1%E7%AE%97%E6%9C%BA/Hadoop%E6%8A%80%E6%9C%AF%E6%A0%88/%E8%B5%84%E6%96%99%E8%AE%B2%E4%B9%89/%E6%BA%90/day04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA/1%E3%80%81%E7%AC%94%E8%AE%B0%E3%80%81%E6%80%BB%E7%BB%93/hadoop%E7%A6%BB%E7%BA%BFday04--Hadoop%20MapReduce%E3%80%81YARN%E3%80%81HA.assets/image-20210921173504825.png" alt="image-20210921173504825.png" width=""></picture><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-21.png" alt="4-MapReduce、YARN、HA_image-21.png"><source media="(max-width:480px)" srcset="/img/optimized/4y8sDqWcNg-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/4y8sDqWcNg-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/4y8sDqWcNg-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/4y8sDqWcNg-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/4-MapReduce%E3%80%81YARN%E3%80%81HA_image-21.png" alt="4-MapReduce、YARN、HA_image-21.png" width=""></picture></p>
<hr>
<ul>
<li>
<p>关于HA集群，听懂原理 可以不搭建 <mark>后续课程依然使用非HA集群</mark>。（主要考虑资源不足）</p>
<ul>
<li>针对当下集群进行逻辑删除 备份</li>
<li>使用新的安装包进行编辑</li>
</ul>
</li>
</ul>
<hr>
<h4 id="今日作业" tabindex="-1">今日作业</h4>
<pre><code class="language-shell"><a class="tag" onclick="toggleTagSearch(this)" data-content="#理解分布式计算分而治之的思想">#理解分布式计算分而治之的思想</a>
	分为几步 每步做什么
    如何理解map单词 如何理解reduce单词
    
<a class="tag" onclick="toggleTagSearch(this)" data-content="#学会提交MapReduce程序">#学会提交MapReduce程序</a>
	hadoop jar 
	yarn jar
	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#掌握MapReduce执行流程">#掌握MapReduce执行流程</a>  重要
	map阶段
		1、maptask个数如何决定的
		2、读文件组件textinputFormat 读数据行为是?
		3、map处理完数据进行分区  分区是什么  默认分区规则是啥
		4、缓冲区作用 0.8 100M
		5、spill 溢写
		6、sort排序 行为是什么
		7、merge 合并
		
	reduce阶段
		0、reducetask个数如何决定的 默认1 手动设置
		1、copy主动拉取自己的数据
		2、merge合并
		3、sort排序
		4、分组 行为
		5、默认输出组件textoutputFormat
		
	shuffle机制
		什么是shuffle 缺点是什么
		map端shuffle有哪些步骤
		reduce端shuffle有哪些步骤
		
<a class="tag" onclick="toggleTagSearch(this)" data-content="#MR程序中maptask个数、reducetask个数怎么决定的">#MR程序中maptask个数、reducetask个数怎么决定的</a>		
	maptask影响因素（并行度个数）
	
	reducetask影响因素（并行度个数）
		人干预
	
<a class="tag" onclick="toggleTagSearch(this)" data-content="#掌握YARN功能与架构组件">#掌握YARN功能与架构组件</a>
	3个组件
		RM
		NM
		AM

<a class="tag" onclick="toggleTagSearch(this)" data-content="#掌握程序提交YARN交互流程">#掌握程序提交YARN交互流程</a>  重要
	申请资源就找RM
	程序内部首先启动AM

<a class="tag" onclick="toggleTagSearch(this)" data-content="#理解YARN调度策略">#理解YARN调度策略</a>
	几个策略 默认是谁  优缺点是啥
	FIFO
	Capacity
	Fair

<a class="tag" onclick="toggleTagSearch(this)" data-content="#掌握Hadoop">#掌握Hadoop</a> HA实现原理
	HA相关名称
	设计角度：如何顺利实现HA系统？
		如何避免脑裂？  脑裂的后果是什么？  追求的是什么？
		如何实现主备数据状态同步？
	
    NN HA---QJM
    	zkfc是啥功能
    	jn是啥
</code></pre>
</main>
<aside>
<div class="sidebar">
<div class="sidebar-container">
<div class="toc">
<div class="toc-title-container">
<div class="toc-title">
On this page
</div>
</div>
<div class="toc-container">
<nav class="toc">
<ol>
<li><a href="#hadoop-day04-hadoop-map-reduce-yarn-ha">hadoop离线day04--Hadoop MapReduce、YARN、HA</a>
<ol>
<li><a href="#今日课程学习目标">今日课程学习目标</a>
</li>
<li><a href="#今日课程内容大纲">今日课程内容大纲</a>
</li>
<li><a href="#01-hadoop-map-reduce">知识点01：Hadoop MapReduce--理解分而治之的思想</a>
</li>
<li><a href="#02-hadoop-map-reduce">知识点02：Hadoop MapReduce--官方团队设计构思</a>
</li>
<li><a href="#03-hadoop-map-reduce-mr-yarn">知识点03：Hadoop MapReduce官方示例--计算圆周率（如何提交mr到yarn）</a>
</li>
<li><a href="#04-hadoop-map-reduce-word-count">知识点04：Hadoop MapReduce官方示例--单词统计(WordCount)需求剖析</a>
</li>
<li><a href="#05-hadoop-map-reduce-wordcount-java">知识点05：Hadoop MapReduce官方示例--Wordcount--java代码梳理</a>
</li>
<li><a href="#06-hadoop-map-reduce-python">知识点06：Hadoop MapReduce--python接口接入</a>
</li>
<li><a href="#07-hadoop-map-reduce-hadoop-streaing-python">知识点07：Hadoop MapReduce--Hadoop Streaing提交python脚本</a>
</li>
<li><a href="#08-hadoop-map-reduce">知识点08：Hadoop MapReduce--输入输出路径及注意事项</a>
</li>
<li><a href="#09-hadoop-map-reduce-map">知识点09：Hadoop MapReduce--工作机制--map阶段执行流程</a>
</li>
<li><a href="#10-hadoop-map-reduce-reduce">知识点10：Hadoop MapReduce--工作机制--reduce阶段执行流程</a>
</li>
<li><a href="#11-hadoop-map-reduce-shuffle">知识点11：Hadoop MapReduce--工作机制--shuffle机制</a>
</li>
<li><a href="#---------------------------------">---------------------------------</a>
</li>
<li><a href="#12-hadoop-yarn">知识点12：Hadoop YARN--功能职责概述</a>
</li>
<li><a href="#13-hadoop-yarn-yarn3">知识点13：Hadoop YARN--集群架构、yarn3大组件</a>
</li>
<li><a href="#14-hadoop-yarn-mr-yarn">知识点14：Hadoop YARN--MR程序提交YARN流程</a>
</li>
<li><a href="#15-hadoop-yarn-scheduler">知识点15：Hadoop YARN--scheduler调度策略</a>
</li>
<li><a href="#16-hadoop-yarn-capacity">知识点16：Hadoop YARN--capacity配置示例说明</a>
</li>
<li><a href="#---------------------------------------">---------------------------------------</a>
</li>
<li><a href="#17-hadoop-ha">知识点17：Hadoop HA集群--什么是高可用、实现高可用注意事项</a>
</li>
<li><a href="#18-hadoop-ha-hdfs-ha-qjm">知识点18：Hadoop HA集群--HDFS HA--QJM实现原理</a>
</li>
<li><a href="#19-hadoop-ha-yarn-ha">知识点19：Hadoop HA集群--YARN HA</a>
</li>
<li><a href="#今日作业">今日作业</a>
</li>
</ol>
</li>
</ol>
</nav>
</div>
</div>
<div class="backlinks">
<div class="backlink-title" style="margin:4px 0!important">Pages mentioning this page</div>
<div class="backlink-list"><div class="backlink-card"><i icon-name="link"></i><a href="/czc知识库/计算机/Hadoop技术栈/Hadoop技术栈/" data-note-icon="" class="backlink">Hadoop技术栈</a>
</div></div>
</div>
</div>
</div>
</aside>
<style>#tooltip-wrapper{background:var(--background-primary);padding:1em;border-radius:4px;overflow:hidden;position:fixed;width:80%;max-width:400px;height:auto;max-height:300px;font-size:.8em;box-shadow:0 5px 10px rgba(0,0,0,.1);opacity:0;transition:opacity .1s;unicode-bidi:plaintext;overflow-y:scroll;z-index:10}#tooltip-wrapper:after{content:"";position:absolute;z-index:1;bottom:0;left:0;pointer-events:none;width:100%;unicode-bidi:plaintext;height:75px}</style>
<div style="opacity:0;display:none" id="tooltip-wrapper">
<div id="tooltip-content">
</div>
</div>
<iframe style="display:none;height:0;width:0" id="link-preview-iframe" src="">
</iframe>
<script>var opacityTimeout,contentTimeout,transitionDurationMs=100,iframe=document.getElementById("link-preview-iframe"),tooltipWrapper=document.getElementById("tooltip-wrapper"),tooltipContent=document.getElementById("tooltip-content"),linkHistories={};function hideTooltip(){opacityTimeout=setTimeout((function(){tooltipWrapper.style.opacity=0,contentTimeout=setTimeout((function(){tooltipContent.innerHTML="",tooltipWrapper.style.display="none"}),transitionDurationMs+1)}),transitionDurationMs)}function showTooltip(t){var e=t.target,o=e.getClientRects()[e.getClientRects().length-1],i=window.pageYOffset||document.documentElement.scrollTop,n=t.target.getAttribute("href");if(-1===n.indexOf("http")||-1!==n.indexOf(window.location.host)){let t=n.split("#")[0];linkHistories[t]?(tooltipContent.innerHTML=linkHistories[t],tooltipWrapper.style.display="block",setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)):(iframe.src=t,iframe.onload=function(){tooltipContentHtml="",tooltipContentHtml+='<div style="font-weight: bold; unicode-bidi: plaintext;">'+iframe.contentWindow.document.querySelector("h1").innerHTML+"</div>",tooltipContentHtml+=iframe.contentWindow.document.querySelector(".content").innerHTML,tooltipContent.innerHTML=tooltipContentHtml,linkHistories[t]=tooltipContentHtml,tooltipWrapper.style.display="block",tooltipWrapper.scrollTop=0,setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),console.log(e),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)}),tooltipWrapper.style.left=o.left-tooltipWrapper.offsetWidth/2+o.width/2+"px",window.innerHeight-o.top<tooltipWrapper.offsetHeight?tooltipWrapper.style.top=o.top+i-tooltipWrapper.offsetHeight-10+"px":window.innerHeight-o.top>tooltipWrapper.offsetHeight&&(tooltipWrapper.style.top=o.top+i+35+"px"),o.left+o.width/2<tooltipWrapper.offsetWidth/2?tooltipWrapper.style.left="10px":document.body.clientWidth-o.left-o.width/2<tooltipWrapper.offsetWidth/2&&(tooltipWrapper.style.left=document.body.clientWidth-tooltipWrapper.offsetWidth-20+"px")}}function setupListeners(t){t.addEventListener("mouseleave",(function(t){hideTooltip()})),tooltipWrapper.addEventListener("mouseleave",(function(t){hideTooltip()})),t.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout),showTooltip(t)})),tooltipWrapper.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout)}))}window.addEventListener("load",(function(t){document.querySelectorAll(".internal-link").forEach(setupListeners),document.querySelectorAll(".backlink-card a").forEach(setupListeners)}))</script>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
