<!doctype html>
<html lang="zh-CN">
<head>
<title>402-Python爬虫</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.74516f71.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
<style></style>
</head>
<body class="theme-dark markdown-preview-view markdown-rendered markdown-preview-section css-settings-manager mod-windows is-frameless is-maximized is-hidden-frameless is-focused obsidian-app theme-light show-inline-title show-ribbon show-view-header css-settings-manager theme-default line-style-solid folder-default blockquote-normal callout-normal checkbox-default tag-default link-default heading-default responsive-tile-height oz-show-all-num">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">czc&#39;s digital garden</h1>
</a>
</div>
<div class="search-button align-icon" onclick="toggleSearch()">
<span class="search-icon">
<i icon-name="search"></i>
</span>
<span class="search-text">
<span>Search</span>
<span style="font-size:.6rem;padding:2px 2px 0 6px;text-align:center;transform:translateY(4px)" class="search-keys">
CTRL + K
</span>
</span>
</div>
</nav>
<div class="search-container" id="globalsearch" onclick="toggleSearch()">
<div class="search-box">
<input type="search" id="term" placeholder="Start typing...">
<div id="search-results"></div>
<footer class="search-box-footer">
<div class="navigation-hint">
<span>Enter to select</span>
</div>
<div class="navigation-hint align-icon">
<i icon-name="arrow-up" aria-hidden="true"></i>
<i icon-name="arrow-down" aria-hidden="true"></i>
<span>to navigate</span>
</div>
<div class="navigation-hint">
<span>ESC to close</span>
</div>
</footer>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js"></script>
<script>document.addEventListener("DOMContentLoaded",init,!1),document.addEventListener("DOMContentLoaded",setCorrectShortcut,!1),window.toggleSearch=function(){document.getElementById("globalsearch").classList.contains("active")?document.getElementById("globalsearch").classList.remove("active"):(document.getElementById("globalsearch").classList.add("active"),document.getElementById("term").focus())},window.toggleTagSearch=function(e){console.log(e.textContent);const t=e.textContent;t&&(window.document.getElementById("term").value=t.trim(),window.toggleSearch(),window.search())};const loadingSvg='\n    <svg width="100" height="100" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg" stroke="#fff">\n      <g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2">\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="1.5s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="1.5s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="1.5s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="3s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="3s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="3s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="8">\n              <animate attributeName="r"\n                   begin="0s" dur="1.5s"\n                   values="6;1;2;3;4;5;6"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n      </g>\n  </svg>';function debounce(e,t,n){var a;return function(){var r=this,i=arguments,c=n&&!a;clearTimeout(a),a=setTimeout((function(){a=null,n||e.apply(r,i)}),t),c&&e.apply(r,i)}}function setCorrectShortcut(){navigator.platform.toUpperCase().indexOf("MAC")>=0&&document.querySelectorAll(".search-keys").forEach((e=>e.innerHTML="⌘ + K"))}function createIndex(e){const t=e=>e.toLowerCase().split(/([^a-z]|[^\x00-\x7F])/),n=new FlexSearch.Document({cache:!0,charset:"latin:extra",optimize:!0,index:[{field:"content",tokenize:"reverse",encode:t},{field:"title",tokenize:"forward",encode:t},{field:"tags",tokenize:"forward",encode:t}]});return e.forEach(((e,t)=>{n.add({id:t,title:e.title,content:e.content,tags:e.tags})})),n}async function init(){let e=!0;if(localStorage.getItem("searchIndex")){let{date:t,docs:n}=JSON.parse(localStorage.getItem("searchIndex"));if("2025-06-04T06:34:30.081Z"===t){e=!1;let t=createIndex(n);window.docs=n,window.index=t}}if(e){let e=await(await fetch("/searchIndex.json?v=2025-06-04T06:34:30.081Z")).json(),t=createIndex(e);localStorage.setItem("searchIndex",JSON.stringify({date:"2025-06-04T06:34:30.081Z",docs:e})),window.docs=e,window.index=t}document.addEventListener("keydown",(e=>{if((e.ctrlKey||e.metaKey)&&"k"===e.key&&(e.preventDefault(),toggleSearch()),"Escape"===e.key&&document.getElementById("globalsearch").classList.remove("active"),document.getElementById("globalsearch").classList.contains("active")){if("ArrowDown"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.nextElementSibling?t.nextElementSibling.classList.add("active"):document.querySelector(".searchresult").classList.add("active")):document.querySelector(".searchresult").classList.add("active");let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("ArrowUp"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.previousElementSibling?t.previousElementSibling.classList.add("active"):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling||e.classList.add("active")}))):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling&&e.classList.add("active")}));let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("Enter"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t&&(window.location.href=t.querySelector("a").href)}}}));const t=debounce(search,200,!1);field=document.querySelector("#term"),field.addEventListener("keydown",(e=>{"ArrowDown"!==e.key&&"ArrowUp"!==e.key&&t()})),resultsDiv=document.querySelector("#search-results");const n=new URL(location.href).searchParams;n.get("q")&&(field.setAttribute("value",n.get("q")),toggleSearch(),search())}async function search(){let e=field.value.trim();if(!e)return;if(e==lastSearch)return;console.log(`search for ${e}`),window.lastSearch=e,resultsDiv.innerHTML=loadingSvg;let t=offlineSearch(e),n="";if(!t.length){let t=document.createElement("p");return t.innerText=`No results for "${e}"`,resultsDiv.innerHTML="",void resultsDiv.appendChild(t)}n+='<div style="max-width:100%;">',t.forEach((e=>{e.tags&&e.tags.length>0?n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        <div class="header-meta">\n                            <div class="header-tags">\n                                ${e.tags.map((e=>'<a class="tag" href="JavaScript:Void(0);">#'+e+"</a>")).join("")}\n                            </div>\n                        </div>\n                        ${e.content}\n                    </div>\n                </div>`:n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        ${e.content}\n                    </div>\n                </div>`})),n+="</div>",resultsDiv.innerHTML=n}function truncate(e,t){return(e=e.replaceAll(/<[^>]*>/g,"")).length<t?e:e.substring(0,t-3)+"..."}function offlineSearch(e){let t=window.docs,n="#"===e[0]&&e.length>1?index.search(e.substring(1),[{field:"tags"}]):index.search(e,[{field:"title",limit:5},{field:"content",weight:10}]);const a=e=>{const t=n.filter((t=>t.field===e));return 0===t.length?[]:[...t[0].result]};return[...new Set([...a("title"),...a("content"),...a("tags")])].map((e=>{let n=t[e];return n.content=truncate(n.content,400),n.tags=n.tags.filter((e=>"gardenEntry"!=e&&"note"!=e)),n}))}window.lastSearch=""</script>
<main class="content cm-s-obsidian">
<header>
<h1 data-note-icon="">402-Python爬虫</h1>
<div class="header-meta">
<div class="header-tags">
</div>
<div class="timestamps"><div><i icon-name="calendar-plus"></i> <span class="human-date" data-date="2024-12-25T16:29:49.139+08:00"></span></div><div><i icon-name="calendar-clock"></i> <span class="human-date" data-date="2025-02-24T23:15:05.000+08:00"></span></div></div></div>
</header>
<h2 id="python" tabindex="-1">Python爬虫</h2>
<h3 id="什么是爬虫" tabindex="-1">什么是爬虫</h3>
<p><strong><code>网络爬虫:</code></strong></p>
<p>又被称为网页蜘蛛，网络机器人，是一种按照一定的规则，自动地抓取网络信息的程序或者脚本，另外一些不常使用的名字还有蚂蚁、自动索引、模拟程序或者蠕虫。</p>
<p><strong><code>通俗理解:</code></strong></p>
<p>简单来讲，爬虫就是一个探测机器，它的基本操作就是模拟人的行为去各个网站溜达，点点按钮，查查数据，或者把看到的信息背回来. 就像一只虫子在一幢楼里不知疲倦地爬来爬去.</p>
<p><strong><code>你可以简单地想象</code>：</strong> <strong>每个爬虫都是你的「分身」。就像孙悟空拔了一撮汗毛，吹出一堆猴子一样</strong></p>
<p>**<code>百度:</code>**其实就是利用了这种爬虫技术, 每天放出无数爬虫到各个网站，把他们的信息抓回来，然后化好淡妆排着小队等你来检索。</p>
<p>有了这样的特性, 对于一些自己公司数据量不足的小公司, 这个时候还想做数据分析就可以通过爬虫获取同行业的数据然后进行分析, 进而指导公司的策略指定。</p>
<h3 id="爬虫的基本步骤" tabindex="-1">爬虫的基本步骤</h3>
<p>基本步骤：</p>
<ul>
<li>起始URL地址</li>
<li>发出请求获取响应数据</li>
<li>对响应数据解析</li>
<li>数据入库</li>
</ul>
<h3 id="requests" tabindex="-1">安装requests模块</h3>
<ul>
<li>requests : 可以模拟浏览器的请求</li>
<li>官方文档 ：<a href="http://cn.python-requests.org/zh_CN/latest/" target="_blank" class="external-link">http://cn.python-requests.org/zh_CN/latest/</a></li>
<li>安装 ：pip install requests</li>
</ul>
<p>快速入门（requests三步走）：</p>
<pre><code class="language-python"># 导入模块
import requests
# 通过requests.get()发送请求
# data保存返回的响应数据(这里的响应数据不是单纯的html,需要通过content获取html代码)
data = requests.get(&quot;http://www.baidu.com&quot;)
# 通过data.content获取html代码
data = data.content.decode(&quot;utf-8&quot;)
</code></pre>
<h3 id="爬取照片" tabindex="-1">爬取照片</h3>
<h4 id="爬取照片的步骤" tabindex="-1">爬取照片的步骤</h4>
<ol>
<li>获取index.html代码</li>
<li>解析index.html代码获取图片url</li>
<li>通过图片url获取图片</li>
</ol>
<h4 id="index-html" tabindex="-1">获取index.html代码</h4>
<pre><code class="language-python"># 通过爬虫向index.html发送请求
# requests.get(网址): 向一个网址发送请求,和在浏览器中输入网址是一样的
data = requests.get(&quot;http://127.0.0.1:8000/index.html&quot;)
# content可以把requests.get()获取的返回值中的html内容获取到
data = data.content.decode(&quot;utf-8&quot;)
</code></pre>
<h4 id="index-html-url" tabindex="-1">解析index.html代码获取图片url</h4>
<pre><code class="language-python"># 获取图片的请求url
def get_pic_url():
    # 通过爬虫向index.html发送请求
    # requests.get(网址): 向一个网址发送请求,和在浏览器中输入网址是一样的
    data = requests.get(&quot;http://127.0.0.1:8000/index.html&quot;)
    # content可以把requests.get()获取的返回值中的html内容获取到
    data = data.content.decode(&quot;utf-8&quot;)
    # html每一行都有&quot;\n&quot;, 对html进行分割获得一个列表
    data = data.split(&quot;\n&quot;)
    # 创建一个列表存储所有图片的url地址(也就是图片网址)
    url_list = []
    for url in data:
        # 通过正则解析出所有的图片url
        result = re.match('.*src=&quot;(.*)&quot; width.*', url)
        if result is not None:
            # 把解析出来的图片url添加到url_list中
            url_list.append(result.group(1))

    return url_list
</code></pre>
<h4 id="url" tabindex="-1">通过图片url获取图片</h4>
<pre><code class="language-python"># 把爬取到的图片保存到本地
def save_pic(url_list):
    # 通过num给照片起名字 例如:0.jpg 1.jpg 2.jpg
    num = 0
    for url in url_list:
        # 通过requests.get()获取每一张图片
        pic = requests.get(f&quot;http://127.0.0.1:8000{url[1:]}&quot;)  # 索引为1开始切片，去掉获取的链接的第一个点
        # 创建文件保存每一张图片
        with open(f&quot;./source/spyder/{num}.jpg&quot;, &quot;wb&quot;) as f:
            f.write(pic.content)
            num += 1
</code></pre>
<h4 id="完整代码" tabindex="-1">完整代码</h4>
<pre><code class="language-python">import requests
import re


# 获取图片的请求url
def get_pic_url():
    # 通过爬虫向index.html发送请求
    # requests.get(网址): 向一个网址发送请求,和在浏览器中输入网址是一样的
    data = requests.get(&quot;http://127.0.0.1:8000/index.html&quot;)
    # content可以把requests.get()获取的返回值中的html内容获取到
    data = data.content.decode(&quot;utf8&quot;)
    # html每一行都有&quot;\n&quot;, 对html进行分割获得一个列表
    data = data.split(&quot;\n&quot;)
    # 创建一个列表存储所有图片的url地址(也就是图片网址)
    url_list = []
    for url in data:
        # 通过正则解析出所有的图片url
        result = re.match('.*src=&quot;(.*)&quot; width.*', url)
        if result is not None:
            # 把解析出来的图片url添加到url_list中
            url_list.append(result.group(1))

    return url_list


# 把爬取到的图片保存到本地
def save_pic(url_list):
    # 通过num给照片起名字 例如:0.jpg 1.jpg 2.jpg
    num = 0
    for url in url_list:
        # 通过requests.get()获取每一张图片
        pic = requests.get(f&quot;http://127.0.0.1:8000{url[1:]}&quot;)
        # 保存每一张图片
        with open(f&quot;./source/spyder/{num}.jpg&quot;, &quot;wb&quot;) as f:
            f.write(pic.content)
            num += 1


if __name__ == '__main__':
    url_list = get_pic_url()
    save_pic(url_list)
</code></pre>
<h3 id="gdp" tabindex="-1">爬取GDP数据</h3>
<h4 id="zip" tabindex="-1">zip函数的使用</h4>
<p><strong>zip()</strong> 函数: 用于将<a class="internal-link" target="" data-note-icon="" href="/czc知识库/计算机/Python/Python日常笔记/可迭代的对象/">可迭代的对象</a>作为参数，将对象中对应的元素打包成一个个元组，然后返回由这些元组组成的列表.</p>
<pre><code class="language-python">a = [1, 2, 3]
b = [4, 5, 6]
c = [4, 5, 6, 7, 8]
# 打包为元组的列表
zipped = zip(a, b)
# 注意使用的时候需要list转化
print(list(zipped))
&gt;&gt;&gt; [(1, 4), (2, 5), (3, 6)]

# 元素个数与最短的列表一致
zipped = zip(a, c)
# 注意使用的时候需要list转化
print(list(zipped))
&gt;&gt;&gt; [(1, 4), (2, 5), (3, 6)]
</code></pre>
<h4 id="gdp-1" tabindex="-1">爬取GDP数据</h4>
<pre><code class="language-python">import requests
import re

# 存储爬取到的国家的名字
country_list = []
# 存储爬取到的国家gdp的数据
gdp_list = []


# 获取gdp数据
def get_gdp_data():
    global country_list
    global gdp_list

    # 获取gdp的html数据
    data = requests.get(&quot;http://localhost:8000/gdp.html&quot;)
    # 对获取数据进行解码
    data = data.content.decode(&quot;utf8&quot;)
    # 对gdp的html数据进行按行分割
    data_list = data.split(&quot;\n&quot;)

    for i in data_list:
        # 对html进行解析获取&lt;国家名字&gt;
        country_result = re.match('.*&lt;a href=&quot;&quot;&gt;&lt;font&gt;(.*)&lt;/font&gt;&lt;/a&gt;', i)
        # 匹配成功就存放到列表中
        if country_result is not None:
            country_list.append(country_result.group(1))
        # 对html进行解析获取&lt;gdp数据&gt;
        gdp_result = re.match(&quot;.*￥(.*)亿元&quot;, i)
        # 匹配成功就存储到列表中
        if gdp_result is not None:
            gdp_list.append(gdp_result.group(1))
    # 把两个列表融合成一个列表
    gdp_data = list(zip(country_list, gdp_list))
    print(gdp_data)


if __name__ == '__main__':
    get_gdp_data()
</code></pre>
<h3 id="爬虫进阶" tabindex="-1">爬虫进阶</h3>
<h4 id="and-amp-xpath" tabindex="-1">伪造头信息实现反反爬虫 &amp; Xpath技术简化提取数据</h4>
<pre><code class="language-python">import requests
from lxml import etree

headers={
'User-Agent':'Mozilla/5.0(Windows NT 10.0;Win64; x64) AppleWebKit/537.36(KHTML, Like Gecko) Chrome/101.0.0.0 Safari/537.36'
}  # 伪造浏览器的头信息

res = requests.get('http://www.splxx.cn/WarticleList.aspx?typeid=opDItqtHf7A=', headers=headers)
<a class="tag" onclick="toggleTagSearch(this)" data-content="#把数据转换为HTML结构">#把数据转换为HTML结构</a>=&gt;结合XPath读取
data = etree.HTML(res.text)
data = data.xpath('//div[@class=&quot;list_body&quot;]//li/a/text()')  # 使用xpath技术读取数据，//表示从根节点开始，div[@class=&quot;list_body&quot;]表示class为list_body的div标签，//li/a/text()表示li标签下的a标签下的text()
for row in data:
    print(row)
</code></pre>
<h3 id="多任务爬虫" tabindex="-1">多任务爬虫</h3>
<p>同时爬取gdp数据和下载图片</p>
<pre><code class="language-python"># 获取gdp
def get_gdp_data():
    pass


# 获取照片
def get_pic():
    pass


if __name__ == '__main__':
    p1 = multiprocessing.Process(target=get_pic)
    p2 = multiprocessing.Process(target=get_gdp_data)

    p1.start()
    p2.start()
</code></pre>
</main>
<aside>
<div class="sidebar">
<div class="sidebar-container">
<div class="toc">
<div class="toc-title-container">
<div class="toc-title">
On this page
</div>
</div>
<div class="toc-container">
<nav class="toc">
<ol>
<li><a href="#python">Python爬虫</a>
<ol>
<li><a href="#什么是爬虫">什么是爬虫</a>
</li>
<li><a href="#爬虫的基本步骤">爬虫的基本步骤</a>
</li>
<li><a href="#requests">安装requests模块</a>
</li>
<li><a href="#爬取照片">爬取照片</a>
<ol>
<li><a href="#爬取照片的步骤">爬取照片的步骤</a>
</li>
<li><a href="#index-html">获取index.html代码</a>
</li>
<li><a href="#index-html-url">解析index.html代码获取图片url</a>
</li>
<li><a href="#url">通过图片url获取图片</a>
</li>
<li><a href="#完整代码">完整代码</a>
</li>
</ol>
</li>
<li><a href="#gdp">爬取GDP数据</a>
<ol>
<li><a href="#zip">zip函数的使用</a>
</li>
<li><a href="#gdp-1">爬取GDP数据</a>
</li>
</ol>
</li>
<li><a href="#爬虫进阶">爬虫进阶</a>
<ol>
<li><a href="#and-amp-xpath">伪造头信息实现反反爬虫 & Xpath技术简化提取数据</a>
</li>
</ol>
</li>
<li><a href="#多任务爬虫">多任务爬虫</a>
</li>
</ol>
</li>
</ol>
</nav>
</div>
</div>
<div class="backlinks">
<div class="backlink-title" style="margin:4px 0!important">Pages mentioning this page</div>
<div class="backlink-list"><div class="backlink-card"><i icon-name="link"></i><a href="/czc知识库/计算机/Python/python学习/④python高级进阶/④python爬虫/" data-note-icon="" class="backlink">④python爬虫</a>
</div><div class="backlink-card"><i icon-name="link"></i><a href="/czc知识库/计算机/Python/Python/" data-note-icon="" class="backlink">Python</a>
</div></div>
</div>
</div>
</div>
</aside>
<style>#tooltip-wrapper{background:var(--background-primary);padding:1em;border-radius:4px;overflow:hidden;position:fixed;width:80%;max-width:400px;height:auto;max-height:300px;font-size:.8em;box-shadow:0 5px 10px rgba(0,0,0,.1);opacity:0;transition:opacity .1s;unicode-bidi:plaintext;overflow-y:scroll;z-index:10}#tooltip-wrapper:after{content:"";position:absolute;z-index:1;bottom:0;left:0;pointer-events:none;width:100%;unicode-bidi:plaintext;height:75px}</style>
<div style="opacity:0;display:none" id="tooltip-wrapper">
<div id="tooltip-content">
</div>
</div>
<iframe style="display:none;height:0;width:0" id="link-preview-iframe" src="">
</iframe>
<script>var opacityTimeout,contentTimeout,transitionDurationMs=100,iframe=document.getElementById("link-preview-iframe"),tooltipWrapper=document.getElementById("tooltip-wrapper"),tooltipContent=document.getElementById("tooltip-content"),linkHistories={};function hideTooltip(){opacityTimeout=setTimeout((function(){tooltipWrapper.style.opacity=0,contentTimeout=setTimeout((function(){tooltipContent.innerHTML="",tooltipWrapper.style.display="none"}),transitionDurationMs+1)}),transitionDurationMs)}function showTooltip(t){var e=t.target,o=e.getClientRects()[e.getClientRects().length-1],i=window.pageYOffset||document.documentElement.scrollTop,n=t.target.getAttribute("href");if(-1===n.indexOf("http")||-1!==n.indexOf(window.location.host)){let t=n.split("#")[0];linkHistories[t]?(tooltipContent.innerHTML=linkHistories[t],tooltipWrapper.style.display="block",setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)):(iframe.src=t,iframe.onload=function(){tooltipContentHtml="",tooltipContentHtml+='<div style="font-weight: bold; unicode-bidi: plaintext;">'+iframe.contentWindow.document.querySelector("h1").innerHTML+"</div>",tooltipContentHtml+=iframe.contentWindow.document.querySelector(".content").innerHTML,tooltipContent.innerHTML=tooltipContentHtml,linkHistories[t]=tooltipContentHtml,tooltipWrapper.style.display="block",tooltipWrapper.scrollTop=0,setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),console.log(e),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)}),tooltipWrapper.style.left=o.left-tooltipWrapper.offsetWidth/2+o.width/2+"px",window.innerHeight-o.top<tooltipWrapper.offsetHeight?tooltipWrapper.style.top=o.top+i-tooltipWrapper.offsetHeight-10+"px":window.innerHeight-o.top>tooltipWrapper.offsetHeight&&(tooltipWrapper.style.top=o.top+i+35+"px"),o.left+o.width/2<tooltipWrapper.offsetWidth/2?tooltipWrapper.style.left="10px":document.body.clientWidth-o.left-o.width/2<tooltipWrapper.offsetWidth/2&&(tooltipWrapper.style.left=document.body.clientWidth-tooltipWrapper.offsetWidth-20+"px")}}function setupListeners(t){t.addEventListener("mouseleave",(function(t){hideTooltip()})),tooltipWrapper.addEventListener("mouseleave",(function(t){hideTooltip()})),t.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout),showTooltip(t)})),tooltipWrapper.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout)}))}window.addEventListener("load",(function(t){document.querySelectorAll(".internal-link").forEach(setupListeners),document.querySelectorAll(".backlink-card a").forEach(setupListeners)}))</script>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
