<!doctype html>
<html lang="en">
<head>
<title>301-面向对象基本思想</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.d92311c2.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
</head>
<body class="theme-dark markdown-preview-view markdown-rendered markdown-preview-section">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">Digital Garden</h1>
</a>
</div>
</nav>
<main class="content cm-s-obsidian">
<header>
<div class="header-meta">
</div>
</header>
<h1 id="要学会啥？" tabindex="-1">要学会啥？</h1>
<ul>
<li>面向对象编程思想</li>
<li>面向对象基本概念
<ul>
<li><strong>对象</strong></li>
<li><strong>类</strong></li>
</ul>
</li>
<li>添加和获取对象属性</li>
<li>魔术方法（三个常见的init、str、del）</li>
</ul>
<h1 id="面向对象编程思想" tabindex="-1">面向对象编程思想</h1>
<p>两个时代的两个产物，没有好坏之分，小系统用面向过程，团队开发用面向对象</p>
<h2 id="编程思想" tabindex="-1">编程思想</h2>
<p>所谓的编程思想，就是人们利用计算机来解决实际问题的一种思维方式，常见的编程思想有面向过程和面向对象，很多<br>
计算机语言的语法各不相同，但是它们基本的编程思想却是差不多的，而Python是同时支持面向对象和面向过程的编<br>
程语言！</p>
<h2 id="面向过程编程思想" tabindex="-1">面向过程编程思想</h2>
<p>自顶向下，逐步细化</p>
<p>学生管理系统→while True→菜单→增删改查→具体def</p>
<p>面向过程的核心：<strong>函数</strong></p>
<h2 id="面向对象编程思想-1" tabindex="-1">面向对象编程思想</h2>
<p>编程的的时候尽可能模拟世界</p>
<p>面向对象第一步：找对象<br>
面向对象第二部：找每个对象属性和方法<br>
面向对象第三步：让对象执行相关功能</p>
<h1 id="面向过程向面向对象思想迁移" tabindex="-1">面向过程向面向对象思想迁移</h1>
<p>面向对象的核心思想是：不仅仅是简单的将功能进行封装（封装成函数），更是对调用该功能的主体进行封装，实现某个主体拥有多个功能，在使用的过程中，先得到对应的主体，再使用主体去实现相关的功能！</p>
<h1 id="面试题：面向过程和面向对象的区别" tabindex="-1">面试题：面向过程和面向对象的区别</h1>
<p>①都可以实现代码重用和模块化编程，面向对象的模块化更深，<strong>数据也更封闭和安全</strong><br>
②面向对象的思维方式更加贴近现实生活，更容易解决<strong>大型的复杂的业务逻辑</strong>，适合团队开发<br>
③从前期开发的角度来看，面向对象比面向过程要<strong>更复杂</strong>，但是从维护和扩展的角度来看，<strong>面向对象要远比面向过程</strong><br>
<strong>简单</strong>！<br>
④面向过程的<strong>代码执行效率</strong>比面向对象高（过度封装）</p>
<h1 id="来个代码例子：" tabindex="-1">来个代码例子：</h1>
<pre><code class="language-python">#!/usr/bin/env python
# -*- encoding: utf-8 -*-
'''
@File    :   model.py
@Time    :   2020/07/05 22:07:45
@Author  :   Yiling He
@Version :   1.0
@Contact :   heyilinge0@gmail.com
@License :   (C)Copyright 2020
@Desc    :   Define loss, build model, enable train and test. 
'''

# here put the import lib
from torch.nn import Sequential as Seq, Linear, ReLU
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import remove_self_loops, add_self_loops
import torch
import torch.nn.functional as F
from torch_geometric.data import Data, Batch
from torch_geometric.data import DataLoader
from torch_geometric.data import Dataset
import torch.nn as nn
import torch_geometric.nn as pyg_nn
import torch_geometric.utils as pyg_utils
import torch.optim as optim
import time
from datetime import datetime
from tqdm import tqdm
import os
import os.path as osp
import numpy as np
import logging
model_logger = logging.getLogger()

from training.loader import real_batch
from utils import get_device, fscore, metric2scores


class GNNStack(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, conv_func=None, global_pool=None, train_eps=False, layer_norm=False):
        super(GNNStack, self).__init__()
        self.convs = nn.ModuleList()
        self.conv_func = conv_func
        self.train_eps = train_eps
        self.convs.append(self.build_conv_model(input_dim, hidden_dim))
        self.norm = nn.ModuleList()
        if layer_norm:
            self.norm.append(nn.LayerNorm(hidden_dim))
            self.norm.append(nn.LayerNorm(hidden_dim))
        else:
            self.norm.append(pyg_nn.BatchNorm(hidden_dim))
            self.norm.append(pyg_nn.BatchNorm(hidden_dim))

        for l in range(2):
            self.convs.append(self.build_conv_model(hidden_dim, hidden_dim))
        self.global_pool = global_pool

        # post-message-passing
        if self.global_pool == 'mix':
            self.post_mp = nn.Sequential(
                # -&gt; CONV/FC -&gt; BatchNorm -&gt; ReLu(or other activation) -&gt; Dropout -&gt; CONV/FC -&gt;??                # nn.Linear(hidden_dim*2, hidden_dim*2), nn.ReLU(inplace=True), # mix_relu
                nn.Linear(hidden_dim*2, hidden_dim), nn.Dropout(0.25), 
                nn.Linear(hidden_dim, output_dim))
        else:
            self.post_mp = nn.Sequential(
                nn.Linear(hidden_dim, hidden_dim), nn.Dropout(0.25), 
                nn.Linear(hidden_dim, output_dim))

        self.dropout = 0.25
        self.num_layers = 3

    def build_conv_model(self, input_dim, hidden_dim):
        if not self.conv_func:
            return pyg_nn.GINConv(nn.Sequential(nn.Linear(input_dim, hidden_dim), nn.ReLU(),
                                                nn.Linear(hidden_dim, hidden_dim)), train_eps=self.train_eps)
        elif self.conv_func == 'GATConv':
            return pyg_nn.GATConv(input_dim, hidden_dim)

    def forward(self, data):
        x, edge_index, batch = data.x, data.edge_index, data.batch
        if data.num_node_features == 0:
            x = torch.ones(data.num_nodes, 1)

        for i in range(self.num_layers):
            x = self.convs[i](x, edge_index)
            x = F.relu(x)
            x = F.dropout(x, p=self.dropout, training=self.training)
            if not i == self.num_layers - 1:
                x = self.norm[i](x)

        if not self.global_pool:
            x = pyg_nn.global_mean_pool(x, batch)
        elif self.global_pool == 'max':
            x = pyg_nn.global_max_pool(x, batch)
        elif self.global_pool == 'mix':
            x1 = pyg_nn.global_mean_pool(x, batch)
            x2 = pyg_nn.global_max_pool(x, batch)
            x = torch.cat((x1, x2), 1)

        emb = x
        x = self.post_mp(x)
        out = F.log_softmax(x, dim=1)

        return emb, out
    
    def apk_loss(self, pred, label, position):
        loss = 0
        for i in range(len(position)-1):
            start, end = position[i:i+2]
            apk_pred = pred[start:end]
            apk_label = label[start:end]
            unilabel = set(apk_label.tolist())
            
            assert len(unilabel)==1
            unilabel = list(unilabel)[0]
            if not unilabel: # Benign
                apk_loss = F.nll_loss(apk_pred, apk_label)  # log_softmax + nll_loss =&gt; cross_entropy
                # print('Benign Loss: %f' % apk_loss.item())
            else:
                scores = []
                for j in range(end-start):
                    scores.append(F.nll_loss(apk_pred[j:j+1], apk_label[j:j+1]))
                apk_loss = min(scores)
                # print('Malware Loss: %f' % apk_loss.item())
            
            loss += apk_loss
        return loss

    def apk_hard_loss(self, pred, label, position, weights=True):
        loss = 0
        for i in range(len(position)-1):
            start, end = position[i:i+2]
            apk_pred = pred[start:end]
            apk_label = label[start:end]
            unilabel = set(apk_label.tolist())
            
            assert len(unilabel)==1
            unilabel = list(unilabel)[0]
            if not unilabel: # Benign
                apk_loss = F.nll_loss(apk_pred, apk_label)
                # print('Benign Loss: %f' % apk_loss.item())
            else:
                scores = []
                all_scores = []
                for j in range(end-start):
                    single_pred = apk_pred[j:j+1]
                    single_loss = F.nll_loss(apk_pred[j:j+1], apk_label[j:j+1])
                    all_scores.append(single_loss)
                    if single_pred.argmax(dim=1):
                        scores.append(single_loss)
                sclen = len(scores)
                if sclen:
                    if weights:
                        w = np.linspace(0, 1, num=sclen+1)
                        w = (w / sum(w))[1:]
                        scores.sort(reverse=True) # descending order(larger loss, smaller weight??                        apk_loss = 0
                        for i in range(len(w)):
                            apk_loss += scores[i]*w[i]  
                    else:
                        apk_loss = sum(scores) / len(scores)
                else:
                    apk_loss =  min(all_scores)
                # print('Malware Loss: %f' % apk_loss.item())
            
            loss += apk_loss
        return loss
    
    
def my_train(loader, test_loader, writer, model_dict, dev=None, lossfunc=0, batch_size=64, num_epoch=1000, start_epoch=0, best=None, conv_func=None, global_pool=None, train_eps=False, dimension=128, layer_norm=False):
    dev = get_device(dev)
    model_logger.info('Starting Training')
    # build model
    num_classes = 2
    num_node_features = loader.dataset[0].data[0].x.shape[1]
    model = GNNStack(num_node_features, dimension, num_classes, conv_func=conv_func, global_pool=global_pool, train_eps=train_eps, layer_norm=layer_norm).to(dev)

    dict_name = model_dict.split('/')[-1]
    if best is None:
        if dict_name.startswith('last_epoch_') or (dict_name == '0'):
            best = [0, 0, 0, 0, 0]
        else:
            best = [float(i) for i in dict_name.split('_')]
    if osp.exists(model_dict):
        model.load_state_dict(torch.load(model_dict))
    model_path = '/'.join(model_dict.split('/')[:-1])
    
    opt = optim.Adam(model.parameters(), lr=0.001)
    min_loss = loss_model = None
    best_model = {i:None for i in range (5)}
    flag = False
    
    try:
        # train
        for epoch in range(num_epoch):
            total_loss = 0
            model.train()
            
            T1 = time.process_time()
            for batch in tqdm(loader, desc=f'Epoch {epoch}'):
                opt.zero_grad()
                batch, position = real_batch(batch)
                
                # print('batch traing for %d subgraphs' % len(batch.y))
                embedding, pred = model(batch.to(dev))
                label = batch.y
                if lossfunc == 0:
                    loss = model.apk_loss(pred, label, position)
                elif lossfunc == 1:
                    loss = model.apk_hard_loss(pred, label, position)
                elif lossfunc == 2:
                    loss = model.apk_hard_loss(pred, label, position, weights=False)
        
                loss.backward()
                opt.step()
                total_loss += loss.item()
                torch.cuda.empty_cache()
            T2 = time.process_time()
            model_logger.info(f'[Timer] Epoch@{epoch}: {T2-T1}')
            
            del batch, label, embedding, pred, loss
            torch.cuda.empty_cache()
                
            total_loss /= len(loader.dataset) # mean loss of that epoch
            r_epoch = start_epoch + epoch

            precission, recall, accuracy = my_test(test_loader, model, dev)
            f1 = fscore(precission, recall, 1) # f1-score
            f2 = fscore(precission, recall, 2)
            model_logger.info(&quot;Epoch {}. Loss: {:.4f}. [TEST] precission: {:.4f} recall: {:.4f} accuracy: {:.4f}, F1: {:.4f}&quot;.format(
                r_epoch, total_loss, precission, recall, accuracy, f1))
            if epoch % 5 == 0:
                writer.add_scalar(&quot;Train_Loss&quot;, total_loss, r_epoch)
                writer.add_scalar(&quot;Test_Precission&quot;, precission, r_epoch)
                writer.add_scalar(&quot;Test_Recall&quot;, recall, r_epoch)
                writer.add_scalar(&quot;Test_Accuracy&quot;, accuracy, r_epoch)
                writer.add_scalar(&quot;Test_F1-score&quot;, f1, r_epoch)
                writer.add_scalar(&quot;Test_F2-score&quot;, f2, r_epoch)

            if r_epoch &gt; 500 and not sum(best):
                flag = True
            if f1 &gt; 0.95 or (flag and f1 &gt; 0.85):
                store = [precission, recall, accuracy, f1, f2]
                savename = '%s/%f_%f_%f_%f_%f' % (model_path, precission, recall, accuracy, f1, f2)
                # save best precission or recall or accuracy or f1 or f2 model
                for i in range(5):
                    if store[i] &gt; best[i]:
                        best[i] = store[i]
                        if not osp.exists(savename):
                            torch.save(model.state_dict(), savename)
                        tmp = best_model[i]
                        best_model[i] = savename
                        if tmp is not None:
                            if osp.exists(tmp) and tmp not in best_model.values():
                                os.remove(tmp)
                # save min train loss model (if not in best models)
                if min_loss is None:
                    min_loss = total_loss
                elif total_loss &lt; min_loss:
                    min_loss = total_loss
                    if savename not in best_model.values():
                        if loss_model is not None:
                            os.remove(loss_model)
                        torch.save(model.state_dict(), savename)
                        loss_model = savename
                        
    except Exception as e:
        print(e)
        model_logger.exception(f'Exception while training batch `{batch}` in No.{epoch} epoch.')
        epoch -= 1
    finally:
        return epoch+1, model


def my_test(loader, model, dev=None, is_validation=False, curve=False, emb_=False):
    &quot;&quot;&quot; confusion matrix 
    `prediction` and `truth`
    - 1 and 1 (True Positive)
    - 1 and 0 (False Positive)
    - 0 and 0 (True Negative)
    - 0 and 1 (False Negative)
    &quot;&quot;&quot;
    model.eval()
    if dev is None:
        dev = get_device(dev)
        model.to(dev)
    if is_validation:
        api_preds = []
    if curve:
        apk_labels = []
        apk_preds = []
        apk_plabel = []
    if emb_:
        embeddings = []
    
    TP = TN = FN = FP = 0
    for data in loader:
        data, position = real_batch(data)
        with torch.no_grad():
            emb, pred = model(data.to(dev))
            if emb_:
                embeddings.extend(emb)
                continue
            if curve:
                pred_score = pred[:,1]
            pred = pred.argmax(dim=1) # 0 or 1
            label = data.y
            if is_validation:
                api_preds += pred.tolist() # api_labels in a batch
                continue
            
        for i in range(len(position)-1):
            start, end = position[i:i+2]
            apk_pred = pred[start:end]
            apk_label = label[start:end]
            unilabel = set(apk_label.tolist())
            
            assert len(unilabel)==1
            unilabel = list(unilabel)[0]
            apk_pred = apk_pred.sum().sign().item()
            # print(&quot;Label: %d \t Prediction:%s&quot; % (unilabel, apk_pred))
            if curve:
                apk_pred_score = pred_score[start:end]
                apk_preds.append(apk_pred_score.max().item())
                apk_plabel.append(apk_pred)
                apk_labels.append(unilabel)
            else:          
                if apk_pred==unilabel:
                    if unilabel:
                        TP += 1
                    else:
                        TN += 1
                else:
                    if unilabel: # pred=0, label=1
                        FN += 1
                    else:
                        FP += 1
                    
    if is_validation:
        return api_preds
    elif curve:
        return apk_preds, apk_labels, apk_plabel
    elif emb_:
        return embeddings
    else:
        precission, recall, accuracy = metric2scores(TP, FP, TN, FN, f=False)   
        return precission, recall, accuracy


if __name__ == &quot;__main__&quot;:
    import argparse
    parser = argparse.ArgumentParser(description='Model Efficiency Analysis')
    parser.add_argument('--node', '-n', help='node number of dummy input', type=int, default=35)
    parser.add_argument('--edge', '-e', help='edge number of dummy input', type=int, default=122)
    parser.add_argument('--feature', '-f', help='feature dimension of dummy input', type=int, default=492)
    parser.add_argument('--dimension', '-d', help='hidden layer embedding dimension', type=int, default=128)
    parser.add_argument('--pool', '-p', help='global pooling function', default='mix')
    parser.add_argument('--layer', '-l', help='set True if you want LayerNorm, else use BatchNorm', default=False)
    args = parser.parse_args()

    num_edge, num_node, num_node_features = [args.edge, args.node, args.feature]
    print(f'[INFO] num_node: {num_node}, num_edge: {num_edge}, num_node_features: {num_node_features}')
    data = Data(x=torch.randn(num_node, num_node_features), edge_index=torch.LongTensor(2*num_edge).random_(0, num_node).reshape(2, num_edge))

    dimension, global_pool, layer_norm = [args.dimension, args.pool, args.layer]
    print(f'[INFO] embedding dimension: {dimension}\n')
    model = GNNStack(num_node_features, dimension, 2, global_pool=global_pool, layer_norm=layer_norm)

    data = [data]
    from thop import profile, clever_format
    for dummy_input in DataLoader(data, batch_size=len(data)):
        macs, params = profile(model, inputs=(dummy_input, ))
        # macs, params = clever_format([macs, params], &quot;%.3f&quot;)
        print(f'\n[INFO] macs: {macs}, params: {params}')
    # print(f'[INFO] model structure: \n{model}')

</code></pre>
</main>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
