<!doctype html>
<html lang="zh-CN">
<head>
<title>MalBERTv2：基于代码感知bert的恶意软件识别模型 Code Aware BERT-Based Model for Malware Identification</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<script async type="module">import mermaid from"https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs"</script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/prism.min.js" integrity="sha512-hpZ5pDCF2bRCweL5WoA0/N1elet1KYL5mx3LP555Eg/0ZguaHawxNvEjF6O3rufAChs16HVNhEc6blF/rZoowQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/plugins/autoloader/prism-autoloader.min.js" integrity="sha512-sv0slik/5O0JIPdLBCR2A3XDg/1U3WuDEheZfI/DI5n8Yqc3h5kjrnr46FGBNiUAJF7rE4LHKwQ/SoSLRKAxEA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>
<script async src="https://cdn.jsdelivr.net/npm/lucide@0.115.0/dist/umd/lucide.min.js"></script>
<script>window.addEventListener("load",(()=>{document.querySelectorAll(".callout").forEach((e=>{const t=getComputedStyle(e).getPropertyValue("--callout-icon"),l=t&&t.trim().replace(/^lucide-/,"");if(l){const t=e.querySelector(".callout-title");if(t){const e=document.createElement("div"),c=document.createElement("i");e.appendChild(c),c.setAttribute("icon-name",l),e.setAttribute("class","callout-icon"),t.insertBefore(e,t.firstChild)}}})),lucide.createIcons(),Array.from(document.querySelectorAll(".callout.is-collapsible")).forEach((e=>{e.querySelector(".callout-title").addEventListener("click",(t=>{e.classList.contains("is-collapsed")?e.classList.remove("is-collapsed"):e.classList.add("is-collapsed")}))}))}))</script>
<script async src="https://fastly.jsdelivr.net/npm/force-graph@1.43.0/dist/force-graph.min.js"></script>
<script async src="https://fastly.jsdelivr.net/npm/@alpinejs/persist@3.11.1/dist/cdn.min.js"></script>
<script src="https://fastly.jsdelivr.net/npm/alpinejs@3.11.1/dist/cdn.min.js" async></script>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.25.0/themes/prism-okaidia.min.css" integrity="sha512-mIs9kKbaw6JZFfSuo+MovjU+Ntggfoj8RwAmJbVXQ5mkAX5LlgETQEweFPI18humSPHymTb5iikEOKWF7I8ncQ==" crossorigin="anonymous" referrerpolicy="no-referrer" async>
<script src="https://fastly.jsdelivr.net/npm/whatwg-fetch@3.6.2/dist/fetch.umd.min.js" crossorigin="anonymous" referrerpolicy="no-referrer" async></script>
<link href="/styles/digital-garden-base.css" rel="stylesheet">
<link href="/styles/obsidian-base.css" rel="stylesheet">
<link href="/styles/_theme.74516f71.css" rel="stylesheet">
<link href="/styles/custom-style.css" rel="stylesheet">
<link rel="icon" href="/favicon.ico" sizes="any">
<link rel="icon" href="/favicon.svg" type="image/svg+xml">
<link rel="apple-touch-icon" href="/apple-touch-icon.png">
<link rel="manifest" href="/manifest.webmanifest">
<style></style>
<style></style>
</head>
<body class="theme-light markdown-preview-view markdown-rendered markdown-preview-section css-settings-manager mod-windows is-frameless is-maximized is-hidden-frameless is-focused obsidian-app theme-light show-inline-title show-ribbon show-view-header css-settings-manager theme-default line-style-solid folder-default blockquote-normal callout-normal checkbox-default tag-default link-default heading-default responsive-tile-height oz-show-all-num">
<nav class="navbar">
<div class="navbar-inner">
<a href="/" style="text-decoration:none">
<h1 style="margin:15px!important">czc&#39;s digital garden</h1>
</a>
</div>
<div class="search-button align-icon" onclick="toggleSearch()">
<span class="search-icon">
<i icon-name="search"></i>
</span>
<span class="search-text">
<span>Search</span>
<span style="font-size:.6rem;padding:2px 2px 0 6px;text-align:center;transform:translateY(4px)" class="search-keys">
CTRL + K
</span>
</span>
</div>
</nav>
<div class="search-container" id="globalsearch" onclick="toggleSearch()">
<div class="search-box">
<input type="search" id="term" placeholder="Start typing...">
<div id="search-results"></div>
<footer class="search-box-footer">
<div class="navigation-hint">
<span>Enter to select</span>
</div>
<div class="navigation-hint align-icon">
<i icon-name="arrow-up" aria-hidden="true"></i>
<i icon-name="arrow-down" aria-hidden="true"></i>
<span>to navigate</span>
</div>
<div class="navigation-hint">
<span>ESC to close</span>
</div>
</footer>
</div>
</div>
<script src="https://cdn.jsdelivr.net/npm/flexsearch@0.7.21/dist/flexsearch.bundle.js"></script>
<script>document.addEventListener("DOMContentLoaded",init,!1),document.addEventListener("DOMContentLoaded",setCorrectShortcut,!1),window.toggleSearch=function(){document.getElementById("globalsearch").classList.contains("active")?document.getElementById("globalsearch").classList.remove("active"):(document.getElementById("globalsearch").classList.add("active"),document.getElementById("term").focus())},window.toggleTagSearch=function(e){console.log(e.textContent);const t=e.textContent;t&&(window.document.getElementById("term").value=t.trim(),window.toggleSearch(),window.search())};const loadingSvg='\n    <svg width="100" height="100" viewBox="0 0 45 45" xmlns="http://www.w3.org/2000/svg" stroke="#fff">\n      <g fill="none" fill-rule="evenodd" transform="translate(1 1)" stroke-width="2">\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="1.5s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="1.5s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="1.5s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="6" stroke-opacity="0">\n              <animate attributeName="r"\n                   begin="3s" dur="3s"\n                   values="6;22"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-opacity"\n                   begin="3s" dur="3s"\n                   values="1;0" calcMode="linear"\n                   repeatCount="indefinite" />\n              <animate attributeName="stroke-width"\n                   begin="3s" dur="3s"\n                   values="2;0" calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n          <circle cx="22" cy="22" r="8">\n              <animate attributeName="r"\n                   begin="0s" dur="1.5s"\n                   values="6;1;2;3;4;5;6"\n                   calcMode="linear"\n                   repeatCount="indefinite" />\n          </circle>\n      </g>\n  </svg>';function debounce(e,t,n){var a;return function(){var r=this,i=arguments,c=n&&!a;clearTimeout(a),a=setTimeout((function(){a=null,n||e.apply(r,i)}),t),c&&e.apply(r,i)}}function setCorrectShortcut(){navigator.platform.toUpperCase().indexOf("MAC")>=0&&document.querySelectorAll(".search-keys").forEach((e=>e.innerHTML="⌘ + K"))}function createIndex(e){const t=e=>e.toLowerCase().split(/([^a-z]|[^\x00-\x7F])/),n=new FlexSearch.Document({cache:!0,charset:"latin:extra",optimize:!0,index:[{field:"content",tokenize:"reverse",encode:t},{field:"title",tokenize:"forward",encode:t},{field:"tags",tokenize:"forward",encode:t}]});return e.forEach(((e,t)=>{n.add({id:t,title:e.title,content:e.content,tags:e.tags})})),n}async function init(){let e=!0;if(localStorage.getItem("searchIndex")){let{date:t,docs:n}=JSON.parse(localStorage.getItem("searchIndex"));if("2025-06-04T08:48:00.343Z"===t){e=!1;let t=createIndex(n);window.docs=n,window.index=t}}if(e){let e=await(await fetch("/searchIndex.json?v=2025-06-04T08:48:00.343Z")).json(),t=createIndex(e);localStorage.setItem("searchIndex",JSON.stringify({date:"2025-06-04T08:48:00.343Z",docs:e})),window.docs=e,window.index=t}document.addEventListener("keydown",(e=>{if((e.ctrlKey||e.metaKey)&&"k"===e.key&&(e.preventDefault(),toggleSearch()),"Escape"===e.key&&document.getElementById("globalsearch").classList.remove("active"),document.getElementById("globalsearch").classList.contains("active")){if("ArrowDown"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.nextElementSibling?t.nextElementSibling.classList.add("active"):document.querySelector(".searchresult").classList.add("active")):document.querySelector(".searchresult").classList.add("active");let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("ArrowUp"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t?(t.classList.remove("active"),t.previousElementSibling?t.previousElementSibling.classList.add("active"):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling||e.classList.add("active")}))):document.querySelectorAll(".searchresult").forEach((e=>{e.nextElementSibling&&e.classList.add("active")}));let n=document.querySelector(".searchresult.active");n&&n.scrollIntoView({behavior:"smooth",block:"nearest",inline:"start"})}if("Enter"===e.key){e.preventDefault();let t=document.querySelector(".searchresult.active");t&&(window.location.href=t.querySelector("a").href)}}}));const t=debounce(search,200,!1);field=document.querySelector("#term"),field.addEventListener("keydown",(e=>{"ArrowDown"!==e.key&&"ArrowUp"!==e.key&&t()})),resultsDiv=document.querySelector("#search-results");const n=new URL(location.href).searchParams;n.get("q")&&(field.setAttribute("value",n.get("q")),toggleSearch(),search())}async function search(){let e=field.value.trim();if(!e)return;if(e==lastSearch)return;console.log(`search for ${e}`),window.lastSearch=e,resultsDiv.innerHTML=loadingSvg;let t=offlineSearch(e),n="";if(!t.length){let t=document.createElement("p");return t.innerText=`No results for "${e}"`,resultsDiv.innerHTML="",void resultsDiv.appendChild(t)}n+='<div style="max-width:100%;">',t.forEach((e=>{e.tags&&e.tags.length>0?n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        <div class="header-meta">\n                            <div class="header-tags">\n                                ${e.tags.map((e=>'<a class="tag" href="JavaScript:Void(0);">#'+e+"</a>")).join("")}\n                            </div>\n                        </div>\n                        ${e.content}\n                    </div>\n                </div>`:n+=`<div class="searchresult">\n                    <a class="search-link" href="${e.url}">${e.title}</a>\n                    <div onclick="window.location='${e.url}'">\n                        ${e.content}\n                    </div>\n                </div>`})),n+="</div>",resultsDiv.innerHTML=n}function truncate(e,t){return(e=e.replaceAll(/<[^>]*>/g,"")).length<t?e:e.substring(0,t-3)+"..."}function offlineSearch(e){let t=window.docs,n="#"===e[0]&&e.length>1?index.search(e.substring(1),[{field:"tags"}]):index.search(e,[{field:"title",limit:5},{field:"content",weight:10}]);const a=e=>{const t=n.filter((t=>t.field===e));return 0===t.length?[]:[...t[0].result]};return[...new Set([...a("title"),...a("content"),...a("tags")])].map((e=>{let n=t[e];return n.content=truncate(n.content,400),n.tags=n.tags.filter((e=>"gardenEntry"!=e&&"note"!=e)),n}))}window.lastSearch=""</script>
<main class="content cm-s-obsidian">
<header>
<h1 data-note-icon="">MalBERTv2：基于代码感知bert的恶意软件识别模型 Code Aware BERT-Based Model for Malware Identification</h1>
<div class="header-meta">
<div class="header-tags">
</div>
<div class="timestamps"><div><i icon-name="calendar-plus"></i> <span class="human-date" data-date="2025-02-21T14:29:00.553+08:00"></span></div><div><i icon-name="calendar-clock"></i> <span class="human-date" data-date="2025-04-18T21:25:25.371+08:00"></span></div></div></div>
</header>
<h2 id="摘要：" tabindex="-1">摘要：</h2>
<p>为了主动缓解恶意软件的威胁，网络安全工具，如杀毒软件和防火墙，需要频繁更新和主动实施。然而，仅依靠传统方法处理大量数据集样本可能会令人不知所措。在网络安全工作流程中，自然语言处理（NLP）模型的最新进展可以帮助主动检测各种威胁。本文提出一种新的方法，通过使用预训练语言模型MalBERTv2来表示恶意软件/商品（MG）数据集的相关性和重要性。我们的模型在公开的数据集上进行训练，通过提取呈现最相关信息的排名靠前的文件，重点关注应用程序的源代码。然后，这些文件通过预分词特征生成器传递，并使用生成的关键字从头开始训练分词器。最后，我们将一个使用transformer双向编码器表示（BERT）的分类器作为模型管道中的一个层。在不同的数据集上评估了该模型的性能，取得了从82%到99%的加权f1分数。实验结果证明了所提出方法在使用NLP技术主动检测恶意软件威胁方面的有效性。</p>
<h2 id="1" tabindex="-1">1.介绍</h2>
<p>已经开展了一系列研究，以使用机器学习（ML）和深度学习（DL）工具解决网络安全威胁。大量研究针对恶意软件在静态、动态和混合级别分析[1]，以提取各种特征，如应用程序编程接口（API）调用、权限和二进制文件。例如，深度学习算法的使用帮助安全专家分析复杂的网络攻击。深度学习模型由机器学习算法的几个层组成，这些层能够从极其复杂的数据集中学习高级抽象。这使得深度学习算法更有效地识别模式和检测恶意活动[2]。因此，DL使许多网络安全公司能够提高其恶意软件检测系统的准确性。随着NLP应用的指数级增长，深度学习算法，特别是基于transformer （TB）的架构，在解决复杂问题方面得到了普及。由于具有学习数据上下文的能力和处理大型数据集[3]的能力，这些算法比其他传统的ML技术显示出了显著的优势。NLP是人工智能（AI）的一个领域，它处理基于文本的语言数据。它提供了多种工具，用于将创新的网络安全相关解决方案付诸实践。为了找到基础设施中的弱点，NLP可以从公司的技术栈和威胁流中找到数据的重叠部分。NLP的最终目标是定位关键字，阅读文本，并理解任何相关的上下文。尽管所有这些任务现在都是手动完成的，但迫切需要一个自动化的系统。近年来，注意力权重[4]在语言建模中的应用改善了人工智能领域的迁移学习任务。BERT (Bidirectional encoder representation from transformers)[5]是最先进的TB模型之一。BERT是一种创新的、被广泛应用于学术界和工业界的解决方案。这些基于迁移学习的方法为在更大的数据集上预训练模型微调特定领域的自定义数据集提供了机会。TB模型比传统的单向语言模型[4]对语言上下文有更深入的理解。在本研究中，我们提出了一种使用MalBERT[6,7]检测恶意软件的新方法。本文扩展了之前的工作，使用更大的数据集来训练和建模Android恶意软件（AM）检测作为二进制文本分类问题。该方法利用软件应用的源代码作为特征集，并利用文本预处理技术提取相关信息，如意图和活动。在从公开资源中收集的预处理Android数据集上进行了广泛的实验。在我们之前的研究[7]中，我们提出了一个基于MalBERT的恶意软件自动识别和检测系统的架构。本文旨在量化文本文档的主观相关性及其潜在意义，可以使用现有的NLP技术进行定制，以满足代码感知的需求。本文提出了一种基于过滤文本的恶意软件内容识别方法，主要工作包括：1。本文提出MalBERTv2，一种用于恶意软件检测表示的MalBERT方法的改进版本，通过为用于MG检测的代码感知预训练语言模型创建一个完整的管道。2. 本文提出一个预分词过程来表示特征。3. 在从公共资源中收集的各种数据集上进行了广泛的实验和评估。</p>
<h2 id="2" tabindex="-1">2. 相关工作</h2>
<p>目前互联网上的主要威胁之一是恶意软件攻击。恶意软件检测、可视化和分类是解决该问题的主要研究领域之一。当今时代需要一个系统来自动分类恶意软件，而不需要反编译或混淆代码。对NLP中用于恶意代码分类的深度学习方法进行了综述。这些方法侧重于解析和提取自然语言中有用的信息，以简化人机交互。NLP在网络安全中成功的关键是大型数据集的可用性。网络安全中的文本数据来源多样，如电子邮件[8,9]、不同系统的交易日志、源代码和在线社交网络。使用自然语言处理技术从不同的网络事件和用户活动日志中获取信息，对态势感知有直接的影响。实现了多种文本数字表示方法，如向量空间模型和分布式表示。在单词或字符级别编码文本包括预处理，然后编码作为初始步骤。这包括数据清洗和转换不必要的和未知的单词或字符。非顺序输入和顺序输入是文本表示的两种主要类型。词袋（BoWs）[10]、词-文档矩阵（TDMs）[11]和词频-逆文档频率（TFIDF）矩阵属于非序列表示。N-gram、Keras embedding、Word2vec[12]、Neural-Bag-of-words和FastText[13]属于序列表示，可以提取词义相似度。在网络安全领域，由于大多数数据包含时间和空间信息，因此捕获时序信息比语义相似度更重要。因此，深度学习方法被用于有效的恶意软件检测。恶意软件攻击是互联网上的一大威胁，恶意软件检测、可视化和分类是解决这一问题的重要研究领域。随着人们对无需反编译或混淆代码的恶意代码自动分类需求的日益增长，深度学习（deep learning， DL）方法被应用于自然语言处理（natural language processing， NLP）中的恶意代码分类。这些方法侧重于解析和提取自然语言中有用的信息，以方便人机交互。大型数据集的可用性对NLP在网络安全中的成功至关重要，因为网络安全中的文本数据来自不同的来源，包括电子邮件、交易日志、源代码和在线社交网络。实现了多种文本数字表示方法，如向量空间模型和分布式表示。预处理涉及到单词或字符级别的文本编码，包括数据清洗和对不必要和未知单词或字符的转换。文本表示的两种主要类型是非顺序输入和顺序输入。虽然非顺序表示技术，如词袋、词文档矩阵和词频-逆文档频率矩阵很有用，但顺序表示技术，<strong>如Ngram、Keras embedding、Word2vec、神经词袋和FastText，更适合捕获在网络安全领域至关重要的顺序信息</strong>。因此，深度学习方法被用于有效的恶意软件检测。表1展示了使用自然语言处理（NLP）和深度学习模型的恶意软件相关工作的全面概述。该表包含了所使用的<strong>方法、作者、描述、数据类型和每个工作的重点信息</strong>。使用的方法包括各种<strong>标记化和嵌入技术、预训练模型和自定义学习模型</strong>。数据类型包括恶意软件和恶意软件样本，以及url和可执行文件。这些工作证明了NLP和深度学习模型在恶意软件检测和分类任务中的有效性。预训练模型和自定义学习模型的使用在识别不同类型的恶意软件方面表现出了良好的效果，并具有较高的准确率。此外，使用基于注意力机制和基于gan的方法提高了这些模型从数据中提取有意义特征的能力。尽管取得了这些进步，但仍然有挑战需要克服，包括最大序列长度的限制和缺乏恶意软件/产品识别的基准。需要进一步的研究来应对这些挑战并提高这些模型的性能。总之，本文概述中列出的工作为网络安全领域的研究人员和从业人员提供了宝贵的资源。</p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image.png"><source media="(max-width:480px)" srcset="/img/optimized/fCDYoJbIJQ-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/fCDYoJbIJQ-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/fCDYoJbIJQ-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/fCDYoJbIJQ-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image.png" width=""></picture><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-1.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-1.png"><source media="(max-width:480px)" srcset="/img/optimized/48dYaV00vb-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/48dYaV00vb-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/48dYaV00vb-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/48dYaV00vb-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-1.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-1.png" width=""></picture><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-2.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-2.png"><source media="(max-width:480px)" srcset="/img/optimized/XBVX0RilUb-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/XBVX0RilUb-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/XBVX0RilUb-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/XBVX0RilUb-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-2.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-2.png" width=""></picture><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-3.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-3.png"><source media="(max-width:480px)" srcset="/img/optimized/7mghexMhke-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/7mghexMhke-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/7mghexMhke-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/7mghexMhke-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-3.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-3.png" width=""></picture></p>
<h3 id="2-1" tabindex="-1">2.1. 基于深度学习的方法</h3>
<p>研究人员在学术界提出了多个研究和研究项目来解决恶意软件的识别和分类问题。Rupali等人研究了大量之前的研究论文，涵盖了恶意软件分类技术的系统设计的研究特点。Singh等人对恶意软件图像类别进行了综述，[27]等人重点分析了恶意软件样本的可执行文件。Kouliaridis等[28]将静态和动态分析相结合。他们通过对每个恶意软件实例的所有基分类模型的输出分别进行平均来引入集成模型。Syed等人[29]提出了DeepAMD，一种用于恶意软件检测的深度学习模型。他们的实验表明，DeepAMD在恶意软件类别分类和家族分类的静态和动态层上检测和识别恶意软件攻击的性能优于其他方法。Amin等人[30]提出了一种自定义学习模型的反恶意软件系统，通过从应用程序字节码中提取操作码来检测AM并对其进行属性识别。结果表明，双向长短期记忆（BiLSTMs）神经网络可以检测AM的静态行为。Karbab等人[31]提出了一种基于静态分析的检测AM的方法PetaDroid。该方法还适用于恶意软件家族的custring。该框架利用了建立在NLP之上的新技术，例如卷积神经网络（cnn）的集成。Pooja等人[32]对26个最先进的预训练CNN模型在AM检测中的性能进行了比较。还包括使用支持向量机（SVM）和随机森林（RF）分类器进行大规模学习，以及与CNN模型进行叠加得到的性能。基于他们的结果，一个基于efficientnet - b4cnn的模型可以使用Android DEX文件的基于图像的恶意代码表示准确检测AM。Chong等人提出了一种基于双头神经网络的异常检测方法。该模型识别先前训练的深度学习模型错误分类的时间开发样本。此外，Weng Lo等人提出了一种基于图神经网络（GNNs）的AM检测方法，通过捕获有意义的过程内调用路径模式。此外，跳跃知识技术适用于最小化过平滑问题的影响，这在gnn中很常见。</p>
<h3 id="2-2" tabindex="-1">2.2. 基于注意力的方法</h3>
<p>基于注意力机制的人工智能方法极大地推动了自然语言处理领域的发展，从而推动了与基于文本的网络安全相关的应用。Choi等人提出了一种基于API系统调用注意力机制的有害文件特征提取技术。他们的结果表明，该策略的性能优于两个常见的基线：基于跳跃连接的长短期记忆检测模型和基于cnn的检测模型。Cagatay等人[20]利用图注意力网络（GAN）中从恶意和良性Android文件中获取的API调用图来检测恶意软件威胁。Hei等人，[21]介绍了HAWK，一种使用异构GANs的自适应Android应用的恶意软件检测工具。为了表达隐式的高阶链接，他们将Android实体和行为关系作为异质信息网络（heterogeneous information network， HIN）。Pathak等人[22]提出了一项研究，使用两个基于注意力的BiLSTM模型来寻找最具预测性的API调用。他们发现了一组API调用，可以帮助社区发现新的恶意软件签名。Chen等人[23]提出了一种名为SLAM的恶意软件检测技术，该技术基于使用API调用语义的注意力方法。基于API执行序列的语义和结构数据进行特征检索；他们研究了执行序列的属性，并将它们分为17组。Ganesan et al.[24]利用残差注意力方法来发现恶意软件。他们使用了从一张图片中获取的全局数据（称为GIST特征），将该模型与基于cnn的技术和标准ML算法进行比较。建议的策略集中于吸引人们注意恶意软件的关键特征，使其从安全文件中脱颖而出，从而降低误报的数量。Ren等人，[25]建议ATT-CNNBiLSTM，一种用于识别域生成算法（DGA）攻击的深度学习框架来识别危险。通过生成不同的网络位置，利用DGA确定对命令控制服务器的责任点。注意力层为从域名中收集到的深度信息分配权重；CNN和BiLSTM神经网络层从域序列数据中提取特征。Lao等人[35]提出了DeepRan，使用全连接层和基于注意力的BiLSTM对勒索软件进行分类。通过在基于注意力机制的BiLSTM中添加条件随机场（CRF）模型，将异常活动标记为潜在的勒索病毒攻击之一。他们采用高维主机日志数据，并使用词频-逆文档频率（TFIDF）方法提取语义信息。注意力机制是TB模型的主要架构重点，注意力块并行重复执行其计算。每一个都被称为注意力头。</p>
<h3 id="2-3-transformer" tabindex="-1">2.3. 基于transformer的方法</h3>
<p>很少有工作将TB[4]架构应用于网络安全领域。我们的第一篇论文，MalBERT[7]，在对BERT进行微调以对二进制和多分类的恶意软件进行分类时，显示了有趣的性能结果。Rudd等人[14]通过从头开始训练transformer模型，实现了URL分类器的恶意和良性。他们指出，辅助自回归损失提高了模型的性能。Han等人[15]提出了两种交通网络分类方法，首先使用无标签流量预训练Albert模型，然后使用有标签流量数据对模型进行微调。其次，使用语言数据迁移Albert预训练语言模型，并使用带标签的网络流量对模型进行微调。他们发现，用网络流量数据预训练的ALBERT网络流量模型具有更快的收敛速度、更高的准确率和更少的误报。Li等人[16]提出了I-MAD，一种使用Galaxy Transformer网络进行静态恶意软件检测的深度学习模型。它可以从基本块、函数和可执行级别理解汇编代码。它还可以为其检测结果提供解释，定位恶意有效载荷，并在恶意代码样本中发现一致模式。Jusoh等人[17]专注于恶意软件检测的静态分析。他们提出了通过静态分析检测恶意软件的新方法，为研究人员提供了指南。他们讨论了从2009年到2019年发表的文章，并分析了静态分析、逆向工程、特征和分类中的步骤。Srinidhi等人[18]提出了一种结合静态和动态恶意软件检测方法的大数据分析框架。他们使用这两种方法对零日恶意软件进行分类和定位。在包含几个不同恶意软件家族的二进制文件样本上，他们测试了该框架。他们创建了三个候选特征的子集用于静态分析，使用权限和意图作为静态特征和三种特征选择技术[36-38]。利用多特征训练数据，他们最终应用提出的混合分析方法来识别AM并将样本分类到族中。Mahmood等人使用自动编码器作为生成模型。[39]提出了一种用于网络安全任务的特征学习模型，该模型可以学习各种特征集的潜在表示。通过使用特征向量，自动编码器能够提取出一个准确反映特征向量之间语义相似度的代码向量。后来，他们开发了一个无监督的模型来识别恶意软件。本文扩展了在MG数据集上开发的语言模型，并主要专注于二分类。本文还提出了一种新的预分词技术，以解决序列长度限制的问题。重点关注恶意软件和正品样本的文本表示。根据我们的数据，与其他评估基线相比，我们建议的技术表现最好。静态和动态评估必须使用复杂的过程。对于恶意软件识别，过程的特征表示阶段仍然是一个研究重点。随着Android数据集的普及，越来越多的研究集中在AM识别任务上。为了改善特征表示，我们实际上结合了最新的数据集，并使用全新的预标记化（pre-tokenization）对BERT进行微调。</p>
<h2 id="3" tabindex="-1">3. 建议的系统架构</h2>
<p>由于这项研究扩展了我们之前的工作[7]，因此之前使用的数据集将用于测试和比较模型架构的改进。我们分两个阶段构建模型：训练和测试。训练过程与预测或测试阶段是不同的。我们使用训练验证集来构建多级MalBERTv2分类器，然后在单独的测试集上进行评估。</p>
<h3 id="3-1" tabindex="-1">3.1. 数据创建</h3>
<p>数据创建阶段通过数据选择和排名，以获得最有用的数据集。由于没有已知的恶意代码分析基准，我们在线收集了恶意代码分析的数据集，并提取了不同格式的特征。我们还使用Androzoo平台从收集的Android包文件（APK）列表中下载了示例。然后我们提取了最重要的文件来传递给特征生成器。图1概述了一个研究的数据收集过程。图中显示了两个级别的预处理：第1级处理基于特征的数据集（FBs），第2级处理从最先进的数据集中提取的数据。对于第2级，数据通过VirusTotal来检查标记，然后提取Manifest.xml文件。从谷歌Play中采集商品apk，通过两个层次的预处理进行处理。在过程结束时，将为每个示例生成文本文件。</p>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-4.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-4.png"><source media="(max-width:480px)" srcset="/img/optimized/9psEeQ6O1Y-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/9psEeQ6O1Y-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/9psEeQ6O1Y-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/9psEeQ6O1Y-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-4.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-4.png" width=""></picture></p>
<h3 id="3-2" tabindex="-1">3.2. 特征创建模块</h3>
<p>特性创建有两个级别，如图2所示。这些水平取决于收集的数据集的来源。公开可用的AM数据集有两种不同的格式。</p>
<ul>
<li>首先是研究人员与<strong>APK格式</strong>的样本共享的数据集，其中每个样本都有一个不同的哈希标识符，作为一种指纹。恶意软件通常通过一种称为哈希的技术来识别。一个哈希应用程序被用来运行恶意软件，产生一个独特的哈希作为恶意软件的标识。</li>
<li>其次，根据他们建议的提取方法，数据集作者共享预处理的特征。这些特征主要表现为<strong>CSV文件</strong>。</li>
</ul>
<p><picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-5.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-5.png"><source media="(max-width:480px)" srcset="/img/optimized/qio9DqTBZs-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/qio9DqTBZs-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/qio9DqTBZs-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/qio9DqTBZs-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-5.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-5.png" width=""></picture></p>
<p>我们在两个级别上配置了特征生成器，以处理各种格式，以覆盖更大的数据集。NLP分析的第一个阶段是特征和代表性关键词的提取。TFIDF是最常用的关键词提取算法。有多种可用的技术，从利用学习到的语言模型（如BERT）的标记化到词嵌入。为了评估所提出策略的性能并与之进行比较，建立了不同程度的特征表示。除了开发我们自己独特的特征生成器，我们还使用了TFIDF，在维基百科数据集上训练的Fasttext词嵌入，以及预训练的BERT表示。</p>
<h4 id="3-2-1" tabindex="-1">3.2.1. 标记</h4>
<p>在预处理和分词阶段，原始文本首先被分割成单词或子单词，然后通过查找表将其转换为唯一的整数id。标记化是涉及文本的自然语言处理和机器学习任务中的关键步骤。在基于transformer的模型中，有三种主要类型的分词器，包括字节对编码（BPE） [42], WordPiece（线性时间WordPiece分词和快速WordPiece分词[43]）和句子[44]。BertTokenizer类提供了一个高级接口，其中包括BERT标记拆分算法和WordPieceTokenizer。它将句子作为输入并返回标记id。BERT的一个限制是最大序列长度为512个单词。小于最大长度的序列需要使用[PAD]标记进行填充，而较长的序列必须被截断。我们之前的工作[7]解决了这个限制。BERT中的上下文化嵌入提供了一种依赖于句子位置的单词表示，导致与词义相对应的不同聚类。这一特点在词义消歧任务中取得了成功。然而，BERT在恶意软件数据集中捕获模式的程度还需要进一步研究。</p>
<h4 id="3-2-2-mal-ber-tv2" tabindex="-1">3.2.2. MalBERTv2特征分析器</h4>
<p>为了详细描述数据集的特定性质，我们在transformer编码器tokenizer之上提出了一个初始tokenizer。将代码文本分割成更小的块是一项比看起来更困难的任务，有几种方法可以做到这一点。编码语法因使用的编程语言而异。这是稳健的第一步。我们注意到，标点符号没有正确地附加在单词上。我们应该考虑标点符号，这样模型就不必学习单词的不同表示以及后面可能出现的每个标点符号。然而，分词处理“android.permission”这个词的方式是不利的。INTERNET“代表”android&quot; &quot; permission &quot; &quot; INTERNET“，所以把它标记为<code>[”android&quot;, &quot; permission &quot;, &quot; INTERNET&quot;]</code>会更好。根据我们为文本分词应用的规则，对相同的文本生成不同的分词输出。表2是预处理后样本的一个例子。只有当你给预训练模型输入一个用与训练数据分词相同的规则分词的输入时，它才能正常运行。大的词汇量迫使模型有一个巨大的嵌入矩阵作为输入和输出层，这导致了内存和时间复杂度的增加。我们使用预定义的算法来定制数据集的分词过程。首先是MaxMatch[45]算法，即最大匹配算法，它从给定的相关语言中抽取出给定字典中存在的最大匹配词，作为真词知识库；此外，Sennrich等人在[46]中引入了BPE，一种带有子词单元的罕见词神经机器翻译。在预标记化之后，创建一组唯一的单词，并确定每个单词在训练数据中出现的频率。<br>
接下来，BPE创建一个基本词汇表，其中包含出现在唯一单词集中的所有符号，并学习合并规则，从基本词汇表中的两个符号形成一个新符号。BERT分词器已经使用了BPE，所以我们的预分词器是第一级特定的单词调节器。图3所示的标记赋予器应用预处理方法来清理代码文本，只保留有用的关键字。此外，我们还使用了MaxMatch算法，如MalBERTv2分词器的算法所示。然后，添加一个事件移除器。这个模块在第4节详细介绍。完整的分词器算法见算法1。<br>
为了评估之前的预训练分词器，我们比较了它们对收集的数据集的覆盖率。图4和图5展示了TB标记器和其他一些工具，如Fasttext和Glove。最好的TB分词器是bert - un大小写预训练模型，紧跟在Fasttext嵌入之后。然而，这些模型只能覆盖数据集已有词汇的50%左右。使用的嵌入是bert -base- un大小写，bert -base-大小写，bert -base-多语言大小写，bert -base-多语言无大小写，RoBERTabase-vocab, GPT2-xl-vocab, XLM-mlm-en-2048, Word2Vec (GoogleNews-vectors), Glove （Glove . 6b .300d）和Fasttext （wiki-en）。图4和5显示了预处理后对整个数据集样本文本和数据集词汇表的嵌入覆盖率。</p>
<p>3.3. 模型创建<br>
MalBERTv2框架包含一个用于MG分类的TB架构。它被设计成一个通用的恶意软件分类系统。模型构建和训练过程与预测或测试阶段不同。我们使用不同的数据集进行训练和验证，用于分词器和层来构建最终的分类器模型，然后在单独的测试数据集上进行评估。图6所示的模型显示了用于将基于bert的层的特征映射到主模型中的tokenizer的训练。<br>
该模型使用生成的特征并微调模型。BERT基础模型使用transformer块和一些自注意力头。对于序列中的每个输入标记，每个head计算用于创建加权表示的键、值和查询向量。同一层中所有头的输出被组合并通过全连接层运行。每一层都用一个跳跃连接包裹，然后进行层归一化。BERT的第一层接收标记、段和位置嵌入的组合作为输入。设X为含有M个恶意软件和G个良性软件样本的实例总数，其中M个样本具有标签L = 1表示恶意软件，来自X的G个样本具有标签L = 0表示良性软件或良性软件。所有X样本都被提取为包含特征的全文文件。我们在特征上应用了2级特征生成器。最后，样本被表示为文本文件F表示。MalBERT主要关注如图7所示的注意力层。注意力将它们的输入视为一组没有顺序的向量。该模型也不包含任何递归或卷积层。transformer是用来处理顺序输入数据的，很像循环神经网络（rnn）。然而，与rnn不同的是，transformer不是按顺序处理数据，而是使用位置编码（PE）。为了使模型获得词项在句子中的相对位置信息，引入了PE。将PE向量与嵌入向量相加。嵌入表示d维空间中的标记，其中具有相似含义的标记将彼此更接近。然而，嵌入并不编码标记在句子中的相对位置。计算PE的公式如公式(1)和(2)所示。transformer使用的注意力函数有三个输入：Q(query)， K(key)， V(value)，如公式(3)所示。点积注意力按深度的平方根进行缩放。这样做的原因是，对于较大的深度值，点积在量级上增长很大，将softmax函数推到具有较小梯度的地方。BERT使用Adam优化器和自定义学习率调度，如式(4)所示：<br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-6.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-6.png"><source media="(max-width:480px)" srcset="/img/optimized/xsiZMDDWfg-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/xsiZMDDWfg-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/xsiZMDDWfg-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/xsiZMDDWfg-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-6.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-6.png" width=""></picture><br>
<picture src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-7.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-7.png"><source media="(max-width:480px)" srcset="/img/optimized/ueqf-8Fj6k-500.webp" type="image/webp">
<source media="(max-width:480px)" srcset="/img/optimized/ueqf-8Fj6k-500.jpeg">
<source media="(max-width:1920px)" srcset="/img/optimized/ueqf-8Fj6k-700.webp" type="image/webp"><source media="(max-width:1920px)" srcset="/img/optimized/ueqf-8Fj6k-700.jpeg"><img class="" src="/img/user/czc%E7%9F%A5%E8%AF%86%E5%BA%93/%E6%9D%82%E4%B8%83%E6%9D%82%E5%85%AB/9-%E9%99%84%E4%BB%B6/%E9%99%84%E4%BB%B6/MalBERTv2%EF%BC%9ACode%20Aware%20BERT-Based%20Model%20for%20Malware%20Identification_image-7.png" alt="MalBERTv2：Code Aware BERT-Based Model for Malware Identification_image-7.png" width=""></picture></p>
<h2 id="4" tabindex="-1">4. 实现</h2>
<p>在本节中，我们将详细介绍所提出方法的实现步骤。我们从数据集的细节开始，然后是特征工程步骤，最后我们详细说明事件删除方法。<br>
4.1. 数据集<br>
预训练模型的性能在很大程度上取决于用于训练的数据集的规模和质量。因此，我们需要一个大规模的扫描文档数据集来预训练MalBERTv2模型。我们最终从图8所示的分布的数据集中选择了85000个应用程序。<br>
• AMD数据集[47]。它包含24553个样本，分类在71个恶意软件家族的135种品种中，从2010年到2016年。该数据集与研究社区公开共享。<br>
•Drebin数据集[48]。它包含来自179个不同恶意软件家族的5560个应用程序。样本采集时间为2010年8月至2012年10月，由MobileSandbox项目[48]提供。作者公开了项目中的数据集，以促进AM的研究，并使不同检测方法的比较成为可能。<br>
•VirusShare数据集[49]。它是一个恶意代码样本的仓库，安全研究人员可以通过它获取实时的恶意代码样本。它是从恶意软件库VirusShare中获取的静态数据集。样本是使用AM数据集去偏准则[50]收集的。<br>
• Androzoo数据集[51]。它是一个不断增长的Android应用程序集合，来自各种来源，包括官方谷歌Play应用程序市场，目的是促进Android相关研究。它目前包含超过1500万个apk，每一个都被数十种不同的反病毒产品分析，以确定哪些应用程序是恶意软件。每个应用程序包含20多种不同类型的元数据，例如VirusTotal报告。</p>
<p>微调数据集可以归纳为两种类型：最先进的数据集，包括MixG-Androzoo， MixG-VirusShare， MixG-AMD和MixG-Derbin，以及基于特征的数据集（FBs），包括D01， D02, D03, D04, D05。</p>
<p>• Android权限和API调用动态分析[52]。该数据集包括50000个Android应用程序和10000个恶意应用程序，它们来自不同的来源。我们把这个数据集记为D01。<br>
• Android恶意软件检测[53]。这些数据包含来自不同来源的apk，包括恶意和正常应用程序。它们是在选择足够数量的应用程序后创建的。使用pyaxmlparser和Androguard[54]框架，我们分析数组中的每个应用程序。在每个特征的集合上，我们使用二进制向量格式，在标记为class的最后一列中，我们将其标记为1（恶意）或0（良性）。我们把这个数据集记为D02。<br>
• 用于机器学习的Android恶意软件数据集[55]。这些数据包含从15036个应用中提取的215个特征向量：5560个来自Drebin项目的恶意应用和9476个正常应用。该数据集用于开发和测试用于AM检测的多级分类器融合方法。支持文件包含通过对Android应用程序的静态代码分析发现的特征向量或属性的更详细的描述。我们把这个数据集记为D03。<br>
• Android恶意软件和正常权限数据集[56]。这些数据包括18,850个正常android应用程序包和10,000个恶意android应用程序包，用于识别恶意应用程序在运行时所需权限的行为。我们把这个数据集记为D04。<br>
• Android权限数据集[57]。这些数据包含android应用程序及其权限。它们被分为1（恶意）或0（良性）。我们将这个数据集命名为D05。</p>
<p>根据DADA[58]标记指南的建议，从最先进的数据集收集了样本。这些样本是优质软件和恶意软件的混合体。作者提出这些APK列表是为了解决恶意软件数据集存在偏差的问题。收集的数据集是MixG-Androzoo、MixG-VirusShare、MixG-AMD和MixGDerbin。图9显示了所有测试数据集的分布及其主要功能以及应用程序的发布日期。</p>
<p>4.2. 预处理和特征表示</p>
<p>数据预处理阶段与MalBERT[7]相同，包括基本的标点删除。一旦定义了apk列表，我们就可以编写一个脚本来下载这些文件。然后，我们使用Jdax[59]和Apktool[60]反编译下载的apk，这将创建应用程序文件的文件夹[61]。我们从每个示例中提取了Mani fest .xml文件。这个文件展示了有关应用程序的基本信息，包括权限列表、活动、服务、广播接收器、内容提供者、版本和元数据。然后，这些文件被解析为文本格式，并通过预处理阶段。在这一步中，我们对不重要的、主要是重复的单词进行特定的清理。我们手动分析了不同的示例，并创建了一个单词和表达式列表，这些单词和表达式不提供额外的信息。预处理的目的是将输入的大小减少到transformer指定的标记数量的限制。最终的数据集格式有三列，ID列用APK散列名称表示，text列用预处理后的清单文件表示，label列用二进制格式表示，如果应用程序是恶意软件，则等于1，否则为0，而对于其余的数据集，因为特征的CSV是二进制的。如果特征存在，则将特征的名称连接到文本中。</p>
<p>4.3. 发生剂</p>
<p>我们处理的是代码文本，而不是普通文本，因此某些键的存在比这个单词在文件中出现的次数更重要。基于这个假设，我们删除所有出现的单词。我们假设关键字是否存在比关键字是否出现更重要。图10显示了数据集不同文档中文档单词的密度，而图11显示了应用所提出的分词器后的密度。现在，98%的样本符合512个token的阈值限制。</p>
<h2 id="5" tabindex="-1">5. 实验结果</h2>
<p>本节着重于使用提出的评估指标对所进行的实验结果进行评估。为了比较所提出的方法，根据相关研究定义了基线。定义了评估指标来评估所提出方法和基线的性能。所选择的指标是经过仔细选择的，以确保它们准确地反映模型的性能。最后，给出实验结果并进行分析，以评估所提方法对恶意代码样本检测的有效性。</p>
<p>5.1. 基线</p>
<p>将MalBERTv2模型与文献中先前报道的几个最先进的恶意软件检测模型进行了性能比较。具体来说，选择用于比较的模型包括具有TFIDF特征表示的SVM模型、具有Fasttext预训练嵌入的CNN模型、具有TFIDF特征的MalBERTv1、transformer层模型以及提出的MalBERTv2模型。所选模型代表了恶意软件检测任务中常用的各种机器学习方法和特征表示。通过将所提出模型的性能与这些已建立的方法进行比较，旨在对其有效性进行全面评估，并强调任何潜在的优势或局限性。</p>
<p>5.1.1. Tfidf + SVM</p>
<p>我们使用一个基本的机器学习模型（SVM）和一个简单的文本表示（TFIDF）进行了一个初步的实验来评估恶意软件数据集。然而，分析这些数据集带来了重大挑战，因为这些恶意软件样本通常与收集到的恶意软件样本在时间或包装类型上存在重复或差异。这一限制使得在恶意软件检测和分类任务中获得准确可靠的结果具有挑战性。</p>
<p>5.1.2. Fasttext + CNN</p>
<p>Fasttext[62]是一个广泛用于学习单词表示和句子分类的库。现代机器学习的一个基本思想是将单词表示为向量，该向量捕获关于语言的隐藏信息，如单词类比或语义，以提高文本分类器的性能。Fasttext的wiki-en模型嵌入是在维基百科文章上进行训练的，这使得它成为自然语言处理任务的一个有吸引力的选择。图4和5表明，Fasttext比其他预训练嵌入提供了更好的覆盖率，进一步推动了我们对该模型的选择。提出了一种简单的CNN模型，该模型由一个一维卷积网络和两个密集层组成，用于恶意软件分类。之前的相关工作[63,64]使用基于cnn的模型报告了有希望的结果。因此，将所提出方法的性能与这些最先进的模型进行比较至关重要。</p>
<p>5.1.3. MalBERTv1</p>
<p>MalBERT是一个经过微调的BERT模型，专门为恶意软件分类而设计。该模型在大量恶意软件和正品样本语料库上进行训练，目标是识别和区分这两类。MalBERT在几个基准数据集上取得了最先进的性能，包括Androzoo、Derbin、AMD和VirusShare。MalBERT的架构基于BERT， BERT是一种基于transformer的预训练语言模型，广泛应用于自然语言处理任务中。然而，与BERT不同的是，MalBERT是在恶意软件和正品样本的数据集上进行训练的，这使得它在恶意软件分类任务中更加有效。MalBERT的训练过程包括在大量恶意软件和正常软件样本的语料库上微调预训练的BERT模型，然后在微调后的BERT模型上训练分类层。与传统的基于特征的恶意代码检测方法相比，MalBERT模型具有许多优点。该方法能够检测出未知类型的恶意软件，并能有效识别不同类型的恶意软件，具有较高的准确率。此外，该模型可以处理大量非结构化文本类数据，使其成为网络安全专业人员的有用工具。图12显示了MalBERTv1方法步骤的概述，是使用MalBERTv1方法识别和分类恶意软件样本的过程的图形表示，图13显示了MalBERTv1中的模型微调过程。</p>
<p>在我们的研究中，我们使用[7]中描述的MalBERT实现。MalBERT模型在过程开始时使用特定的特征表示对BERT模型进行微调。为了解决BERT的512个词项的限制，该方法通过优先排序最重要的单词并选择前512个词项来重新排序文本。BERT[5]是一种由一堆transformer块组成的神经网络架构。transformer模块利用自注意力在输入序列中的单词之间建立关系，并生成有意义的嵌入。</p>
<p>5.1.4. 从头开始TFIDF + Transformer</p>
<p>该基线的主要目标是评估使用基本的单词标记化从头训练transformer编码器的有效性，特别是词频-逆文档频率（TFIDF）方法。transformer块使用多头注意力、前馈和归一化技术构建。对于本实验，我们将头的数量设置为2，并将transformer块作为一层添加到两个全连接层。为了进行二分类，我们使用了sigmoid激活函数。这个实验设置允许我们将所提出的模型与基准方法进行比较，并确定额外的特征和技术在多大程度上提高了模型的性能。</p>
<p>5.2. 培训MalBERTv2</p>
<p>如图2所示，训练过程包括几个阶段，包括数据收集和特征创建，在第4节中详细描述。在后续章节中，我们将重点放在模型创建的最后阶段。</p>
<p>5.2.1. 训练MalBERTv2分词器</p>
<p>在这项研究中，我们处理的是用各种编程语言编写的文件，而不是具有结构化段落和连续上下文的传统英语文本。图11显示，使用基于transformer （TB）或传统深度学习嵌入的最先进数据集的词汇覆盖率低于50%，表明这些模型对我们的特定领域不充分。为了解决这个问题，我们开发了一个基于RoBERTa[65]的分词器模型，从头开始训练，作为所提出的MalBERTv2模型的编码器和解码器。由于我们的数据域是特定于应用程序的，因此必须包含与应用程序描述相关的相关单词和符号，同时避免来自其他领域的不相关的通用词汇。为了实现这一点，我们为tokenizer创建了一个代码感知的特定词汇表。我们模型的训练阶段可以用四个主要步骤来描述：</p>
<ol>
<li>在数据集上应用特征生成器，并将生成的特征作为tokenizer的输入。特征生成器可以被认为是一个初始分词器，因为它对原始文本进行分词，以获得最相关和与英语相关的单词，而不会丢失文件中最重要的关键词。</li>
<li>使用与RoBERTa相同的特殊标记创建并训练一个字节级的字节对编码标记赋予器。</li>
<li>使用掩码语言建模（MLM）从头开始训练定义的RoBERTa模型。</li>
<li>保存分词器以映射测试数据集的特征，稍后对MalBERTv2分类器进行微调。</li>
</ol>
<p>5.2.2. 训练MalBERTv2分类器</p>
<p>为了构建分类任务的模型，我们在BERT的末尾添加了两个未经训练的密集神经元层，并对其进行微调。我们使用预训练的BERT基础模型初始化MalBERTv2模型的权重，该模型已经编码了关于训练数据词汇表的大量信息。这使我们能够通过将特征映射到建议的tokenizer来快速微调模型。微调BERT已被证明可以在对恶意软件识别任务进行最小的特定任务调整的情况下取得最先进的结果，如[7]所示。这种方法比实现适用于特定任务的自定义的、有时晦涩的体系结构更可取。该模型的参数包括BERT块层预训练的基本无套头BERT模型权重、最大序列长度为512、批量大小为8、Adam优化器[4]的学习率，该学习率根据公式(4)在最终的sigmoid激活函数上自定义学习率调度器，被设置为2e−5。这些参数是经过仔细选择的，以确保我们的模型的最佳性能。</p>
<p>5.3. 评价指标</p>
<p>评估模型的有效性，避免训练集和测试集划分带来的偶然性。使用以下性能指标评估模型：准确率、马修斯相关系数（MCC）、准确率（mc）、召回率（mc）、F1score （mc）和AUC是常见的分类问题指标。恶意软件类用（mc）标签表示。我们的评估是基于该模型检测恶意软件模式的能力。我们使用术语TP（真阳性）、FN（假阴性）、FP（假阳性）和TN（真阴性）。准确性（ACC）指标用于评估分类模型。它的计算方法是正确预测的次数除以总预测次数。MCC用于不平衡数据集的二分类。它的取值范围是-1到+1。我们选择了MCC而不是Chicco等人[66]推荐的F1-score进行二分类。标准F1-score的公式是精确率和召回率的调和平均值。一个完美的模型的f值为1。在本文的结果中，我们使用了宏平均。AUC[67]是指数学曲线下的面积。AUC的取值范围是0 ~ 1。公式(5)-(9)显示了所使用指标的不同细节。</p>
<p>5.4. 实验结果与讨论</p>
<p>本节概述了实验结果，以检查使用MalBERTv2通过从头训练transformer标记器来提高精度性能的可行性。</p>
<p>表3展示了5个模型（TFIDF + SVM、Fasttext + CNN、MalBERT、TFIDF + Transformer从零开始和MalBERTv2）在使用4个数据集（MixG-Androzoo、MixG-VirusShare、MixG-AMD和MixG-Derbin）进行恶意软件识别的评估结果。用于评估模型的指标有数据准确率、F1-score、马修斯相关系数（MCC）、准确率、召回率和曲线下面积（AUC）。总体而言，MalBERTv2在所有数据集上表现最好，平均准确率达到97.1%，f1分数达到97.2%，MCC达到95.8%，精确率达到98.4%，召回率达到96.7%，AUC达到98.6%。MalBERTv2在准确率、f1分数、精度和召回率方面优于其他所有模型。TFIDF + Transformer从头开始表现第二好，其次是MalBERT、Fasttext + CNN和TFIDF + SVM。值得注意的是，MalBERTv2模型在混合收集的数据集上进行了微调，这可能是其在评估中表现优越的原因。此外，数据集分割率为90%:10%用于训练验证和测试，这也会影响模型的性能。总的来说，该表清晰而有组织地比较了5种恶意软件识别模型的性能，为该领域的研究人员提供了有价值的见解。</p>
<p>表4展示了在五个收集的数据集上应用不同深度学习模型对恶意软件和良性软件样本进行分类的性能指标。将特征分析与MalBERT模型相结合的MalBERTv2在所有5个数据集上都取得了最好的性能，具有较高的准确率、F1-score、精确率、召回率和曲线下面积（AUC）值。传统的机器学习方法TFIDF与SVM相结合，其性能低于深度学习模型。Fasttext + CNN模型在一些数据集上取得了较高的准确率和f1分数，但精度和召回率相对较低。MalBERT模型单独在一些数据集上表现良好，但其性能因数据集而异。实验结果表明，将深度学习模型与特征分析相结合可以提高恶意软件检测系统的性能，MalBERTv2是一种很有前途的方法。</p>
<p>5.5. MalBERTv2在混合数据集上的性能</p>
<p>本文在混合收集的数据集上对MalBERTv2进行了评估。表4显示了与我们提出的方法相比，在四个提出的基线上的预测指标。训练验证集和测试集的划分比为90%：所有四个数据集的划分比为10%。从表3中可以看出，MalBERTv2对于恶意软件类具有最好的召回率和准确率，而我们没有将商品类的准确率包含在表中，因为我们想专注于恶意软件识别任务。在训练验证集上，Androzoo数据集的第一个基线的加权F1-measure很好，为0.9695，在使用MalBERTv2进行测试时有所提高。重要的是要注意，我们没有投入时间将参数工程过程应用于基线。我们主要关注于评估所提出方法的性能。</p>
<p>5.6. Malbertv2在基于特征数据集上的性能</p>
<p>该文在D01 ~ D05数据集上对MalBERTv2算法进行了评测。表4显示了与我们提出的方法相比，在四个提出的基线上的预测指标。训练验证集和测试集的划分比例也是90%：所有四个数据集的划分比例都是10%。需要注意的是，这些数据集的文档比之前的数据集要小。因为创建的文本是通过组合所提供的特征向量中存在的特征的名称创建的。在这种情况下，特征存在的陈述比特征出现的次数更重要，两个特征生成层次都适用于数据集。从表4可以看出，MalBERTv2在5个数据集上的准确率和加权F-measure相比其他基线都有所提升，准确率在0.8224 ~ 0.9376之间。所提出方法的主要优点之一是其灵活性，可以将任何格式的应用程序代码作为所需的功能。基于特征的数据集的结果说明了这种优势。</p>
<p>5.7. 时间性能分析</p>
<p>如前所述，我们使用了我们之前的工作[7]中描述的基于python的特征提取工具从应用程序中提取特征。从应用程序中提取特征所需的处理时间取决于它们的大小，从几千字节到几兆字节不等。平均来说，使用Apktool解压和分解一个应用程序需要70秒，而分析清单并生成特征的平均时间是10秒。因此，一个应用程序的总平均处理时间大约是80秒。在我们的实验中，我们将从工具中获得的特征向量输入到模型中进行测试。在加载tokenizer和MalBERTv2模型后，在单个GPU机器上对特征向量进行分类的测试时间为0.5 s。</p>
<p>5.8. 基线性能分析</p>
<p>根据表3和表4所示的评估结果，我们可以得出结论，对于所提出的预处理，根据表3和表4所示的评估结果，可以得出结论，所提出的使用MalBERTv2中的特征分析器的预处理技术，通过利用token化过程的不同阶段，增强了特征表示，并帮助模型专注于最相关的模式。与其他基线相比，使用简单的机器学习模型导致了较差的性能。TFIDF + SVM方法对D04的识别率达到了0.88，而单独使用SVM的识别率仅为0.81。为了进一步提高性能，我们将基于cnn的模型应用于使用Fasttext嵌入进行特征表示的数据集。如表3所示，该模型优于机器学习模型，从头开始使用带有transformer层的TFIDF n-grams将准确率提高了约0.2%。MalBERTv1表现出了最好的性能，超过了所有其他基准。</p>
<p>5.9. 定性分析</p>
<p>在本研究中，我们对使用的数据集的质量进行了全面的评估。数据集是在多个阶段从不同来源收集的。只选择可靠的数据集进行分析，并使用第一个基线模型剔除规模有限的数据集或通过简单训练即可产生高分类结果的数据集，其中恶意软件和商品是不同的。为了进一步评估数据的质量，我们将MixG-VirusShare数据集划分为恶意软件和良性软件子集。然后，在特征生成器生成的输出文本上应用知识图谱，并禁用事件移除器，以更深入地了解数据集特征。这种方法使我们能够评估数据集的质量，并识别任何可能影响我们分析的潜在问题或偏差。</p>
<p>5.9.1. 恶意的主要因素</p>
<p>类别图14和15展示了恶意软件样本中出现在实体之间的文本分布。图15特别关注了Con f igChanges实体，它根据Android文档限制了对敏感活动的访问。当一个activity在AndroidMani f est.xml文件中使用intent过滤器声明时，该activity可以被导出到其他应用。然而，如果该活动仅用于内部使用，并且启用了intent filter，则包括恶意软件在内的其他应用程序可能会出于恶意目的使用它[68]。图14中恶意软件和商品样本的文本表示，与商品样本中相同实体的连接数量相比，证明了检测模式的有效性。这一观察突出了恶意代码样本的文本表示的可靠性及其在检测恶意行为方面的潜在用途。</p>
<p>5.9.2. 商品的主要因素</p>
<p>类别图16和17可视化了出现在商品样本数据集中的实体之间的不同文本的分布。所提出的特征工程过程是MalBERTv2的一个重要组成部分。自然语言处理（NLP）是一个重要的领域，在网络安全中有许多应用，特别是在将文本表示转换为数值表示方面。文本表示的有效性在很大程度上取决于它们在特定任务中的表现。因此，选择合适的文本表示对于获得最优结果至关重要。</p>
<h2 id="6" tabindex="-1">6. 结论</h2>
<p>本文提出了一种新颖的方法来标记从恶意软件和商品数据集中提取的数据源。这种方法有助于关注来自不同编程语言的非结构化代码的相关性和重要性，这些代码对应用程序功能具有虚拟的重要性。相信该方法可以解决网络安全领域中处理大量非结构化文本类恶意软件/商品样本的问题。我们的想法是使用特征生成器来扮演主分类的预分词器的角色。我们在训练期间应用了这种代码感知的标记化过程，然后在测试阶段映射特征。新的特征表示方法将软件应用程序源代码视为一组特征。我们对这些特征进行文本预处理，以保留重要信息，如权限、意图和活动。我们从头开始训练基于bert的分词器，使用从不同数据集提取的85000个样本的特征，通常是Androzoo， Derbin， AMD， VirusShare和一组goodware样本，其中列表由DADA[58]提供。最后，训练MalBERTv2分类器；它有一个BERT层块，与预训练BERT具有相同的权重，并且我们添加了一个全连接层用于预测概率。将所有这些部分结合起来，提出了MalBERTv2，一种用于恶意软件分类的端到端恶意软件/好的语言模型。所提方法的结合产生了有趣的结果。由于缺乏恶意软件/商品识别的基准测试等限制，该模型不能有效地与现有方法进行比较。同时，在前人工作的基础上尝试选取最优的方法，并将其作为基准进行比较。此外，对于大量的数据集，研究人员以非日志格式提供了提取的特征。我们对包含特征名称和出现次数的数据集进行了重新格式化，但其余不符合要求的数据集在数据集收集步骤被删除。除了解决这些流，未来我们还将通过提高全平台执行时间、减少特征生成和预测过程来扩展研究。最终使整个系统能够在较短的时间内运行一个完整的周期。</p>
</main>
<aside>
<div class="sidebar">
<div class="sidebar-container">
<div class="toc">
<div class="toc-title-container">
<div class="toc-title">
On this page
</div>
</div>
<div class="toc-container">
<nav class="toc">
<ol>
<li><a href="#摘要：">摘要：</a>
</li>
<li><a href="#1">1.介绍</a>
</li>
<li><a href="#2">2. 相关工作</a>
<ol>
<li><a href="#2-1">2.1. 基于深度学习的方法</a>
</li>
<li><a href="#2-2">2.2. 基于注意力的方法</a>
</li>
<li><a href="#2-3-transformer">2.3. 基于transformer的方法</a>
</li>
</ol>
</li>
<li><a href="#3">3. 建议的系统架构</a>
<ol>
<li><a href="#3-1">3.1. 数据创建</a>
</li>
<li><a href="#3-2">3.2. 特征创建模块</a>
<ol>
<li><a href="#3-2-1">3.2.1. 标记</a>
</li>
<li><a href="#3-2-2-mal-ber-tv2">3.2.2. MalBERTv2特征分析器</a>
</li>
</ol>
</li>
</ol>
</li>
<li><a href="#4">4. 实现</a>
</li>
<li><a href="#5">5. 实验结果</a>
</li>
<li><a href="#6">6. 结论</a>
</li>
</ol>
</nav>
</div>
</div>
<div class="backlinks">
<div class="backlink-title" style="margin:4px 0!important">Pages mentioning this page</div>
<div class="backlink-list"><div class="backlink-card"><i icon-name="link"></i><a href="/硕士研究生/科研/文献阅读笔记/文献阅读笔记/" data-note-icon="" class="backlink">文献阅读笔记</a>
</div></div>
</div>
</div>
</div>
</aside>
<style>#tooltip-wrapper{background:var(--background-primary);padding:1em;border-radius:4px;overflow:hidden;position:fixed;width:80%;max-width:400px;height:auto;max-height:300px;font-size:.8em;box-shadow:0 5px 10px rgba(0,0,0,.1);opacity:0;transition:opacity .1s;unicode-bidi:plaintext;overflow-y:scroll;z-index:10}#tooltip-wrapper:after{content:"";position:absolute;z-index:1;bottom:0;left:0;pointer-events:none;width:100%;unicode-bidi:plaintext;height:75px}</style>
<div style="opacity:0;display:none" id="tooltip-wrapper">
<div id="tooltip-content">
</div>
</div>
<iframe style="display:none;height:0;width:0" id="link-preview-iframe" src="">
</iframe>
<script>var opacityTimeout,contentTimeout,transitionDurationMs=100,iframe=document.getElementById("link-preview-iframe"),tooltipWrapper=document.getElementById("tooltip-wrapper"),tooltipContent=document.getElementById("tooltip-content"),linkHistories={};function hideTooltip(){opacityTimeout=setTimeout((function(){tooltipWrapper.style.opacity=0,contentTimeout=setTimeout((function(){tooltipContent.innerHTML="",tooltipWrapper.style.display="none"}),transitionDurationMs+1)}),transitionDurationMs)}function showTooltip(t){var e=t.target,o=e.getClientRects()[e.getClientRects().length-1],i=window.pageYOffset||document.documentElement.scrollTop,n=t.target.getAttribute("href");if(-1===n.indexOf("http")||-1!==n.indexOf(window.location.host)){let t=n.split("#")[0];linkHistories[t]?(tooltipContent.innerHTML=linkHistories[t],tooltipWrapper.style.display="block",setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)):(iframe.src=t,iframe.onload=function(){tooltipContentHtml="",tooltipContentHtml+='<div style="font-weight: bold; unicode-bidi: plaintext;">'+iframe.contentWindow.document.querySelector("h1").innerHTML+"</div>",tooltipContentHtml+=iframe.contentWindow.document.querySelector(".content").innerHTML,tooltipContent.innerHTML=tooltipContentHtml,linkHistories[t]=tooltipContentHtml,tooltipWrapper.style.display="block",tooltipWrapper.scrollTop=0,setTimeout((function(){if(tooltipWrapper.style.opacity=1,-1!=n.indexOf("#")){let t=n.split("#")[1];const e=tooltipWrapper.querySelector(`[id='${t}']`);e.classList.add("referred"),console.log(e),e.scrollIntoView({behavior:"smooth"},!0)}else tooltipWrapper.scroll(0,0)}),1)}),tooltipWrapper.style.left=o.left-tooltipWrapper.offsetWidth/2+o.width/2+"px",window.innerHeight-o.top<tooltipWrapper.offsetHeight?tooltipWrapper.style.top=o.top+i-tooltipWrapper.offsetHeight-10+"px":window.innerHeight-o.top>tooltipWrapper.offsetHeight&&(tooltipWrapper.style.top=o.top+i+35+"px"),o.left+o.width/2<tooltipWrapper.offsetWidth/2?tooltipWrapper.style.left="10px":document.body.clientWidth-o.left-o.width/2<tooltipWrapper.offsetWidth/2&&(tooltipWrapper.style.left=document.body.clientWidth-tooltipWrapper.offsetWidth-20+"px")}}function setupListeners(t){t.addEventListener("mouseleave",(function(t){hideTooltip()})),tooltipWrapper.addEventListener("mouseleave",(function(t){hideTooltip()})),t.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout),showTooltip(t)})),tooltipWrapper.addEventListener("mouseenter",(function(t){clearTimeout(opacityTimeout),clearTimeout(contentTimeout)}))}window.addEventListener("load",(function(t){document.querySelectorAll(".internal-link").forEach(setupListeners),document.querySelectorAll(".backlink-card a").forEach(setupListeners)}))</script>
<script>window.location.hash&&document.getElementById(window.location.hash.slice(1)).classList.add("referred"),window.addEventListener("hashchange",(e=>{const t=e.oldURL.split("#");t[1]&&document.getElementById(t[1]).classList.remove("referred");const n=e.newURL.split("#");n[1]&&document.getElementById(n[1]).classList.add("referred")}),!1);const url_parts=window.location.href.split("#"),url=url_parts[0],referrence=url_parts[1];document.querySelectorAll(".cm-s-obsidian > *[id]").forEach((function(e){e.ondblclick=function(e){const t=url+"#"+e.target.id;navigator.clipboard.writeText(t)}}))</script>
<script src="https://fastly.jsdelivr.net/npm/luxon@3.2.1/build/global/luxon.min.js"></script>
<script defer="defer">TIMESTAMP_FORMAT="MMM dd, yyyy h:mm a",document.querySelectorAll(".human-date").forEach((function(e){date=e.getAttribute("data-date")||e.innerText,parsed_date=luxon.DateTime.fromISO(date),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromSQL(date)),null!=parsed_date.invalid&&(parsed_date=luxon.DateTime.fromHTML(date)),e.innerHTML=parsed_date.toFormat(TIMESTAMP_FORMAT)}))</script>
<script>lucide.createIcons({attrs:{class:["svg-icon"]}})</script>
</body>
</html>
